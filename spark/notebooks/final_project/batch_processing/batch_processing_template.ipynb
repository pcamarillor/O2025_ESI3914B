{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "\n",
    "#### <center> **Final Project: Batch Processing** </center>\n",
    "---\n",
    "\n",
    "**Date**: October, 2025\n",
    "\n",
    "**Student Name**: Juan Bernardo Orozco Quirarte\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c542e7f",
   "metadata": {},
   "source": [
    "# Objective \n",
    "To build a data pipeline in Python using Apache Spark for data consumption, transformation, and persistence, with the objective of addressing a practical problem. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd2743",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "### Breve descripción del problema: optimizar ocupación de gimnasios para reducir congestión en horarios punta, mejorar experiencia de usuario y planear recursos.\n",
    "\n",
    "### Fuentes de decisión: usar checkins de usuarios y uso de equipo para:\n",
    "- detectar horas pico\n",
    "- calcular ocupación por zona/equipo\n",
    "- proponer ventanas con baja ocupación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98cc0ac",
   "metadata": {},
   "source": [
    "# Dataset \n",
    "### Modelo de datos: relacional (tablas: gyms, users, checkins)\n",
    "- gyms(gym_id, name, city)\n",
    "- users(user_id, name, age, membership_type)\n",
    "- checkins(checkin_id, gym_id, user_id, timestamp, equipment, duration_min)\n",
    "\n",
    "### CSVs Generados con Faker y disponibles en la carpeta lib/bernardoorozco junto con el .py que genera datos con faker \"faker_project_generator.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dffd4501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/24 00:57:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Final Project Batch Processing\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"INFO\")\n",
    "\n",
    "# Optimization (reduce the number of shuffle partitions)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebdb6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bernardoorozco.spark_utils import SparkUtils\n",
    "base_path = \"/opt/spark/work-dir/lib/bernardoorozco\"\n",
    "\n",
    "gyms_schema= SparkUtils.generate_schema([\n",
    "    (\"gym_id\", \"string\"),\n",
    "    (\"name\", \"string\"),\n",
    "    (\"city\", \"string\")\n",
    "])\n",
    "\n",
    "users_schema= SparkUtils.generate_schema([\n",
    "    (\"user_id\", \"string\"),\n",
    "    (\"username\", \"string\"),\n",
    "    (\"age\", \"int\"),\n",
    "    (\"membership_type\", \"string\")\n",
    "])\n",
    "\n",
    "checkins_schema= SparkUtils.generate_schema([\n",
    "    (\"checkin_id\", \"string\"),\n",
    "    (\"gym_id\", \"string\"),\n",
    "    (\"user_id\", \"string\"),\n",
    "    (\"timestamp\", \"timestamp\"),  \n",
    "    (\"equipment\", \"string\"),\n",
    "    (\"duration_min\", \"int\")\n",
    "])\n",
    "\n",
    "gyms_df = spark.read.schema(gyms_schema).option(\"header\", True).csv(f\"{base_path}/gyms.csv\")\n",
    "users_df = spark.read.schema(users_schema).option(\"header\", True).csv(f\"{base_path}/users.csv\")\n",
    "checkins_df = spark.read.schema(checkins_schema).option(\"header\", True).csv(f\"{base_path}/checkins.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a0e72",
   "metadata": {},
   "source": [
    "# Transformations and Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edce6a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp, hour, dayofweek, when, col,count, avg\n",
    "\n",
    "checkins_clean = (\n",
    "    checkins_df\n",
    "    .filter(col(\"timestamp\").isNotNull())               # eliminamos si no tienen timestamp\n",
    "    .filter(col(\"duration_min\") > 0)                       # eliminar duraciones no valida en caso de que existan (cosa que no pasa porque nuestro generador solo genera duraciones de entre 15 y 120 mins)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc2fe5",
   "metadata": {},
   "source": [
    "## Comentario algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f25921",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkins_timedata = (\n",
    "    checkins_clean\n",
    "    .withColumn(\"hour\", hour(col(\"timestamp\")))\n",
    "    .withColumn(\"dayofweek\", dayofweek(col(\"timestamp\")))\n",
    ")\n",
    "\n",
    "checkins_timedata = checkins_timedata.dropDuplicates([\"checkin_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f875c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkins_full=checkins_timedata.join(gyms_df, on=\"gym_id\", how=\"left\").join(users_df, on=\"user_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4707da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_by_hour = (\n",
    "    checkins_full\n",
    "    .groupBy(\"gym_id\", \"name\", \"city\", \"hour\", \"equipment\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"checkin_count\"),\n",
    "        avg(\"duration_min\").alias(\"avg_duration_min\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1995d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----------+----+---------------+-------------+-----------------+\n",
      "|gym_id|     name|       city|hour|      equipment|checkin_count| avg_duration_min|\n",
      "+------+---------+-----------+----+---------------+-------------+-----------------+\n",
      "|    G9|Gym Fit 9|    Zapopan|   0|Stationary Bike|           14|             50.5|\n",
      "|    G9|Gym Fit 9|    Zapopan|   6|Stationary Bike|           11|60.72727272727273|\n",
      "|    G2|Gym Fit 2|Tlaquepaque|  20|   Lat Pulldown|            8|           67.875|\n",
      "|    G1|Gym Fit 1|Tlaquepaque|   8|      Treadmill|            6|             80.0|\n",
      "|    G2|Gym Fit 2|Tlaquepaque|   5|      Leg Press|            6|             61.0|\n",
      "+------+---------+-----------+----+---------------+-------------+-----------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "occupancy_by_hour.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5854cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_equipment = occupancy_by_hour.orderBy(col(\"checkin_count\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e6c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----------+----+----------+-------------+------------------+\n",
      "|gym_id|     name|       city|hour| equipment|checkin_count|  avg_duration_min|\n",
      "+------+---------+-----------+----+----------+-------------+------------------+\n",
      "|    G5|Gym Fit 5|Tlaquepaque|   0|Ab Machine|           11| 72.27272727272727|\n",
      "|    G9|Gym Fit 9|    Zapopan|   0|Ab Machine|           12|             69.25|\n",
      "|    G1|Gym Fit 1|Tlaquepaque|   0|Ab Machine|            9|50.111111111111114|\n",
      "|    G7|Gym Fit 7|Guadalajara|   0|Ab Machine|           10|              69.8|\n",
      "|    G4|Gym Fit 4|    Zapopan|   0|Ab Machine|           18|              67.5|\n",
      "+------+---------+-----------+----+----------+-------------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "occupancy_by_hour.orderBy(col(\"hour\"), col(\"equipment\")).show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68dfa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc61d130",
   "metadata": {},
   "source": [
    "# Persistence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_to_write = occupancy_by_hour.select(\n",
    "    \"gym_id\", \"name\", \"city\", \"hour\", \"equipment\", \"checkin_count\", \"avg_duration\"\n",
    ")\n",
    "occupancy_to_write = occupancy_to_write.withColumn(\"hour\", col(\"hour\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ef5f1",
   "metadata": {},
   "source": [
    "# DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6ff37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
