{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "\n",
    "#### <center> **Final Project: Batch Processing** </center>\n",
    "---\n",
    "\n",
    "**Date**: October, 2025\n",
    "\n",
    "**Student Name**: Luis Adrian Bravo Ramirez\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd2743",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5055b37",
   "metadata": {},
   "source": [
    "## Large-Scale Problem: Twitch Gamers Streaming Network Analysis\n",
    "\n",
    "The Twitch streaming platform generates massive amounts of relational data as millions of content creators interact through follows, collaborations, raids, and viewer sharing. Analyzing this network is essential for identifying influential streamers, detecting communities, understanding content trends, and monitoring platform health. However, the scale and complexity of these relationships make it challenging to process and query efficiently using traditional relational databases. A specialized data pipeline is needed to collect, store, and analyze this graph-structured data, enabling stakeholders to discover patterns, predict trends, and make data-driven decisions about partnerships, content strategy, and platform improvements.\n",
    "\n",
    "## Data Sample\n",
    "The Twitch Gamer network consists of two primary components\n",
    "*Streamer Nodes* - Individual Twitch accounts with properties.\n",
    "```bash\n",
    "numeric_id: 0\n",
    "views: 7879\n",
    "mature: 1 (contains mature content)\n",
    "life_time: 969 (days active)\n",
    "created_at: 2016-02-16\n",
    "updated_at: 2018-10-12\n",
    "dead_account: 0 (active)\n",
    "language: EN\n",
    "affiliate: 1 (Twitch affiliate)\n",
    "```\n",
    "\n",
    "*Connection Edges* - Relationships between streamers.\n",
    "```bash\n",
    "numeric_id_1: 98343 (source streamer)\n",
    "numeric_id_2: 141493 (target streamer)\n",
    "(represents a connection/follow from streamer 98343 to streamer 141493)\n",
    "```\n",
    "\n",
    " More detail regarding the Twitch Gamers network can be seen on Dataset section.\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1757b962",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4f167",
   "metadata": {},
   "source": [
    "## Data Model: Graph Data Model (Neo4j)\n",
    "\n",
    "This pipeline uses a **Graph Data Model** implemented in **Neo4j**, which is ideal for representing and querying relationships between entities. The dataset consists of nodes and relationships that form a social network graph, specifically for twitch gamers network. \n",
    "\n",
    "### Why Neo4j?\n",
    "\n",
    "The Neo4j property graph model is ideal for this dataset because:\n",
    "1. **Cypher Query Language:** Intuitive pattern-matching syntax for complex relationship queries\n",
    "2. **Index Support:** Automatic indexing on node IDs and custom indexes for properties\n",
    "3. **Network Analysis:** Built-in algorithms for Network Analysis (Community, Pathfinding and more).\n",
    "4. **Scalability:** Handles millions of nodes and relationships\n",
    "5. **Visualization:** Neo4j Browser provides interactive graph visualization\n",
    "6. **Knowledge**: I've worked with Neo4j for a long time, so I'm well experienced with this NoSQL database.\n",
    "\n",
    "## Node Schema\n",
    "\n",
    "Nodes represent individual accounts/users in the network with the following properties:\n",
    "\n",
    "| Property | Data Type | Description |\n",
    "|----------|-----------|-------------|\n",
    "| `numeric_id` | Integer | Unique identifier for the node |\n",
    "| `views` | Integer | Number of views on the account |\n",
    "| `mature` | Boolean | Indicates if account contains mature content (0 for NO, 1 for YES) |\n",
    "| `life_time` | Integer | Account lifetime in days |\n",
    "| `created_at` | Date | Account creation date (YYYY-MM-DD format) |\n",
    "| `updated_at` | Date | Last update date (YYYY-MM-DD format) |\n",
    "| `dead_account` | Boolean | Indicates if account is inactive (0 for NO, 1 for YES) |\n",
    "| `language` | String | Account language (English, Deutsch, Other) |\n",
    "| `affiliate` | Boolean | Indicates if account is affiliated (0 for NO, 1 for YES) |\n",
    "\n",
    "### Example Node\n",
    "```cypher\n",
    "(:Account {\n",
    "  numeric_id: 0,\n",
    "  views: 7879,\n",
    "  mature: true,\n",
    "  life_time: 969,\n",
    "  created_at: date('2016-02-16'),\n",
    "  updated_at: date('2018-10-12'),\n",
    "  dead_account: false,\n",
    "  language: 'English',\n",
    "  affiliate: true\n",
    "})\n",
    "```\n",
    "\n",
    "## Relationship Schema\n",
    "\n",
    "Relationships represent connections between nodes in the network.\n",
    "\n",
    "| Property | Data Type | Description |\n",
    "|----------|-----------|-------------|\n",
    "| `numeric_id_1` | Integer | Source node ID |\n",
    "| `numeric_id_2` | Integer | Target node ID |\n",
    "\n",
    "### Relationship Type\n",
    "- **Type:** `FOLLOWS` \n",
    "- **Direction:** Directed (from numeric_id_1 to numeric_id_2)\n",
    "- **Properties:** None\n",
    "\n",
    "\n",
    "## Dataset Source\n",
    "**Source:** Kaggle Public Repository\n",
    "**Dataset URL:** [https://www.kaggle.com/datasets/wolfram77/graphs-social]\n",
    "\n",
    "**Data Format:**\n",
    "- **Nodes File:** CSV format with 9 columns\n",
    "- **Edges File:** CSV format with 2 columns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a0e72",
   "metadata": {},
   "source": [
    "# Transformations and Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908918d",
   "metadata": {},
   "source": [
    "Here, the transformations (create new columns, aggreate, run joins, etc.) will take place. For this case, we'll execute the following:\n",
    "\n",
    "1. Remove duplicates using `numeric_id` entries and clean null values (if they exist).\n",
    "\n",
    "2. Convert `mature`, `dead_account`and `affiliate` from interger (0 or 1) to a boolean type (true or false).\n",
    "\n",
    "3. Parse `created_at`and `updated_at` string into date objects.\n",
    "\n",
    "4. Make sure that `numeric_id`, `views`, and `life_time` are integers.\n",
    "\n",
    "5. Add a column called `activity_status` that will categorize the account activity with these values:\n",
    "    - \"Very Active\" (updated within 30 days)\n",
    "    - \"Active\" (within 90 days)\n",
    "    - \"Less Active\" (within 180 days)\n",
    "    - \"Inactive\" (no activity)\n",
    "\n",
    "6. Add a column called `account_category` that will classify the account based on views:\n",
    "    - \"Nano\": views < 1,000 (New or very small streamers)\n",
    "    - \"Micro\": 1,000 ≤ views < 10,000 (Small but growing audience)\n",
    "    - \"Mid-Tier\": 10,000 ≤ views < 50,000 (Established presence)\n",
    "    - \"Macro\": 50,000 ≤ views < 100,000 (Significant reach)\n",
    "    - \"Mega\": 100,000 ≤ views < 500,000 (High influence)\n",
    "    - \"Elite\": views ≥ 500,000 (Top-tier streamers)\n",
    "\n",
    "7. Trim whitespace from all string fields to avoid any future issues with these fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9c352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the PySpark Installation\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8facbc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /root/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /root/.ivy2.5.2/jars\n",
      "org.neo4j#neo4j-connector-apache-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-dffd3865-a9a1-40a9-90e8-ff01954436d0;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.13;5.3.10_for_spark_3 in central\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.13_common;5.3.10_for_spark_3 in central\n",
      "\tfound org.neo4j#caniuse-core;1.3.0 in central\n",
      "\tfound org.neo4j#caniuse-api;1.3.0 in central\n",
      "\tfound org.jetbrains.kotlin#kotlin-stdlib;2.1.20 in central\n",
      "\tfound org.jetbrains#annotations;13.0 in central\n",
      "\tfound org.neo4j#caniuse-neo4j-detection;1.3.0 in central\n",
      "\tfound org.neo4j.driver#neo4j-java-driver-slim;4.4.21 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.4 in central\n",
      "\tfound io.netty#netty-handler;4.1.127.Final in central\n",
      "\tfound io.netty#netty-common;4.1.127.Final in central\n",
      "\tfound io.netty#netty-resolver;4.1.127.Final in central\n",
      "\tfound io.netty#netty-buffer;4.1.127.Final in central\n",
      "\tfound io.netty#netty-transport;4.1.127.Final in central\n",
      "\tfound io.netty#netty-transport-native-unix-common;4.1.127.Final in central\n",
      "\tfound io.netty#netty-codec;4.1.127.Final in central\n",
      "\tfound io.netty#netty-tcnative-classes;2.0.73.Final in central\n",
      "\tfound io.projectreactor#reactor-core;3.6.11 in central\n",
      "\tfound org.neo4j#neo4j-cypher-dsl;2022.11.0 in central\n",
      "\tfound org.apiguardian#apiguardian-api;1.1.2 in central\n",
      "\tfound org.neo4j.connectors#commons-authn-spi;1.0.0-rc2 in central\n",
      "\tfound org.neo4j.connectors#commons-reauth-driver;1.0.0-rc2 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.17 in central\n",
      "\tfound org.neo4j.connectors#commons-authn-provided;1.0.0-rc2 in central\n",
      ":: resolution report :: resolve 833ms :: artifacts dl 24ms\n",
      "\t:: modules in use:\n",
      "\tio.netty#netty-buffer;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-codec;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-common;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-handler;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-resolver;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-tcnative-classes;2.0.73.Final from central in [default]\n",
      "\tio.netty#netty-transport;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-unix-common;4.1.127.Final from central in [default]\n",
      "\tio.projectreactor#reactor-core;3.6.11 from central in [default]\n",
      "\torg.apiguardian#apiguardian-api;1.1.2 from central in [default]\n",
      "\torg.jetbrains#annotations;13.0 from central in [default]\n",
      "\torg.jetbrains.kotlin#kotlin-stdlib;2.1.20 from central in [default]\n",
      "\torg.neo4j#caniuse-api;1.3.0 from central in [default]\n",
      "\torg.neo4j#caniuse-core;1.3.0 from central in [default]\n",
      "\torg.neo4j#caniuse-neo4j-detection;1.3.0 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.13;5.3.10_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.13_common;5.3.10_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-cypher-dsl;2022.11.0 from central in [default]\n",
      "\torg.neo4j.connectors#commons-authn-provided;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.connectors#commons-authn-spi;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.connectors#commons-reauth-driver;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.driver#neo4j-java-driver-slim;4.4.21 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.4 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.17 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   24  |   0   |   0   |   0   ||   24  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-dffd3865-a9a1-40a9-90e8-ff01954436d0\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 24 already retrieved (0kB/18ms)\n",
      "25/10/18 16:07:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Create Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Examples on SparkSQL\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.neo4j:neo4j-connector-apache-spark_2.13:5.3.10_for_spark_3\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9448c397",
   "metadata": {},
   "source": [
    "### Define the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c8de63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from luisbravor00.spark_utils import SparkUtils\n",
    "\n",
    "twitch_nodes_schema_columns = [\n",
    "    (\"views\", \"int\"),\n",
    "    (\"mature\", \"int\"),\n",
    "    (\"life_time\", \"int\"),\n",
    "    (\"created_at\", \"string\"),\n",
    "    (\"updated_at\", \"string\"),\n",
    "    (\"numeric_id\", \"int\"),\n",
    "    (\"dead_account\", \"int\"),\n",
    "    (\"language\", \"string\"),\n",
    "    (\"affiliate\", \"int\")\n",
    "]\n",
    "\n",
    "twitch_edges_schema_columns = [\n",
    "    (\"source_account\", \"int\"),\n",
    "    (\"target_account\", \"int\")\n",
    "]\n",
    "\n",
    "twitch_nodes_schema = SparkUtils.generate_schema(twitch_nodes_schema_columns)\n",
    "twitch_edges_schema = SparkUtils.generate_schema(twitch_edges_schema_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2300314",
   "metadata": {},
   "source": [
    "### Load CSV files (Nodes and Edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7df1e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and save the csv file for the nodes\n",
    "df_nodes = spark.read \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .schema(twitch_nodes_schema) \\\n",
    "                .csv(\"/opt/spark/work-dir/data/twitch_gamers/large_twitch_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89998b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and save the csv file for the edges\n",
    "df_edges = spark.read \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .schema(twitch_edges_schema) \\\n",
    "                .csv(\"/opt/spark/work-dir/data/twitch_gamers/large_twitch_edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1732c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "| views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|\n",
      "+------+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "|  7879|     1|      969|2016-02-16|2018-10-12|         0|           0|      EN|        1|\n",
      "|   500|     0|     2699|2011-05-19|2018-10-08|         1|           0|      EN|        0|\n",
      "|382502|     1|     3149|2010-02-27|2018-10-12|         2|           0|      EN|        1|\n",
      "|   386|     0|     1344|2015-01-26|2018-10-01|         3|           0|      EN|        0|\n",
      "|  2486|     0|     1784|2013-11-22|2018-10-11|         4|           0|      EN|        0|\n",
      "+------+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_nodes.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1075067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|source_account|target_account|\n",
      "+--------------+--------------+\n",
      "|         98343|        141493|\n",
      "|         98343|         58736|\n",
      "|         98343|        140703|\n",
      "|         98343|        151401|\n",
      "|         98343|        157118|\n",
      "+--------------+--------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_edges.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a4264",
   "metadata": {},
   "source": [
    "### Start with transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "639a50ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, trim, when, isnull, count, to_date, max, datediff, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09c018b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records before cleaning: 168114\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "|views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "|    0|     0|        0|         0|         0|         0|           0|       0|        0|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of records after cleaning with trim & dropna: 168114\n",
      "\n",
      "+------+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "| views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|\n",
      "+------+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "|   500|     0|     2699|2011-05-19|2018-10-08|         1|           0|      EN|        0|\n",
      "|   386|     0|     1344|2015-01-26|2018-10-01|         3|           0|      EN|        0|\n",
      "|  4987|     1|     1288|2015-04-03|2018-10-12|         5|           0|      EN|        1|\n",
      "|   234|     0|      358|2017-09-14|2018-09-07|         6|           0|      EN|        0|\n",
      "| 32073|     0|      499|2017-05-31|2018-10-12|         9|           0|      KO|        1|\n",
      "|  2178|     0|      908|2016-04-16|2018-10-11|        12|           0|      JA|        0|\n",
      "|  4871|     0|      449|2017-07-19|2018-10-11|        13|           0|      EN|        0|\n",
      "| 33882|     1|     2134|2012-12-08|2018-10-12|        15|           0|      EN|        1|\n",
      "|   200|     0|      324|2017-10-21|2018-09-10|        16|           0|      EN|        0|\n",
      "| 11624|     1|     2299|2012-06-15|2018-10-01|        17|           0|      EN|        0|\n",
      "|144812|     1|     2175|2012-10-28|2018-10-12|        19|           0|      EN|        1|\n",
      "|  1885|     1|     2273|2012-07-21|2018-10-11|        20|           0|      EN|        1|\n",
      "|212680|     1|     2056|2013-02-24|2018-10-12|        22|           0|      PL|        0|\n",
      "|  9528|     0|     1459|2014-10-14|2018-10-12|        26|           0|      EN|        1|\n",
      "|  2802|     1|     1931|2013-06-29|2018-10-12|        27|           0|      EN|        0|\n",
      "|162078|     1|     2149|2012-11-23|2018-10-12|        28|           0|      DE|        1|\n",
      "|  4405|     0|     1522|2014-08-08|2018-10-08|        31|           0|      ES|        1|\n",
      "| 17042|     1|      961|2016-02-23|2018-10-11|        34|           0|      IT|        1|\n",
      "|  2559|     0|     2066|2013-01-21|2018-09-18|        35|           0|      EN|        0|\n",
      "|  8231|     0|     1648|2014-04-03|2018-10-07|        37|           0|      EN|        1|\n",
      "+------+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Remove duplicates using numeric_id and clean null values\n",
    "\n",
    "print(f\"Number of records before cleaning: {df_nodes.count()}\")\n",
    "df_nodes.select([count(when(isnull(c[0]) | col(c[0]).isNull(), c[0])).alias(c[0]) for c in twitch_nodes_schema_columns]).show()\n",
    "\n",
    "# Perform data cleaning with trim (column by column)\n",
    "df_nodes_clean = df_nodes \\\n",
    "        .dropDuplicates([\"numeric_id\"]) \\\n",
    "        .filter(col(\"numeric_id\").isNotNull()) \\\n",
    "        .filter(col(\"views\").isNotNull()) \\\n",
    "        .filter(col(\"mature\").isNotNull()) \\\n",
    "        .filter(col(\"life_time\").isNotNull()) \\\n",
    "        .filter(col(\"dead_account\").isNotNull()) \\\n",
    "        .filter(col(\"affiliate\").isNotNull()) \\\n",
    "        .withColumn(\"created_at\", trim(\"created_at\")) \\\n",
    "        .withColumn(\"updated_at\", trim(\"updated_at\")) \\\n",
    "        .withColumn(\"language\", trim(\"language\")) \\\n",
    "\n",
    "# Perform data cleaning with dropna (make sure that it erases null values)\n",
    "df_nodes_clean = df_nodes_clean.dropna()\n",
    "print(f\"\\nNumber of records after cleaning with trim & dropna: {df_nodes_clean.count()}\\n\")\n",
    "\n",
    "df_nodes_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54f3cdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "|views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "|  500| false|     2699|2011-05-19|2018-10-08|         1|       false|      EN|    false|\n",
      "|  386| false|     1344|2015-01-26|2018-10-01|         3|       false|      EN|    false|\n",
      "| 4987|  true|     1288|2015-04-03|2018-10-12|         5|       false|      EN|     true|\n",
      "|  234| false|      358|2017-09-14|2018-09-07|         6|       false|      EN|    false|\n",
      "|32073| false|      499|2017-05-31|2018-10-12|         9|       false|      KO|     true|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert mature, dead_account and affiliate from integer to boolean\n",
    "df_nodes_clean = df_nodes_clean \\\n",
    "    .withColumn(\"mature\", col(\"mature\").cast(\"boolean\")) \\\n",
    "    .withColumn(\"dead_account\", col(\"dead_account\").cast(\"boolean\")) \\\n",
    "    .withColumn(\"affiliate\", col(\"affiliate\").cast(\"boolean\"))\n",
    "\n",
    "df_nodes_clean.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "144b8584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- views: integer (nullable = true)\n",
      " |-- mature: boolean (nullable = true)\n",
      " |-- life_time: integer (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- updated_at: string (nullable = true)\n",
      " |-- numeric_id: integer (nullable = true)\n",
      " |-- dead_account: boolean (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- affiliate: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_nodes_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eee9bfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- views: integer (nullable = true)\n",
      " |-- mature: boolean (nullable = true)\n",
      " |-- life_time: integer (nullable = true)\n",
      " |-- created_at: date (nullable = true)\n",
      " |-- updated_at: date (nullable = true)\n",
      " |-- numeric_id: integer (nullable = true)\n",
      " |-- dead_account: boolean (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- affiliate: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parse created_at and updated_at string values into date objects\n",
    "df_nodes_clean = df_nodes_clean \\\n",
    "    .withColumn(\"created_at\", to_date(\"created_at\")) \\\n",
    "    .withColumn(\"updated_at\", to_date(\"updated_at\"))\n",
    "\n",
    "df_nodes_clean.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9b273",
   "metadata": {},
   "source": [
    "* Already checked that `numeric_id`, `views` and `life_time` fields are **integers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d8689cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a columns called activity status that will categorize the account activity using the updated_at field\n",
    "\n",
    "## Get the latest date from the updated_at column so we can use it as current date\n",
    "max_date = df_nodes_clean.select(max(col(\"updated_at\")).alias(\"max_date\")).collect()[0][\"max_date\"]\n",
    "\n",
    "## Add the new column activity_status and compute it's values\n",
    "df_nodes_clean = df_nodes_clean.withColumn(\n",
    "    \"activity_status\",\n",
    "    when(datediff(lit(max_date), col(\"updated_at\")) <= 30, \"Very Active\")\n",
    "    .when(datediff(lit(max_date), col(\"updated_at\")) <= 90, \"Active\")\n",
    "    .when(datediff(lit(max_date), col(\"updated_at\")) <= 180, \"Less Active\")\n",
    "    .otherwise(\"Inactive\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "392e0717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|activity_status|account_category|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|  500| false|     2699|2011-05-19|2018-10-08|         1|       false|      EN|    false|    Very Active|            Nano|\n",
      "|  386| false|     1344|2015-01-26|2018-10-01|         3|       false|      EN|    false|    Very Active|            Nano|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "only showing top 2 rows\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|activity_status|account_category|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|  234| false|      358|2017-09-14|2018-09-07|         6|       false|      EN|    false|         Active|            Nano|\n",
      "|  200| false|      324|2017-10-21|2018-09-10|        16|       false|      EN|    false|         Active|            Nano|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|activity_status|account_category|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|  180| false|     1324|2014-10-31|2018-06-16|       257|        true|      EN|    false|    Less Active|            Nano|\n",
      "|  771|  true|     2494|2011-08-31|2018-06-29|       436|        true|      EN|    false|    Less Active|            Nano|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "only showing top 2 rows\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|activity_status|account_category|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|   29| false|     1432|2014-02-12|2018-01-14|       476|        true|   OTHER|    false|       Inactive|            Nano|\n",
      "|   14| false|      579|2016-06-27|2018-01-27|       544|        true|      EN|    false|       Inactive|            Nano|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nodes_clean.filter(col(\"activity_status\") == \"Very Active\").show(n=2)\n",
    "df_nodes_clean.filter(col(\"activity_status\") == \"Active\").show(n=2)\n",
    "df_nodes_clean.filter(col(\"activity_status\") == \"Less Active\").show(n=2)\n",
    "df_nodes_clean.filter(col(\"activity_status\") == \"Inactive\").show(n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "668c5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column called account_category that will classify the account based on views column\n",
    "df_nodes_clean = df_nodes_clean.withColumn(\n",
    "    \"account_category\",\n",
    "    when(col(\"views\") < 1000, \"Starter\")\n",
    "    .when((col(\"views\") >= 1000) & (col(\"views\") < 10000), \"Emerging\")\n",
    "    .when((col(\"views\") >= 10000) & (col(\"views\") < 50000), \"Established\")\n",
    "    .when((col(\"views\") >= 50000) & (col(\"views\") < 100000), \"Popular\")\n",
    "    .when((col(\"views\") >= 100000) & (col(\"views\") < 500000), \"Star\")\n",
    "    .otherwise(\"Legend\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9d9c5c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|activity_status|account_category|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|  500| false|     2699|2011-05-19|2018-10-08|         1|       false|      EN|    false|    Very Active|         Starter|\n",
      "|  386| false|     1344|2015-01-26|2018-10-01|         3|       false|      EN|    false|    Very Active|         Starter|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "only showing top 2 rows\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|activity_status|account_category|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "| 4987|  true|     1288|2015-04-03|2018-10-12|         5|       false|      EN|     true|    Very Active|        Emerging|\n",
      "| 2178| false|      908|2016-04-16|2018-10-11|        12|       false|      JA|    false|    Very Active|        Emerging|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|activity_status|account_category|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|32073| false|      499|2017-05-31|2018-10-12|         9|       false|      KO|     true|    Very Active|     Established|\n",
      "|33882|  true|     2134|2012-12-08|2018-10-12|        15|       false|      EN|     true|    Very Active|     Established|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "only showing top 2 rows\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|activity_status|account_category|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|77565| false|     2456|2012-01-16|2018-10-07|        81|       false|      EN|     true|    Very Active|         Popular|\n",
      "|60918| false|     1729|2014-01-17|2018-10-12|       126|       false|      PL|     true|    Very Active|         Popular|\n",
      "+-----+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "only showing top 2 rows\n",
      "+------+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "| views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|activity_status|account_category|\n",
      "+------+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|144812|  true|     2175|2012-10-28|2018-10-12|        19|       false|      EN|     true|    Very Active|            Star|\n",
      "|212680|  true|     2056|2013-02-24|2018-10-12|        22|       false|      PL|    false|    Very Active|            Star|\n",
      "+------+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "only showing top 2 rows\n",
      "+-------+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|  views|mature|life_time|created_at|updated_at|numeric_id|dead_account|language|affiliate|activity_status|account_category|\n",
      "+-------+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "|1974604|  true|      631|2017-01-19|2018-10-12|        85|       false|      EN|    false|    Very Active|          Legend|\n",
      "|1971793| false|     1477|2014-09-26|2018-10-12|       117|       false|      EN|    false|    Very Active|          Legend|\n",
      "+-------+------+---------+----------+----------+----------+------------+--------+---------+---------------+----------------+\n",
      "only showing top 2 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_nodes_clean.filter(col(\"account_category\") == \"Starter\").show(n=2)\n",
    "df_nodes_clean.filter(col(\"account_category\") == \"Emerging\").show(n=2)\n",
    "df_nodes_clean.filter(col(\"account_category\") == \"Established\").show(n=2)\n",
    "df_nodes_clean.filter(col(\"account_category\") == \"Popular\").show(n=2)\n",
    "df_nodes_clean.filter(col(\"account_category\") == \"Star\").show(n=2)\n",
    "df_nodes_clean.filter(col(\"account_category\") == \"Legend\").show(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b922311",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc61d130",
   "metadata": {},
   "source": [
    "# Persistence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a07fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1639f16",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ef5f1",
   "metadata": {},
   "source": [
    "# DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967e5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ef44bc8",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
