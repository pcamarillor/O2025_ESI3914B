{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "\n",
    "#### <center> **Final Project: Batch Processing** </center>\n",
    "---\n",
    "\n",
    "**Date**: October, 2025\n",
    "\n",
    "**Student Name**: Regalado Floriano Luis A.\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1757b962",
   "metadata": {},
   "source": [
    "# Machine Learning algorithm to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea76579-7ace-4f08-bb92-cffafa0076de",
   "metadata": {},
   "source": [
    "Since we will be using, https://www.kaggle.com/datasets/mohankrishnathalla/global-house-purchase-decision-dataset , the most appropriate machine learning algorithm to use would be that of Support Vector Machines, since we would like to predict whether a house will be bought or not from factors such as the region and the kind of house. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a3589d-8519-4f0d-9241-9554eb45714a",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a573eed-95fd-48cd-87e4-53b75862eaf8",
   "metadata": {},
   "source": [
    "The Dataset is https://www.kaggle.com/datasets/mohankrishnathalla/global-house-purchase-decision-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1614de-8c2a-4c6c-b796-eb4f80235ef1",
   "metadata": {},
   "source": [
    "Size of the dataset:\n",
    "    The Dataset is composed of  200,000  entries, with 25 columns each\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db84676-749e-4f82-9239-c90556d3a577",
   "metadata": {},
   "source": [
    "As it will be seen, the dataset is balanced in all of it's country, bar each houses's price, as well as it's city, which is to be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48168cce-862f-405d-904e-2e1ba3a1c4df",
   "metadata": {},
   "source": [
    "Nonetheless, cities tend to be balanced within their own country."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a15b0a-05de-4e81-8b5b-fd33bcfbc694",
   "metadata": {},
   "source": [
    "We will  be training the model on the city the house is in, it's type, furbishing status, size, attributes, legal status, and, of course, price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da11abc-91d5-47ac-9a77-7e97dad1328e",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1ad0bb-bc66-4c0f-99ca-8b79aa2689cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "25/11/22 01:23:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ML: Logistic Regression\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/work-dir/jars/postgresql-42.7.8.jar\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"INFO\")\n",
    "\n",
    "# Optimization (reduce the number of shuffle partitions)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d7fd64-cccd-4157-88c9-84ba1705e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regalado_floriano.spark_utils import SparkUtils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7477f2-5f47-470e-af84-e9a3a69e355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_schema = SparkUtils.generate_schema(\n",
    " \n",
    "    ((\"property_id\",\"int\"),\n",
    "(\"country\",\"string\"),\n",
    "(\"city\",\"string\"),\n",
    "(\"property_type\",\"string\"),\n",
    "(\"furnishing_status\",\"string\"),\n",
    "(\"property_size_sqft\",\"int\"),\n",
    "(\"price\",\"int\"),\n",
    "(\"constructed_year\",\"int\"),\n",
    "(\"previous_owners\",\"int\"),\n",
    "(\"rooms\",\"int\"),\n",
    "(\"bathrooms\",\"int\"),\n",
    "(\"garage\",\"bool\"),\n",
    "(\"garden\",\"bool\"),\n",
    "(\"crime_cases_reported\",\"int\"),\n",
    "(\"legal_cases_on_property\",\"bool\"),\n",
    "(\"customer_salary\",\"int\"),\n",
    "(\"loan_amount\",\"int\"),\n",
    "(\"loan_tenure_years\",\"int\"),\n",
    "(\"monthly_expenses\",\"int\"),\n",
    "(\"down_payment\",\"int\"),\n",
    "(\"emi_to_income_ratio\",\"float\"),\n",
    "(\"satisfaction_score\",\"int\"),\n",
    "(\"neighbourhood_rating\",\"int\"),\n",
    "(\"connectivity_score\",\"int\"),\n",
    "(\"decision\",\"bool\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74428443-4d9c-45e3-b308-f70d912087ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df = spark.read \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .schema(houses_schema) \\\n",
    "                .csv(\"/opt/spark/work-dir/data/house_purchases\")\n",
    "house_df= house_df.na.fill({\"country\":\"unknown\"})\n",
    "house_df= house_df.na.fill(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c21b1c7f-dbf5-4dd9-843b-4f3ff37c8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean as _mean, stddev as _stddev, col\n",
    "from pyspark.sql.functions import when, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f6fb10b-81fe-4d47-b564-c4bdda1903cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_count = house_df.groupBy(\"country\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "730f0390-8c19-4d08-8f1b-126e3b92b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = \"France,USA,Singapore,Japan,Canada,Australia,Germany,Brazil,UK,South Africa,UAE,China,India\".split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d51157-3236-4e4a-b9b5-a3310fc53eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8de2977f-f8ba-4d86-851e-64a17f368051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------------+\n",
      "|summary| city|             count|\n",
      "+-------+-----+------------------+\n",
      "|  count|    3|                 3|\n",
      "|   mean| NULL| 5209.333333333333|\n",
      "| stddev| NULL|124.34360994169879|\n",
      "|    min| Lyon|              5080|\n",
      "|    max|Paris|              5328|\n",
      "+-------+-----+------------------+\n",
      "\n",
      "+-------+-------------+-----------------+\n",
      "|summary|         city|            count|\n",
      "+-------+-------------+-----------------+\n",
      "|  count|            5|                5|\n",
      "|   mean|         NULL|           3056.2|\n",
      "| stddev|         NULL|52.46617958266067|\n",
      "|    min|      Chicago|             2999|\n",
      "|    max|San Francisco|             3107|\n",
      "+-------+-------------+-----------------+\n",
      "\n",
      "+-------+---------+-------+\n",
      "|summary|     city|  count|\n",
      "+-------+---------+-------+\n",
      "|  count|        1|      1|\n",
      "|   mean|     NULL|15278.0|\n",
      "| stddev|     NULL|   NULL|\n",
      "|    min|Singapore|  15278|\n",
      "|    max|Singapore|  15278|\n",
      "+-------+---------+-------+\n",
      "\n",
      "+-------+-----+-----------------+\n",
      "|summary| city|            count|\n",
      "+-------+-----+-----------------+\n",
      "|  count|    3|                3|\n",
      "|   mean| NULL|5105.666666666667|\n",
      "| stddev| NULL|72.07172353519329|\n",
      "|    min|Kyoto|             5054|\n",
      "|    max|Tokyo|             5188|\n",
      "+-------+-----+-----------------+\n",
      "\n",
      "+-------+---------+-----------------+\n",
      "|summary|     city|            count|\n",
      "+-------+---------+-----------------+\n",
      "|  count|        3|                3|\n",
      "|   mean|     NULL|5133.666666666667|\n",
      "| stddev|     NULL|71.02347029914361|\n",
      "|    min| Montreal|             5076|\n",
      "|    max|Vancouver|             5213|\n",
      "+-------+---------+-----------------+\n",
      "\n",
      "+-------+--------+------------------+\n",
      "|summary|    city|             count|\n",
      "+-------+--------+------------------+\n",
      "|  count|       3|                 3|\n",
      "|   mean|    NULL| 5147.333333333333|\n",
      "| stddev|    NULL|139.07671743801453|\n",
      "|    min|Brisbane|              5011|\n",
      "|    max|  Sydney|              5289|\n",
      "+-------+--------+------------------+\n",
      "\n",
      "+-------+------+-----------------+\n",
      "|summary|  city|            count|\n",
      "+-------+------+-----------------+\n",
      "|  count|     3|                3|\n",
      "|   mean|  NULL|           5136.0|\n",
      "| stddev|  NULL|96.90717207719973|\n",
      "|    min|Berlin|             5050|\n",
      "|    max|Munich|             5241|\n",
      "+-------+------+-----------------+\n",
      "\n",
      "+-------+--------------+-----------------+\n",
      "|summary|          city|            count|\n",
      "+-------+--------------+-----------------+\n",
      "|  count|             2|                2|\n",
      "|   mean|          NULL|           7698.5|\n",
      "| stddev|          NULL|79.90306627407988|\n",
      "|    min|Rio de Janeiro|             7642|\n",
      "|    max|     São Paulo|             7755|\n",
      "+-------+--------------+-----------------+\n",
      "\n",
      "+-------+----------+-----------------+\n",
      "|summary|      city|            count|\n",
      "+-------+----------+-----------------+\n",
      "|  count|         4|                4|\n",
      "|   mean|      NULL|          3853.25|\n",
      "| stddev|      NULL|60.98292110637759|\n",
      "|    min|Birmingham|             3793|\n",
      "|    max|Manchester|             3935|\n",
      "+-------+----------+-----------------+\n",
      "\n",
      "+-------+------------+------------------+\n",
      "|summary|        city|             count|\n",
      "+-------+------------+------------------+\n",
      "|  count|           2|                 2|\n",
      "|   mean|        NULL|            7700.5|\n",
      "| stddev|        NULL|16.263455967290593|\n",
      "|    min|   Cape Town|              7689|\n",
      "|    max|Johannesburg|              7712|\n",
      "+-------+------------+------------------+\n",
      "\n",
      "+-------+---------+-----------------+\n",
      "|summary|     city|            count|\n",
      "+-------+---------+-----------------+\n",
      "|  count|        2|                2|\n",
      "|   mean|     NULL|           7570.5|\n",
      "| stddev|     NULL|94.04520189781083|\n",
      "|    min|Abu Dhabi|             7504|\n",
      "|    max|    Dubai|             7637|\n",
      "+-------+---------+-----------------+\n",
      "\n",
      "+-------+--------+------------------+\n",
      "|summary|    city|             count|\n",
      "+-------+--------+------------------+\n",
      "|  count|       3|                 3|\n",
      "|   mean|    NULL| 5178.666666666667|\n",
      "| stddev|    NULL|166.58431298694765|\n",
      "|    min| Beijing|              4999|\n",
      "|    max|Shenzhen|              5328|\n",
      "+-------+--------+------------------+\n",
      "\n",
      "+-------+---------+------------------+\n",
      "|summary|     city|             count|\n",
      "+-------+---------+------------------+\n",
      "|  count|        6|                 6|\n",
      "|   mean|     NULL|            2559.5|\n",
      "| stddev|     NULL|29.984996248123778|\n",
      "|    min|Bangalore|              2510|\n",
      "|    max|     Pune|              2583|\n",
      "+-------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for country in countries:\n",
    "    toGroup = house_df.filter(col(\"country\")==country)\n",
    "    grouped_country = toGroup.groupBy(\"city\").count() \n",
    "    grouped_country.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7becbe7e-ff66-44f9-af8b-abf1fb496b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = \"country city property_type furnishing_status\".split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3028211-a787-4068-8746-2141e2a3eb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------+\n",
      "|summary|  country|             count|\n",
      "+-------+---------+------------------+\n",
      "|  count|       13|                13|\n",
      "|   mean|     NULL|15384.615384615385|\n",
      "| stddev|     NULL|120.51109109506515|\n",
      "|    min|Australia|             15141|\n",
      "|    max|      USA|             15628|\n",
      "+-------+---------+------------------+\n",
      "\n",
      "+-------+---------+------------------+\n",
      "|summary|     city|             count|\n",
      "+-------+---------+------------------+\n",
      "|  count|       40|                40|\n",
      "|   mean|     NULL|            5000.0|\n",
      "| stddev|     NULL|2312.3473587876692|\n",
      "|    min|Abu Dhabi|              2510|\n",
      "|    max|Vancouver|             15278|\n",
      "+-------+---------+------------------+\n",
      "\n",
      "+-------+-------------+------------------+\n",
      "|summary|property_type|             count|\n",
      "+-------+-------------+------------------+\n",
      "|  count|            6|                 6|\n",
      "|   mean|         NULL|33333.333333333336|\n",
      "| stddev|         NULL| 172.1135284243126|\n",
      "|    min|    Apartment|             33008|\n",
      "|    max|        Villa|             33518|\n",
      "+-------+-------------+------------------+\n",
      "\n",
      "+-------+-----------------+------------------+\n",
      "|summary|furnishing_status|             count|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|                3|                 3|\n",
      "|   mean|             NULL| 66666.66666666667|\n",
      "| stddev|             NULL|165.59086126152414|\n",
      "|    min|  Fully-Furnished|             66498|\n",
      "|    max|      Unfurnished|             66829|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cat in categories:\n",
    "    to_describe = house_df.groupBy(cat).count()\n",
    "    to_describe.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a0e72",
   "metadata": {},
   "source": [
    "# ML Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aebd82-8491-4a6d-aaec-d8e5e653cb82",
   "metadata": {},
   "source": [
    "We will  be training the model on the city the house is in, it's type, furbishing status, size, attributes, legal status, and, of course, price.\n",
    "However, many of those values are strings. We will therefore be encoding each of these as ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b1caa6b-44e7-424e-9b29-ae79590289a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "house_df= house_df.na.fill(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "12156db6-e7c6-4d14-bb87-066297deed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=\"country,city,property_type,furnishing_status,property_size_sqft,price,constructed_year,previous_owners,rooms,bathrooms,garage,garden,crime_cases_reported,legal_cases_on_property,neighbourhood_rating\".split(\",\")\n",
    "categorical_features=\"country,city,property_type,furnishing_status\".split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0281ed-7de2-4197-b876-767b1cebd01b",
   "metadata": {},
   "source": [
    "## Transformation 1: Creating unique ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c28ce741-2280-47cb-b298-e91789c56c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to prepare for ease of analysis, all categorical data will be put in it's own frame. That is to say, each country and city will get \n",
    "# their own id\n",
    "_localMap = SparkUtils.generate_keyed_distinct_column(house_df)\n",
    "\n",
    "categoricalTables =   {\n",
    "     key:     _localMap(key) for key in categorical_features\n",
    " }\n",
    "\n",
    "id_house = house_df\n",
    "for cat in categorical_features:\n",
    "    cur_df = categoricalTables[cat]\n",
    "    id_house = SparkUtils.replace_column_for_key(id_house)(cur_df)(cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d14171c4-a28c-4017-b98d-348ec87c7343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- property_id: integer (nullable = true)\n",
      " |-- property_size_sqft: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- constructed_year: integer (nullable = true)\n",
      " |-- previous_owners: integer (nullable = true)\n",
      " |-- rooms: integer (nullable = true)\n",
      " |-- bathrooms: integer (nullable = true)\n",
      " |-- garage: boolean (nullable = false)\n",
      " |-- garden: boolean (nullable = false)\n",
      " |-- crime_cases_reported: integer (nullable = true)\n",
      " |-- legal_cases_on_property: boolean (nullable = false)\n",
      " |-- customer_salary: integer (nullable = true)\n",
      " |-- loan_amount: integer (nullable = true)\n",
      " |-- loan_tenure_years: integer (nullable = true)\n",
      " |-- monthly_expenses: integer (nullable = true)\n",
      " |-- down_payment: integer (nullable = true)\n",
      " |-- emi_to_income_ratio: float (nullable = true)\n",
      " |-- satisfaction_score: integer (nullable = true)\n",
      " |-- neighbourhood_rating: integer (nullable = true)\n",
      " |-- connectivity_score: integer (nullable = true)\n",
      " |-- decision: boolean (nullable = false)\n",
      " |-- country_id: long (nullable = true)\n",
      " |-- city_id: long (nullable = true)\n",
      " |-- property_type_id: long (nullable = true)\n",
      " |-- furnishing_status_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_house.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ed1f6730-3974-4b00-bee1-23d83ce1ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = false)\n",
      " |-- id: long (nullable = false)\n",
      "\n",
      "+-------+---------+-----+\n",
      "|summary|  country|count|\n",
      "+-------+---------+-----+\n",
      "|  count|       13|   13|\n",
      "|   mean|     NULL|  1.0|\n",
      "| stddev|     NULL|  0.0|\n",
      "|    min|Australia|    1|\n",
      "|    max|      USA|    1|\n",
      "+-------+---------+-----+\n",
      "\n",
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n",
      "+-------+---------+-----+\n",
      "|summary|     city|count|\n",
      "+-------+---------+-----+\n",
      "|  count|       40|   40|\n",
      "|   mean|     NULL|  1.0|\n",
      "| stddev|     NULL|  0.0|\n",
      "|    min|Abu Dhabi|    1|\n",
      "|    max|Vancouver|    1|\n",
      "+-------+---------+-----+\n",
      "\n",
      "root\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n",
      "+-------+-------------+-----+\n",
      "|summary|property_type|count|\n",
      "+-------+-------------+-----+\n",
      "|  count|            6|    6|\n",
      "|   mean|         NULL|  1.0|\n",
      "| stddev|         NULL|  0.0|\n",
      "|    min|    Apartment|    1|\n",
      "|    max|        Villa|    1|\n",
      "+-------+-------------+-----+\n",
      "\n",
      "root\n",
      " |-- furnishing_status: string (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      "\n",
      "+-------+-----------------+-----+\n",
      "|summary|furnishing_status|count|\n",
      "+-------+-----------------+-----+\n",
      "|  count|                3|    3|\n",
      "|   mean|             NULL|  1.0|\n",
      "| stddev|             NULL|  0.0|\n",
      "|    min|  Fully-Furnished|    1|\n",
      "|    max|      Unfurnished|    1|\n",
      "+-------+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " \n",
    "for cat in categorical_features:\n",
    "    cur_df = categoricalTables[cat]\n",
    "    cur_df.printSchema()\n",
    "    cur_df.groupBy(cat).count().describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c22b80d5-32ce-42d0-8af6-ae7b0845d882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/20 05:47:40 WARN Column: Constructing trivially true equals predicate, 'm.country_id == m.country_id'. Perhaps you need to use aliases.\n",
      "25/11/20 05:47:40 WARN Column: Constructing trivially true equals predicate, 'm.city_id == m.city_id'. Perhaps you need to use aliases.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "locations = id_house.select( \"country_id\", \"city_id\").distinct().withColumn(\"id\",monotonically_increasing_id())\n",
    "id_house = id_house.join(\n",
    "    locations ,\n",
    "    on=[id_house[\"country_id\"] == locations[\"country_id\"],\n",
    "        id_house[\"city_id\"] == locations[\"city_id\"]],\n",
    "    how=\"left\"\n",
    ").drop(\"country_id\", \"city_id\").withColumnRenamed(\"id\", \"location_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "afdd4748-4e4f-47ab-950e-acc7326a0417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- property_id: integer (nullable = true)\n",
      " |-- property_size_sqft: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- constructed_year: integer (nullable = true)\n",
      " |-- previous_owners: integer (nullable = true)\n",
      " |-- rooms: integer (nullable = true)\n",
      " |-- bathrooms: integer (nullable = true)\n",
      " |-- garage: boolean (nullable = false)\n",
      " |-- garden: boolean (nullable = false)\n",
      " |-- crime_cases_reported: integer (nullable = true)\n",
      " |-- legal_cases_on_property: boolean (nullable = false)\n",
      " |-- customer_salary: integer (nullable = true)\n",
      " |-- loan_amount: integer (nullable = true)\n",
      " |-- loan_tenure_years: integer (nullable = true)\n",
      " |-- monthly_expenses: integer (nullable = true)\n",
      " |-- down_payment: integer (nullable = true)\n",
      " |-- emi_to_income_ratio: float (nullable = true)\n",
      " |-- satisfaction_score: integer (nullable = true)\n",
      " |-- neighbourhood_rating: integer (nullable = true)\n",
      " |-- connectivity_score: integer (nullable = true)\n",
      " |-- decision: boolean (nullable = false)\n",
      " |-- property_type_id: long (nullable = true)\n",
      " |-- furnishing_status_id: long (nullable = true)\n",
      " |-- location_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_house.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2c211-ff84-4087-9c7d-3534b1d45532",
   "metadata": {},
   "source": [
    "## Transformation 3: Final prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6bf39bc7-ba2c-4e1a-9a0f-96e533725a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- decision: float (nullable = false)\n",
      " |-- location_id: long (nullable = true)\n",
      " |-- crime_cases_reported: integer (nullable = true)\n",
      " |-- previous_owners: integer (nullable = true)\n",
      " |-- constructed_year: integer (nullable = true)\n",
      " |-- neighbourhood_rating: integer (nullable = true)\n",
      " |-- garden: boolean (nullable = false)\n",
      " |-- property_size_sqft: integer (nullable = true)\n",
      " |-- bathrooms: integer (nullable = true)\n",
      " |-- legal_cases_on_property: boolean (nullable = false)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- garage: boolean (nullable = false)\n",
      " |-- rooms: integer (nullable = true)\n",
      " |-- property_type_id: long (nullable = true)\n",
      " |-- furnishing_status_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_cat = list(set(features) - set(categorical_features))\n",
    "train_features = [\"location_id\"]\n",
    "train_features.extend(non_cat)\n",
    "train_features.extend([f\"{x}_id\" for x in categorical_features if x not in (\"country,city\").split(\",\") ])\n",
    "to_select = [\"decision\"]\n",
    "to_select.extend(train_features)\n",
    "to_train = id_house.select(to_select)\n",
    "to_train = to_train.withColumn(\"decision\", to_train.decision.cast(\"float\"))\n",
    "to_train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee0c88-7806-48da-974c-ed71b025a005",
   "metadata": {},
   "source": [
    "## Transformation 4: Assembling columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4237da7f-fb67-434b-915a-4d0c3cfed8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n",
    "stringIndexer = StringIndexer(inputCol=\"decision\", outputCol=\"indexed_decision\",\n",
    "stringOrderType=\"frequencyDesc\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "772683e1-6c8a-496a-8488-8a56e7512dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['location_id', 'crime_cases_reported', 'previous_owners', 'constructed_year', 'neighbourhood_rating', 'garden', 'property_size_sqft', 'bathrooms', 'legal_cases_on_property', 'price', 'garage', 'rooms', 'property_type_id', 'furnishing_status_id']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/20 14:17:42 WARN HeartbeatReceiver: Removing executor 1 with no recent heartbeats: 28312766 ms exceeds timeout 120000 ms\n",
      "25/11/20 14:17:44 ERROR Inbox: Ignoring error\n",
      "java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost\n",
      "\tat scala.Predef$.assert(Predef.scala:279)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:741)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/11/20 14:17:44 ERROR TaskSchedulerImpl: Lost executor 1 on 172.18.0.3: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/11/20 14:17:44 ERROR Inbox: Ignoring error\n",
      "java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost\n",
      "\tat scala.Predef$.assert(Predef.scala:279)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:741)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    }
   ],
   "source": [
    "print(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "58e52a56-ff57-48ed-b838-9ddee18e3e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "\n",
    "assembler = VectorAssembler(inputCols=train_features, outputCol=\"features\")\n",
    "\n",
    "data_with_features = assembler.transform(to_train).select(\"decision\", \"features\")# Step 2: Scale the features vector\n",
    "scaler = StandardScaler(\n",
    "inputCol=\"features\",\n",
    "outputCol=\"scaledFeatures\",\n",
    "withMean=True,\n",
    "# centers the data\n",
    "withStd=True\n",
    "# scales to unit std\n",
    ")\n",
    "scaler_model = scaler.fit(data_with_features)\n",
    "scaled_data = scaler_model.transform(data_with_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6cafa-14af-46f4-9789-5f84140e5a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f257f483-8468-4b0f-a593-a48e04b268e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = scaled_data.randomSplit([0.8, 0.2], seed=57)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff30aad-a248-495d-87bb-9141b7854d56",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2a8ddd3f-950f-4ace-a2a1-6bf91a0dce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "\n",
    "# Initialize the LinearSVC classifier for binary classification\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.01, labelCol=\"decision\", predictionCol=\"prediction\")\n",
    "\n",
    "# Set up OneVsRest classifier for multi-class classification\n",
    "ovr = OneVsRest(classifier=lsvc,  labelCol=\"decision\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "93d1cd35-d101-42c4-b65c-187feafc3e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/20 06:20:57 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    }
   ],
   "source": [
    "ovr_model = ovr.fit(train_df)# Make predictions on the test set\n",
    "predictions = ovr_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5e30004b-c68f-4c71-a5a6-4550a1a41cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ova_model_path = \"/opt/spark/work-dir/data/mlmodels/svm/svm_proy\"\n",
    "ovr_model.write().overwrite().save(ova_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7f1131c3-4000-4316-a325-280c3a1634f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 635:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|scaledFeatures                                                                                                                                                                                                                          |prediction|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|[-1.4862535988148422,0.6503936857867727,-1.4990373079553454,0.08176840028099842,-0.8726186738832207,0.0,-0.5396525338410022,2.3031306963615155,0.0,-1.0520684492372587,0.0,1.0829720735220196,-1.4685206377004068,-1.222746414315009]   |0.0       |\n",
      "|[-1.4862535988148422,1.4940363869052378,-1.4990373079553454,-1.7025879537682018,1.2172857038607927,0.0,-0.5390326948862244,0.1303505150286207,0.0,-1.0498867324002494,0.0,1.5185750144293262,-1.4685206377004068,-1.222746414315009]    |0.0       |\n",
      "|[-1.4030863515606933,-0.19324901533169225,-1.4990373079553454,1.1631964936441501,-0.8726186738832207,0.0,-1.2617649161571578,-0.9560395756378267,0.0,-1.2238388887569707,0.0,-0.6594396901072063,-1.4685206377004068,-1.222746414315009]|0.0       |\n",
      "|[-1.4030863515606933,0.6503936857867727,-1.4990373079553454,-1.540373739763729,-1.2209360701738896,0.0,1.032259055475539,0.1303505150286207,0.0,-0.4158715637642743,0.0,-0.2238367491998998,-1.4685206377004068,-1.222746414315009]     |0.0       |\n",
      "|[-1.4030863515606933,0.6503936857867727,-1.4990373079553454,-0.08044581372347431,-0.1759838813018829,0.0,-1.2791204068909368,2.3031306963615155,0.0,-1.2259307630531127,0.0,1.0829720735220196,-1.4685206377004068,-1.222746414315009]  |0.0       |\n",
      "|[-1.3199191043065444,-0.19324901533169225,-1.4990373079553454,1.0009822796396772,-0.1759838813018829,0.0,-1.7260242932857421,0.6735455603618444,0.0,-1.3827035686899216,0.0,0.6473691326147132,-1.4685206377004068,-1.222746414315009]  |0.0       |\n",
      "|[-1.3199191043065444,0.6503936857867727,-1.4990373079553454,-1.0537310977503107,0.5206509112794548,0.0,-1.7043299298685184,-0.412844530304603,0.0,-1.3757820507779626,0.0,1.5185750144293262,-1.4685206377004068,-1.222746414315009]    |0.0       |\n",
      "|[-1.3199191043065444,0.6503936857867727,-1.4990373079553454,-0.513017051068735,-0.8726186738832207,0.0,0.3529155610390528,-0.9560395756378267,0.0,-0.6547956603171873,0.0,-0.6594396901072063,-1.4685206377004068,-1.222746414315009]   |0.0       |\n",
      "|[-1.3199191043065444,1.4940363869052378,-1.4990373079553454,-0.35080283706426224,-0.1759838813018829,0.0,-1.399369164117833,-0.412844530304603,0.0,-1.2659106937390996,0.0,-0.2238367491998998,-1.4685206377004068,-1.222746414315009]  |0.0       |\n",
      "|[-1.3199191043065444,1.4940363869052378,-1.4990373079553454,0.1899112096173136,0.8689683075701238,0.0,0.8159352602580814,1.216740605695068,0.0,-0.49495728149537627,0.0,0.2117661917074067,-1.4685206377004068,-1.222746414315009]      |0.0       |\n",
      "|[-1.3199191043065444,1.4940363869052378,-1.4990373079553454,1.0009822796396772,-1.2209360701738896,0.0,-0.9784985138236959,1.7599356510282917,0.0,-1.1186587692574534,0.0,0.6473691326147132,-1.4685206377004068,-1.222746414315009]    |0.0       |\n",
      "|[-1.3199191043065444,2.3376790880237026,-1.4990373079553454,-0.513017051068735,-1.2209360701738896,0.0,0.41242010069772317,2.3031306963615155,0.0,-0.6351347129279109,0.0,1.5185750144293262,-1.4685206377004068,-1.222746414315009]    |0.0       |\n",
      "|[-1.2367518570523957,0.6503936857867727,-1.4990373079553454,0.35212542362178634,0.172333514988786,0.0,-0.02518620137541494,-0.412844530304603,0.0,-0.3211908806623402,0.0,-0.2238367491998998,-1.4685206377004068,-1.222746414315009]   |0.0       |\n",
      "|[-1.2367518570523957,1.4940363869052378,-1.4990373079553454,-0.513017051068735,-0.5243012775925517,0.0,1.3551951509147813,0.6735455603618444,0.0,0.48380192777461173,0.0,1.0829720735220196,-1.4685206377004068,-1.222746414315009]     |0.0       |\n",
      "|[-1.1535846097982467,0.6503936857867727,-1.4990373079553454,-1.540373739763729,-0.1759838813018829,0.0,-1.6138334424709573,-0.412844530304603,0.0,-1.2395273389338406,0.0,-1.0950426310145127,-1.4685206377004068,-1.222746414315009]   |0.0       |\n",
      "|[-1.1535846097982467,0.6503936857867727,-1.4990373079553454,-1.3781595257592563,1.2172857038607927,0.0,-0.5545286687556698,0.6735455603618444,0.0,-0.5797759246045295,0.0,-0.2238367491998998,-1.4685206377004068,-1.222746414315009]   |0.0       |\n",
      "|[-1.1535846097982467,0.6503936857867727,-1.4990373079553454,0.29805401895362876,-0.5243012775925517,0.0,0.5580822550705099,-0.9560395756378267,0.0,0.1136154508376671,0.0,-1.0950426310145127,-1.4685206377004068,-1.222746414315009]   |0.0       |\n",
      "|[-1.1535846097982467,0.6503936857867727,-1.4990373079553454,0.6224824469625743,-1.2209360701738896,0.0,1.059531969485763,-0.9560395756378267,0.0,0.431831660147999,0.0,-1.0950426310145127,-1.4685206377004068,-1.222746414315009]      |0.0       |\n",
      "|[-1.0704173625440978,-0.19324901533169225,-1.4990373079553454,-1.2159453117547836,-1.5692534664645583,0.0,0.4682056066277266,1.7599356510282917,0.0,0.44187338522251457,0.0,1.5185750144293262,-1.4685206377004068,-1.222746414315009]  |0.0       |\n",
      "|[-1.0704173625440978,0.6503936857867727,-1.4990373079553454,1.433553516984938,1.5656031001514614,0.0,0.5946527534024011,1.216740605695068,0.0,0.5381858031207428,0.0,0.2117661917074067,-1.4685206377004068,-1.222746414315009]         |0.0       |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import OneVsRestModel\n",
    "\n",
    "# Retreive the saved model\n",
    "ovr_model = OneVsRestModel.load(ova_model_path)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = ovr_model.transform(test_df)\n",
    "\n",
    "# Show predictions\n",
    "predictions.select(\"scaledFeatures\", \"prediction\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "020c27d9-0f2b-4f88-a3f2-e1103465955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 668:============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"decision\",\n",
    "                            predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, \n",
    "                  {evaluator.metricName: \"accuracy\"})\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "f1 = evaluator.evaluate(predictions,\n",
    "                {evaluator.metricName: \"f1\"})\n",
    "print(f\"F1 Score: {f1}\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
