{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db2969a-ec46-4261-be6f-5a9f6d88527f",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "\n",
    "#### <center> **Final Project: ML** </center>\n",
    "---\n",
    "\n",
    "**Date**: 24 November, 2025\n",
    "\n",
    "**Student Name**: Antonia Horburger\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e297f743-6f8f-48dc-beef-64068db617e2",
   "metadata": {},
   "source": [
    "## 1. Algoritmo de Machine Learning a usar\n",
    "\n",
    "En este proyecto quiero construir un sistema de recomendación de películas.  \n",
    "El objetivo es predecir qué tan bien le podría gustar una película a un usuario, a partir de las calificaciones que otros usuarios han dado en el pasado. Este problema es un problema típico de **sistemas de recomendación**, donde los datos principales son (usuario, ítem, rating).\n",
    "\n",
    "Por eso elegí el algoritmo **Alternating Least Squares** de Spark MLlib. ALS es un algoritmo de factorización de matrices que funciona muy bien cuando tenemos muchos usuarios, muchos ítems y una matriz de calificaciones muy dispersa (la mayoría de las películas no han sido calificadas por la mayoría de los usuarios). Además, ALS está implementado de forma nativa en Apache Spark, lo que facilita el entrenamiento distribuido y el manejo de conjuntos de datos grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a2226-b3e9-4054-af5d-d18d88eb40fb",
   "metadata": {},
   "source": [
    "## 2. Descripción del conjunto de datos\n",
    "\n",
    "Para este proyecto utilizo el conjunto de datos **MovieLens \"ml-latest-small\"**.  \n",
    "Este dataset se puede descargar desde la página de MovieLens / GroupLens o desde Kaggle (https://www.kaggle.com/datasets/shubhammehta21/movie-lens-small-latest-dataset). Contiene calificaciones de películas hechas por usuarios reales.\n",
    "\n",
    "El archivo principal que uso es `ratings.csv`, que tiene las columnas `userId`, `movieId`, `rating` y `timestamp`.  \n",
    "En total el dataset tiene alrededor de 100,000 calificaciones, más de 600 usuarios y casi 10,000 películas diferentes.  \n",
    "\n",
    "Como se trata de un sistema de recomendación, es importante describir cuántos **usuarios únicos** y cuántos **ítems (películas) únicos** hay en el dataset. Esta descripción la hago usando PySpark, contando los usuarios distintos y las películas distintas en el DataFrame de calificaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be87de7-c930-4a2e-9f9d-d8c1cd0691c8",
   "metadata": {},
   "source": [
    "## 3. Proceso de entrenamiento del modelo de ML\n",
    "\n",
    "El flujo de entrenamiento de mi sistema de recomendación es el siguiente:\n",
    "\n",
    "1. Cargar el archivo ratings.csv en un DataFrame de Spark.\n",
    "2. Dividir los datos en un conjunto de entrenamiento y un conjunto de prueba usando randomSplit.\n",
    "3. Configurar el modelo **ALS** indicando qué columnas representan al usuario, al ítem y al rating.\n",
    "4. Definir los hiperparámetros principales del modelo.\n",
    "5. Entrenar el modelo usando el conjunto de entrenamiento.\n",
    "6. Guardar el modelo entrenado en disco para poder cargarlo más tarde.\n",
    "\n",
    "En este proyecto uso los siguientes hiperparámetros de ALS:\n",
    "\n",
    "- rank: número de factores latentes. Controla la dimensión de las representaciones de usuario e ítem. Un valor moderado (por ejemplo, 10) permite capturar patrones sin hacer el modelo demasiado grande.\n",
    "- maxIter: número máximo de iteraciones del algoritmo ALS. Más iteraciones permiten que el modelo converja mejor, pero aumentan el tiempo de cómputo. En este proyecto uso un valor como 10.\n",
    "- regParam: parámetro de regularización. Sirve para evitar sobreajuste penalizando valores muy grandes en los vectores de usuario e ítem. Uso un valor como 0.1 para tener un equilibrio entre ajuste y generalización.\n",
    "- nonnegative: si es True, fuerza a que los factores latentes sean no negativos. Esto puede hacer que las representaciones sean más interpretables.\n",
    "- implicitPrefs: en este proyecto lo dejo en False porque mis ratings son explícitos (valores de 0.5 a 5.0 y no sólo información implícita de clics o vistas).\n",
    "- coldStartStrategy: uso el valor \"drop\" para que Spark elimine las filas donde la predicción es NaN (por ejemplo, usuarios o películas no vistos en entrenamiento) antes de calcular las métricas.\n",
    "\n",
    "Después de entrenar el modelo, lo guardo en una ruta dentro del sistema de archivos del cluster usando el método .save() de Spark ML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce13771-fd17-42ed-8c8e-f2da13b29c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/24 13:46:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Final Project - ALS Recommender\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4f81b2-496b-447f-9e58-14e510683a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "First 5 rows:\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "Total number of ratings:\n",
      "100836\n",
      "Number of distinct users and movies:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|n_users|n_movies|\n",
      "+-------+--------+\n",
      "|    610|    9724|\n",
      "+-------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "base_path = \"/opt/spark/work-dir/data/ml/movies/\"\n",
    "ratings_path = base_path + \"ratings.csv\"\n",
    "\n",
    "ratings_df = (spark.read\n",
    "              .option(\"header\", True)\n",
    "              .option(\"inferSchema\", True)\n",
    "              .csv(ratings_path))\n",
    "\n",
    "print(\"Schema:\")\n",
    "ratings_df.printSchema()\n",
    "\n",
    "print(\"First 5 rows:\")\n",
    "ratings_df.show(5)\n",
    "\n",
    "print(\"Total number of ratings:\")\n",
    "print(ratings_df.count())\n",
    "\n",
    "print(\"Number of distinct users and movies:\")\n",
    "ratings_df.select(\n",
    "    F.countDistinct(\"userId\").alias(\"n_users\"),\n",
    "    F.countDistinct(\"movieId\").alias(\"n_movies\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53f65d9-0655-44d2-8adc-143513e5d8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 80578\n",
      "Test set size: 20258\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = ratings_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Training set size:\", train_df.count())\n",
    "print(\"Test set size:\", test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f2dcd6-45ce-4db2-8d6c-8bcc3c3a10f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    rank=10,             \n",
    "    maxIter=10,           \n",
    "    regParam=0.1,        \n",
    "    nonnegative=True,    \n",
    "    implicitPrefs=False,  \n",
    "    coldStartStrategy=\"drop\"  \n",
    ")\n",
    "\n",
    "\n",
    "als_model = als.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59ec91-bd46-44c4-ad8f-eb2bb6b00584",
   "metadata": {},
   "source": [
    "## 4. Evaluación del modelo de ML\n",
    "\n",
    "Para evaluar la calidad de mi sistema de recomendación con ALS utilizo la métrica **RMSE (Root Mean Squared Error)** sobre el conjunto de prueba.\n",
    "\n",
    "El RMSE mide la diferencia promedio entre las calificaciones reales y las calificaciones predichas por el modelo. Cuanto más pequeño es el RMSE, mejor está ajustado el modelo a los datos. Esta métrica es adecuada porque en este problema los ratings son valores numéricos continuos (por ejemplo, de 0.5 a 5.0) y nos interesa que las predicciones estén lo más cerca posible de los valores reales.\n",
    "\n",
    "El proceso de evaluación es:\n",
    "\n",
    "1. Usar el modelo entrenado para generar predicciones sobre el conjunto de prueba con el método .transform(test_df).\n",
    "2. Eliminar filas con predicciones NaN (esto ya lo hace automáticamente la opción coldStartStrategy=\"drop\").\n",
    "3. Calcular el RMSE usando RegressionEvaluator de Spark ML, indicando como etiqueta real la columna rating y como predicción la columna prediction.\n",
    "\n",
    "Además, para entender mejor el comportamiento del modelo, también muestro algunas filas de las predicciones y algunas recomendaciones para usuarios específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aaee220-03a7-4e96-9e19-2c0f4fc6c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions example:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating|timestamp |prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|22    |858    |3.0   |1268726337|2.8674862 |\n",
      "|22    |1193   |5.0   |1268726374|3.4953542 |\n",
      "|22    |3006   |4.0   |1268726047|2.5993364 |\n",
      "|22    |3481   |0.5   |1268726778|2.3403294 |\n",
      "|22    |3489   |5.0   |1268726106|1.324918  |\n",
      "|22    |4017   |4.0   |1268727100|2.3640177 |\n",
      "|22    |4903   |4.0   |1268727442|1.5251408 |\n",
      "|22    |5464   |2.0   |1268727450|2.835936  |\n",
      "|22    |5669   |4.5   |1268726814|1.9405422 |\n",
      "|22    |6874   |4.0   |1268726782|2.9470587 |\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error (RMSE) = 0.877014014393235\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "predictions = als_model.transform(test_df)\n",
    "\n",
    "print(\"Predictions example:\")\n",
    "predictions.show(10, truncate=False)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error (RMSE) = {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99752e90-0a59-42f5-aa0a-576d2dc7837f",
   "metadata": {},
   "source": [
    "## 4. Evaluación del modelo de ML\n",
    "\n",
    "Para evaluar el desempeño de mi modelo ALS utilicé el conjunto de prueba, es decir, los datos que no fueron usados durante el entrenamiento. Primero generé predicciones para cada par (usuario, película) usando el método transform() y verifiqué que Spark eliminara automáticamente las filas con `NaN` gracias a la opción coldStartStrategy=\"drop\".\n",
    "\n",
    "Un ejemplo de las predicciones obtenidas es el siguiente:\n",
    "\n",
    "- Usuario 22, Película 858 → rating real = 3.0, predicción ≈ 2.87  \n",
    "- Usuario 22, Película 1193 → rating real = 5.0, predicción ≈ 3.49  \n",
    "- Usuario 22, Película 3481 → rating real = 0.5, predicción ≈ 2.34  \n",
    "- Usuario 22, Película 5669 → rating real = 4.5, predicción ≈ 1.94  \n",
    "\n",
    "Estas diferencias entre la calificación real y la predicha son esperables en modelos de recomendación, ya que ALS intenta aproximar la matriz de usuarios y películas usando factores latentes.\n",
    "\n",
    "Para medir la calidad del modelo utilicé la métrica **RMSE (Root Mean Squared Error)**.  \n",
    "El valor obtenido fue:\n",
    "\n",
    "**RMSE = 0.877**\n",
    "\n",
    "Este valor indica que, en promedio, la diferencia entre la predicción del modelo y la calificación real es menor a 1 punto de rating (en una escala de 0.5 a 5). Este nivel de error es consistente con los resultados típicos de ALS en el dataset MovieLens “ml-latest-small”, y muestra que el modelo logra capturar patrones relevantes en las preferencias de los usuarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
