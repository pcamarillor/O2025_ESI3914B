{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78458170-5cc1-4624-b8d6-7048e384ba5a",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "\n",
    "#### <center> **Final project: Machine Learning** </center>\n",
    "---\n",
    "\n",
    "**Date**: November, 2025\n",
    "\n",
    "**Student Name**: Díaz Campos José Juan\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b370cfc7-6085-4bac-acd0-c445173a175c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/11 04:38:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/11 04:38:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession iniciada y configurada.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from jjodiaz.spark_utils import SparkUtils\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ML_FinalProject_JoseJuanDiaz\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"INFO\")\n",
    "\n",
    "print(\"SparkSession iniciada y configurada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde08888-8da7-4316-8c4d-1bed565f6639",
   "metadata": {},
   "source": [
    "## Machine Learning algorithm to use (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3b3a0-a6ae-4040-bd5a-f55cab36c3f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Problema a Resolver: Clustering\n",
    "Para este proyecto, el problema a resolver es la **segmentación de clientes** (Customer Segmentation), que es una tarea de **Clustering** (Aprendizaje No Supervisado). El algoritmo seleccionado de la lista provista es **K-Means**\n",
    "### Justificación de la Elección\n",
    "\n",
    "He seleccionado este problema por su alta relevancia práctica en el análisis de Big Data.En muchos escenarios de negocio, como el comercio electrónico (similar a mi proyecto de batch processing ), acumulamos grandes volúmenes de datos transaccionales. Sin embargo, a menudo carecemos de etiquetas predefinidas que nos digan \"este es un cliente de alto valor\" o \"este es un cliente en riesgo\".\n",
    "\n",
    "En lugar de predecir un valor conocido (Clasificación), el objetivo aquí es aplicar **aprendizaje no supervisado** para **descubrir patrones y estructuras ocultas** en los datos.\n",
    "\n",
    "El algoritmo **K-Means** es la herramienta ideal para este fin, ya que nos permite particionar los datos en *K* clústeres distintos, agrupando a los clientes en función de la similitud de sus características (como sus ingresos, edad o puntuación de gasto).El resultado es la creación de \"segmentos\" de clientes que la empresa puede usar para tomar decisiones informadas sobre marketing, inventario y estrategias de personalización, una aplicación que se mencionó en la Sesión 22."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739a28b-eb32-4755-a243-c1cbc04a5422",
   "metadata": {},
   "source": [
    "## Dataset Description (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7b16d5-44bf-4bdf-802f-cd355516d258",
   "metadata": {},
   "source": [
    "Para este proyecto de clustering, he seleccionado el dataset \"Mall Customer Segmentation\", obtenido de Kaggle.\n",
    "https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python\n",
    "\n",
    "Este dataset contiene información demográfica y de comportamiento de 200 clientes de un centro comercial.\n",
    "\n",
    "### Tamaño del Dataset\n",
    "El dataset es compacto, lo que lo hace ideal para el prototipado y la validación del modelo K-Means.\n",
    "\n",
    "Total de filas (clientes): 200\n",
    "\n",
    "Total de columnas (atributos): 5\n",
    "\n",
    "### Dimensiones (Clustering)\n",
    "De las 5 columnas disponibles (CustomerID, Gender, Age, Annual Income (k$), Spending Score (1-100)), no todas son relevantes como dimensiones directas para el algoritmo K-Means.\n",
    "\n",
    "CustomerID es un identificador único y será excluido del análisis.\n",
    "\n",
    "Gender es una variable categórica que podría usarse, pero para este análisis nos centraremos en las métricas de comportamiento.\n",
    "\n",
    "Las dimensiones o features principales que se utilizarán para segmentar a los clientes son las 3 columnas numéricas:\n",
    "\n",
    "Age (Edad del cliente).\n",
    "\n",
    "Annual Income (k$) (Ingreso anual del cliente en miles de dólares).\n",
    "\n",
    "Spending Score (1-100) (Puntuación asignada por el centro comercial basada en el comportamiento de gasto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb758e7-ab8b-479d-b405-a129a5df1bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Esquema del Dataset ---\n",
      "root\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Annual Income (k$): integer (nullable = true)\n",
      " |-- Spending Score (1-100): integer (nullable = true)\n",
      "\n",
      "\n",
      "--- Tamaño del Dataset ---\n",
      "Total de filas: 200\n",
      "Total de columnas: 5\n"
     ]
    }
   ],
   "source": [
    "# Definir Esquema\n",
    "schema_columns = [\n",
    "    (\"CustomerID\", \"int\"),\n",
    "    (\"Gender\", \"string\"),\n",
    "    (\"Age\", \"int\"),\n",
    "    (\"Annual Income (k$)\", \"int\"),\n",
    "    (\"Spending Score (1-100)\", \"int\")\n",
    "]\n",
    "customers_schema = SparkUtils.generate_schema(schema_columns)\n",
    "\n",
    "# Cargar el Dataset\n",
    "DATA_PATH = \"/opt/spark/work-dir/data/ml/proyectopepe/Mall_Customers.csv\"\n",
    "df_customers = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(customers_schema) \\\n",
    "    .csv(DATA_PATH)\n",
    "\n",
    "print(\"--- Esquema del Dataset ---\")\n",
    "df_customers.printSchema()\n",
    "\n",
    "print(f\"\\n--- Tamaño del Dataset ---\")\n",
    "print(f\"Total de filas: {df_customers.count()}\")\n",
    "print(f\"Total de columnas: {len(df_customers.columns)}\")\n",
    "\n",
    "df_cleaned = df_customers \\\n",
    "    .withColumnRenamed(\"Annual Income (k$)\", \"Annual_Income\") \\\n",
    "    .withColumnRenamed(\"Spending Score (1-100)\", \"Spending_Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9f3cf-7585-4d14-b657-05970de01ddf",
   "metadata": {},
   "source": [
    "### ML Training process (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb499c2a-47e7-4c98-a09e-e5aadfa173d4",
   "metadata": {},
   "source": [
    "Antes de entrenar, debemos unificar nuestras dimensiones (Age, Annual_Income, Spending_Score) en una sola columna vectorial.\n",
    "\n",
    "Herramienta: VectorAssembler.\n",
    "\n",
    "Justificación: Los algoritmos de spark.ml están diseñados para operar sobre una única columna de tipo Vector, en lugar de múltiples columnas numéricas. Esta transformación es un paso de configuración obligatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b671011b-3698-4130-a566-35b8c2111005",
   "metadata": {},
   "source": [
    "#### Hiperparámetros del Modelo (KMeans)\n",
    "\n",
    "A continuación, se describen y justifican los hiperparámetros clave utilizados para configurar el modelo K-Means:\n",
    "\n",
    "##### **k:**\n",
    "\n",
    "- **Descripción:** Este es el hiperparámetro más importante de K-Means. Define cuántos segmentos de clientes intentará encontrar el algoritmo.\n",
    "\n",
    "- **Justificación:**  \n",
    "  En lugar de seleccionar un valor arbitrario para `k`, implementaremos un proceso de sintonización (similar al Lab 15).  \n",
    "  Se probará un rango de valores para `k` (por ejemplo, de 2 a 10). Para cada valor, entrenaremos un modelo y calcularemos su **Silhouette Score**.  \n",
    "  El valor de `k` que maximice este puntaje (el valor más cercano a 1) será seleccionado como el óptimo, ya que representa la mejor segmentación (alta cohesión interna y baja similitud entre clústeres).\n",
    "\n",
    "##### **seed:**\n",
    "\n",
    "- **Descripción:** El algoritmo K-Means comienza seleccionando `k` centroides iniciales de forma aleatoria.\n",
    "\n",
    "- **Justificación:**  \n",
    "  Usar un `seed` (ej. `setSeed(42)`) asegura que esta aleatoriedad inicial sea la misma cada vez que se ejecuta el código.  \n",
    "  Esto es fundamental para la reproducibilidad del experimento, garantizando que obtengamos los mismos resultados y el mismo `k` óptimo en cada ejecución.\n",
    "\n",
    "##### **featuresCol:**\n",
    "\n",
    "- **Descripción:** Indica al modelo qué columna contiene el vector de características.\n",
    "\n",
    "- **Justificación:**  \n",
    "  Se establece en `\"features\"`, que es el nombre de la columna de salida (`outputCol`) que definimos en nuestro `VectorAssembler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51477cf-4e57-4162-9ae6-617974d90ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Datos listos para ML (con columna 'features') ---\n",
      "+----------------+\n",
      "|features        |\n",
      "+----------------+\n",
      "|[19.0,15.0,39.0]|\n",
      "|[21.0,15.0,81.0]|\n",
      "|[20.0,16.0,6.0] |\n",
      "|[23.0,16.0,77.0]|\n",
      "|[31.0,17.0,40.0]|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "--- Buscando el k óptimo usando Silhouette Score ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/11 04:38:52 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2, Silhouette Score: 0.4601\n",
      "k = 3, Silhouette Score: 0.4681\n",
      "k = 4, Silhouette Score: 0.5732\n",
      "k = 5, Silhouette Score: 0.6317\n",
      "k = 6, Silhouette Score: 0.6412\n",
      "k = 7, Silhouette Score: 0.6273\n",
      "k = 8, Silhouette Score: 0.6262\n",
      "k = 9, Silhouette Score: 0.5827\n",
      "k = 10, Silhouette Score: 0.5704\n"
     ]
    }
   ],
   "source": [
    "# Preparación de Datos\n",
    "feature_cols = [\"Age\", \"Annual_Income\", \"Spending_Score\"]\n",
    "\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\" # Usamos el nombre por defecto\n",
    ")\n",
    "\n",
    "assembled_df = vector_assembler.transform(df_cleaned)\n",
    "\n",
    "print(\"--- Datos listos para ML (con columna 'features') ---\")\n",
    "assembled_df.select(\"features\").show(5, truncate=False)\n",
    "\n",
    "print(\"\\n--- Buscando el k óptimo usando Silhouette Score ---\")\n",
    "k_values = range(2, 11)\n",
    "silhouette_scores = {}\n",
    "\n",
    "# Definir evaluador \n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans().setK(k).setSeed(42)\n",
    "    model = kmeans.fit(assembled_df)\n",
    "    \n",
    "    # Realizar predicciones\n",
    "    predictions = model.transform(assembled_df)\n",
    "    \n",
    "    # Evaluar con Silhouette Score\n",
    "    silhouette = evaluator.evaluate(predictions)\n",
    "    silhouette_scores[k] = silhouette\n",
    "    \n",
    "    print(f\"k = {k}, Silhouette Score: {silhouette:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5487a636-d804-4a5d-92a2-eb9480ef41ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultado de la Sintonización ---\n",
      "El valor óptimo de k es: 6 (Silhouette Score: 0.6412)\n"
     ]
    }
   ],
   "source": [
    "optimal_k = max(silhouette_scores, key=silhouette_scores.get)\n",
    "best_score = silhouette_scores[optimal_k]\n",
    "\n",
    "print(f\"\\n--- Resultado de la Sintonización ---\")\n",
    "print(f\"El valor óptimo de k es: {optimal_k} (Silhouette Score: {best_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206db5de-f1fc-49a4-8ce8-dcc049ace564",
   "metadata": {},
   "source": [
    "### Persistencia del Modelo\n",
    "\n",
    "Una vez que el bucle de sintonización identifica el `optimal_k` (el `k` con el mayor Silhouette Score), se entrenará un modelo final usando ese valor `k`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d35d7f73-8e0d-41c9-ae59-672457982a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo final con k=6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo final guardado en: /opt/spark/work-dir/data/mlmodels/final_project/kmeans_customer_segmentation\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"/opt/spark/work-dir/data/mlmodels/final_project/kmeans_customer_segmentation\"\n",
    "\n",
    "print(f\"\\nEntrenando modelo final con k={optimal_k}...\")\n",
    "kmeans_final = KMeans().setK(optimal_k).setSeed(42)\n",
    "final_model = kmeans_final.fit(assembled_df)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "final_model.write().overwrite().save(MODEL_PATH)\n",
    "\n",
    "print(f\"Modelo final guardado en: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fabb9dc-60ab-419a-9e09-327d86374e8d",
   "metadata": {},
   "source": [
    "### ML Evaluation (20 points)\n",
    "\n",
    "Para un modelo de Clustering como K-Means, donde no tenemos \"etiquetas de la verdad\" (ground truth labels), la evaluación no puede basarse en métricas como **Accuracy** o **F1-Score**. En su lugar, debemos usar métricas internas que midan la calidad de la estructura del clúster.\n",
    "\n",
    "La métrica seleccionada para evaluar el rendimiento de nuestro modelo es el **Silhouette Score**, que mide qué tan bien están definidos los clústeres. Calcula, para cada punto, qué tan similar es a su propio clúster (cohesión) en comparación con qué tan similar es a los clústeres vecinos (separación).\n",
    "\n",
    "- **¿Cómo se interpreta?** El puntaje varía de **-1 a 1**:\n",
    "  - **Cercano a 1:** Indica clústeres densos y bien separados. Este es el ideal.\n",
    "  - **Cercano a 0:** Indica clústeres que se superponen o que los puntos están muy cerca del límite de decisión.\n",
    "  - **Cercano a -1:** Indica que los puntos probablemente fueron asignados al clúster incorrecto.\n",
    "\n",
    "Este es el mismo puntaje que usamos en la sección anterior para encontrar el `optimal_k`. Ahora lo usaremos para validar el rendimiento de nuestro modelo final persistido.\n",
    "El proceso es el siguiente:\n",
    "\n",
    "1. **Cargar el Modelo:**  \n",
    "   Se carga el modelo K-Means final que fue guardado en el disco en la sección anterior.\n",
    "\n",
    "2. **Cargar Datos:**  \n",
    "   Se reutiliza el DataFrame `assembled_df` que ya contiene la columna `features` vectorizada.\n",
    "\n",
    "3. **Obtener Predicciones:**  \n",
    "   Se utiliza el modelo cargado para llamar a `.transform(assembled_df)`.  \n",
    "   Esto añade una nueva columna al DataFrame, `prediction`, que contiene el ID del clúster (de `0` a `k-1`) al que fue asignado cada cliente.\n",
    "\n",
    "4. **Evaluar:**  \n",
    "   Se instancia `ClusteringEvaluator` configurado para la métrica **silhouette** y se aplica al DataFrame de predicciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c25a6a8-225e-48b2-9e54-c40433cb2a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo K-Means (k=6) cargado\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeansModel\n",
    "\n",
    "# Cargar el Modelo\n",
    "loaded_model = KMeansModel.load(MODEL_PATH)\n",
    "\n",
    "print(f\"Modelo K-Means (k={loaded_model.getK()}) cargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f256d235-b3f8-4f23-90be-5d703c3ffe32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Muestra de Predicciones (Cliente -> Clúster) ---\n",
      "+---+-------------+--------------+----------+\n",
      "|Age|Annual_Income|Spending_Score|prediction|\n",
      "+---+-------------+--------------+----------+\n",
      "| 19|           15|            39|         2|\n",
      "| 21|           15|            81|         3|\n",
      "| 20|           16|             6|         2|\n",
      "| 23|           16|            77|         3|\n",
      "| 31|           17|            40|         2|\n",
      "| 22|           17|            76|         3|\n",
      "| 35|           18|             6|         2|\n",
      "| 23|           18|            94|         3|\n",
      "| 64|           19|             3|         2|\n",
      "| 30|           19|            72|         3|\n",
      "+---+-------------+--------------+----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Obtener Predicciones\n",
    "predictions = loaded_model.transform(assembled_df)\n",
    "\n",
    "print(\"\\n--- Muestra de Predicciones (Cliente -> Clúster) ---\")\n",
    "predictions.select(\"Age\", \"Annual_Income\", \"Spending_Score\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "573e711d-a3c2-4c21-aeff-323b85beeb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación Final del Modelo ---\n",
      "Silhouette Score del modelo final: 0.6412\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el Modelo\n",
    "final_silhouette_score = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"\\n--- Evaluación Final del Modelo ---\")\n",
    "print(f\"Silhouette Score del modelo final: {final_silhouette_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cccecd18-9991-47b7-8a26-d6c00f706e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Conteo de Clientes por Segmento ---\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         0|   39|\n",
      "|         1|   44|\n",
      "|         2|   22|\n",
      "|         3|   22|\n",
      "|         4|   39|\n",
      "|         5|   34|\n",
      "+----------+-----+\n",
      "\n",
      "\n",
      "--- Centroides (Promedios) por Segmento ---\n",
      "Segmento 0 [Centroide]:\n",
      "  -> Edad Promedio: 32.7\n",
      "  -> Ingreso Anual Promedio (k$): 86.5\n",
      "  -> Puntuación de Gasto Promedio: 82.1\n",
      "\n",
      "Segmento 1 [Centroide]:\n",
      "  -> Edad Promedio: 56.3\n",
      "  -> Ingreso Anual Promedio (k$): 53.7\n",
      "  -> Puntuación de Gasto Promedio: 49.4\n",
      "\n",
      "Segmento 2 [Centroide]:\n",
      "  -> Edad Promedio: 44.3\n",
      "  -> Ingreso Anual Promedio (k$): 25.8\n",
      "  -> Puntuación de Gasto Promedio: 20.3\n",
      "\n",
      "Segmento 3 [Centroide]:\n",
      "  -> Edad Promedio: 25.3\n",
      "  -> Ingreso Anual Promedio (k$): 25.7\n",
      "  -> Puntuación de Gasto Promedio: 79.4\n",
      "\n",
      "Segmento 4 [Centroide]:\n",
      "  -> Edad Promedio: 27.4\n",
      "  -> Ingreso Anual Promedio (k$): 57.0\n",
      "  -> Puntuación de Gasto Promedio: 48.8\n",
      "\n",
      "Segmento 5 [Centroide]:\n",
      "  -> Edad Promedio: 41.6\n",
      "  -> Ingreso Anual Promedio (k$): 88.7\n",
      "  -> Puntuación de Gasto Promedio: 16.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Análisis de Resultados\n",
    "print(\"\\n--- Conteo de Clientes por Segmento ---\")\n",
    "segment_summary = predictions.groupBy(\"prediction\").count().orderBy(\"prediction\")\n",
    "segment_summary.show()\n",
    "\n",
    "print(\"\\n--- Centroides (Promedios) por Segmento ---\")\n",
    "centers = loaded_model.clusterCenters()\n",
    "for i, center in enumerate(centers):\n",
    "    print(f\"Segmento {i} [Centroide]:\")\n",
    "    print(f\"  -> Edad Promedio: {center[0]:.1f}\")\n",
    "    print(f\"  -> Ingreso Anual Promedio (k$): {center[1]:.1f}\")\n",
    "    print(f\"  -> Puntuación de Gasto Promedio: {center[2]:.1f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994d4ce0-1497-471c-b1c3-0be35dbb7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ec375-4740-4dd1-9858-6a8be21de014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
