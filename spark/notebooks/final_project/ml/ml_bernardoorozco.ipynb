{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a212d38b",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "\n",
    "#### <center> **Final Project: Machine Learning** </center>\n",
    "---\n",
    "\n",
    "**Date**: November, 2025\n",
    "\n",
    "**Student Name**: Juan Bernardo Orozco Quirarte\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ddd91e",
   "metadata": {},
   "source": [
    "# Creamos Sesion de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d6984b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/24 02:54:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, col\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ML: ALS\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"INFO\")\n",
    "\n",
    "# Optimization (reduce the number of shuffle partitions)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1be57",
   "metadata": {},
   "source": [
    "# 1. Machine Learning Algorithm to use (10 pts)\n",
    "\n",
    "**Problema Seleccionado:** Sistema de Recomendación (Recommendation System).\n",
    "\n",
    "**Justificación:**\n",
    "Elegí resolver un problema de recomendación porque es una de las aplicaciones más prácticas y comunes del Big Data hoy en día (como en Netflix o Amazon). El objetivo es predecir qué libros le gustarían a un usuario basándose en sus calificaciones pasadas, ayudando a filtrar información relevante en un catálogo inmenso.\n",
    "\n",
    "**Algoritmo Seleccionado:**\n",
    "Utilizaré **Alternating Least Squares (ALS)**. Este algoritmo de Filtrado Colaborativo es ideal para este problema porque factoriza la matriz de usuarios y productos para encontrar patrones latentes, y está optimizado en Spark para trabajar con grandes volúmenes de datos dispersos.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Dataset Description (20 pts)\n",
    "\n",
    "**Fuente del Dataset:**\n",
    "El dataset utilizado es el **\"Book-Crossing Dataset\"**, obtenido de [Kaggle](https://www.kaggle.com/ruchi798/bookcrossing-dataset).\n",
    "\n",
    "**Contenido:**\n",
    "El dataset original consta de tres archivos CSV: Usuarios, Libros (con metadatos como Título y Autor) y Calificaciones (Ratings).\n",
    "\n",
    "**Estadísticas del Dataset (Analizadas con PySpark):**\n",
    "Para este proyecto, nos enfocamos en el archivo de *Ratings*, filtrando calificaciones explícitas (escala 1-10). Despues de filtrar por usuarios con más de 3 ratings y libros con mas de 5 nos queda lo siguiente.\n",
    "\n",
    "* **Tamaño del dataset (filas):** 1149780 registros crudos y 166646 registros despues de mi limpieza.\n",
    "* **Usuarios únicos:** 19966 usuarios post limpieza.\n",
    "* **Libros (Items) únicos:** 14520 libros distintos post limpiea.\n",
    "\n",
    "**A Aclarar**: \n",
    "Hay más de un millon de registros y más de 100k usuarios y libros, pero hay libros sin ratings y usarios que no han calificado ningun libro, al igual que hay registros con rating 0, los rating con 0 no son ratings explicitamente, solo es un indicativo que el usario compro el libro pero no lo ha calificado ahun, por lo que no nos sirven esos registros. Por eso se reduce el tamaño del dataset, la limpieza nos ayuda a hacerlo más preciso para usuarios activos y libros calificados y asi evitar sesgos. \n",
    "\n",
    "**Nota sobre los datos:**\n",
    "Al ser un sistema de recomendación, la métrica clave es la interacción Usuario-Libro. Los datos representan feedback explícito (estrellas del 1 al 10), lo cual permite al modelo predecir una calificación exacta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8faf9d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros crudos 1149780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Carga del dataset y definicion del esquema\n",
    "from bernardoorozco.spark_utils import SparkUtils\n",
    "\n",
    "schema_cols = [(\"User-ID\", \"int\"), (\"ISBN\", \"string\"), (\"Book-Rating\", \"int\")]\n",
    "schema= SparkUtils.generate_schema(schema_cols)\n",
    "\n",
    "\n",
    "df_ratings = spark.read \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .option(\"delimiter\", \";\") \\\n",
    "                    .schema(schema) \\\n",
    "                    .csv(\"/opt/spark/work-dir/lib/bernardoorozco/ml/BX-Book-Ratings.csv\")  \n",
    "\n",
    "print(f\"Total de registros crudos {df_ratings.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf5817e",
   "metadata": {},
   "source": [
    "## Limpieza y filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4576985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total calificaciones (1-10): 166646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios únicos: 19966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libros únicos: 14520\n"
     ]
    }
   ],
   "source": [
    "df_ratings = df_ratings \\\n",
    "    .withColumnRenamed(\"User-ID\", \"user_idf\") \\\n",
    "    .withColumnRenamed(\"ISBN\", \"isbn_str\") \\\n",
    "    .withColumnRenamed(\"Book-Rating\", \"rating\")\n",
    "df_clean = df_ratings.filter(col(\"rating\") > 0) # Rating = 0 representa mas del 50% del dataset porque 0 son compras del libro mas no ratings\n",
    "\n",
    "book_counts = df_clean.groupBy(\"isbn_str\").agg(count(\"rating\").alias(\"book_count\"))\n",
    "popular_books = book_counts.filter(col(\"book_count\") >= 5) # Minimo 5 ratings por libro\n",
    "\n",
    "user_counts = df_clean.groupBy(\"user_idf\").agg(count(\"rating\").alias(\"user_count\"))\n",
    "active_users = user_counts.filter(col(\"user_count\") >= 3) # Minimo 3 ratings por user\n",
    "\n",
    "# Solo nos quedamos con la interseccion\n",
    "df_optimized = df_clean \\\n",
    "    .join(popular_books, \"isbn_str\", \"inner\") \\\n",
    "    .join(active_users, \"user_idf\", \"inner\") \\\n",
    "    .select(df_clean[\"user_idf\"], df_clean[\"isbn_str\"], df_clean[\"rating\"])\n",
    "\n",
    "print(f\"Total calificaciones (1-10): {df_optimized.count()}\")\n",
    "print(f\"Usuarios únicos: {df_optimized.select('user_idf').distinct().count()}\")\n",
    "print(f\"Libros únicos: {df_optimized.select('isbn_str').distinct().count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2774b39e",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7017a386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexando usuarios y libros...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ISBN a integer e indices numericos a usuarios\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "indexer_user = StringIndexer(inputCol=\"user_idf\", outputCol=\"user_id\", handleInvalid=\"skip\")\n",
    "indexer_book = StringIndexer(inputCol=\"isbn_str\", outputCol=\"book_id\", handleInvalid=\"skip\")\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer_user, indexer_book])\n",
    "\n",
    "print(\"Indexando usuarios y libros...\")\n",
    "model_pipeline = pipeline.fit(df_optimized)\n",
    "df_final = model_pipeline.transform(df_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a33f6f",
   "metadata": {},
   "source": [
    "# 3. ML Training process (30 points)\n",
    "\n",
    "Justificación de Hiperparámetros:\n",
    "\n",
    "rank=20 y maxIter=20: Elegí estos valores para darle suficiente complejidad al modelo y tiempo para aprender, sin que tarde demasiado en procesar.\n",
    "\n",
    "regParam=0.25: Usé una regularización un poco alta para filtrar el ruido, ya que muchos usuarios califican pocos libros y eso puede confundir al modelo.\n",
    "\n",
    "implicitPrefs=False: Fundamental, porque estamos usando calificaciones reales (1 a 10) y no datos implícitos como clics.\n",
    "\n",
    "coldStartStrategy=\"drop\": Para que la evaluación no falle si aparecen usuarios nuevos en el test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6959651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo de libros...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 02:55:59 WARN DAGScheduler: Broadcasting large task binary with size 1200.2 KiB\n",
      "25/11/24 02:56:00 WARN DAGScheduler: Broadcasting large task binary with size 1201.7 KiB\n",
      "25/11/24 02:56:01 WARN DAGScheduler: Broadcasting large task binary with size 1203.2 KiB\n",
      "25/11/24 02:56:01 WARN DAGScheduler: Broadcasting large task binary with size 1204.6 KiB\n",
      "25/11/24 02:56:02 WARN DAGScheduler: Broadcasting large task binary with size 1203.5 KiB\n",
      "25/11/24 02:56:03 WARN DAGScheduler: Broadcasting large task binary with size 1204.9 KiB\n",
      "25/11/24 02:56:04 WARN DAGScheduler: Broadcasting large task binary with size 1205.7 KiB\n",
      "25/11/24 02:56:05 WARN DAGScheduler: Broadcasting large task binary with size 1209.1 KiB\n",
      "25/11/24 02:56:06 WARN DAGScheduler: Broadcasting large task binary with size 1210.6 KiB\n",
      "25/11/24 02:56:07 WARN DAGScheduler: Broadcasting large task binary with size 1212.1 KiB\n",
      "25/11/24 02:56:08 WARN DAGScheduler: Broadcasting large task binary with size 1213.7 KiB\n",
      "25/11/24 02:56:09 WARN DAGScheduler: Broadcasting large task binary with size 1215.2 KiB\n",
      "25/11/24 02:56:09 WARN DAGScheduler: Broadcasting large task binary with size 1216.8 KiB\n",
      "25/11/24 02:56:10 WARN DAGScheduler: Broadcasting large task binary with size 1218.3 KiB\n",
      "25/11/24 02:56:11 WARN DAGScheduler: Broadcasting large task binary with size 1219.8 KiB\n",
      "25/11/24 02:56:12 WARN DAGScheduler: Broadcasting large task binary with size 1221.4 KiB\n",
      "25/11/24 02:56:13 WARN DAGScheduler: Broadcasting large task binary with size 1222.9 KiB\n",
      "25/11/24 02:56:14 WARN DAGScheduler: Broadcasting large task binary with size 1224.4 KiB\n",
      "25/11/24 02:56:15 WARN DAGScheduler: Broadcasting large task binary with size 1226.0 KiB\n",
      "25/11/24 02:56:15 WARN DAGScheduler: Broadcasting large task binary with size 1227.5 KiB\n",
      "25/11/24 02:56:16 WARN DAGScheduler: Broadcasting large task binary with size 1229.0 KiB\n",
      "25/11/24 02:56:17 WARN DAGScheduler: Broadcasting large task binary with size 1230.6 KiB\n",
      "25/11/24 02:56:18 WARN DAGScheduler: Broadcasting large task binary with size 1232.1 KiB\n",
      "25/11/24 02:56:19 WARN DAGScheduler: Broadcasting large task binary with size 1233.7 KiB\n",
      "25/11/24 02:56:19 WARN DAGScheduler: Broadcasting large task binary with size 1235.2 KiB\n",
      "25/11/24 02:56:20 WARN DAGScheduler: Broadcasting large task binary with size 1236.7 KiB\n",
      "25/11/24 02:56:21 WARN DAGScheduler: Broadcasting large task binary with size 1238.3 KiB\n",
      "25/11/24 02:56:22 WARN DAGScheduler: Broadcasting large task binary with size 1239.8 KiB\n",
      "25/11/24 02:56:23 WARN DAGScheduler: Broadcasting large task binary with size 1241.3 KiB\n",
      "25/11/24 02:56:23 WARN DAGScheduler: Broadcasting large task binary with size 1242.9 KiB\n",
      "25/11/24 02:56:24 WARN DAGScheduler: Broadcasting large task binary with size 1244.4 KiB\n",
      "25/11/24 02:56:25 WARN DAGScheduler: Broadcasting large task binary with size 1245.9 KiB\n",
      "25/11/24 02:56:26 WARN DAGScheduler: Broadcasting large task binary with size 1247.5 KiB\n",
      "25/11/24 02:56:27 WARN DAGScheduler: Broadcasting large task binary with size 1249.0 KiB\n",
      "25/11/24 02:56:27 WARN DAGScheduler: Broadcasting large task binary with size 1250.5 KiB\n",
      "25/11/24 02:56:28 WARN DAGScheduler: Broadcasting large task binary with size 1252.1 KiB\n",
      "25/11/24 02:56:29 WARN DAGScheduler: Broadcasting large task binary with size 1253.6 KiB\n",
      "25/11/24 02:56:30 WARN DAGScheduler: Broadcasting large task binary with size 1255.2 KiB\n",
      "25/11/24 02:56:31 WARN DAGScheduler: Broadcasting large task binary with size 1256.7 KiB\n",
      "25/11/24 02:56:32 WARN DAGScheduler: Broadcasting large task binary with size 1258.2 KiB\n",
      "25/11/24 02:56:32 WARN DAGScheduler: Broadcasting large task binary with size 1259.8 KiB\n",
      "25/11/24 02:56:33 WARN DAGScheduler: Broadcasting large task binary with size 1261.3 KiB\n",
      "25/11/24 02:56:34 WARN DAGScheduler: Broadcasting large task binary with size 1262.8 KiB\n",
      "25/11/24 02:56:35 WARN DAGScheduler: Broadcasting large task binary with size 1264.4 KiB\n",
      "25/11/24 02:56:36 WARN DAGScheduler: Broadcasting large task binary with size 1265.9 KiB\n",
      "25/11/24 02:56:36 WARN DAGScheduler: Broadcasting large task binary with size 1267.4 KiB\n",
      "25/11/24 02:56:37 WARN DAGScheduler: Broadcasting large task binary with size 1269.6 KiB\n",
      "25/11/24 02:56:38 WARN DAGScheduler: Broadcasting large task binary with size 1268.0 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "training, test= df_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# ALS\n",
    "als = ALS(\n",
    "    userCol=\"user_id\", \n",
    "    itemCol=\"book_id\", \n",
    "    ratingCol=\"rating\", \n",
    "    implicitPrefs=False,\n",
    "    nonnegative=True,\n",
    "    coldStartStrategy=\"drop\",\n",
    "    rank=20, \n",
    "    maxIter=20, \n",
    "    regParam=0.25\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "print(\"Entrenando modelo de libros...\")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aea909",
   "metadata": {},
   "source": [
    "## Persistencia modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deca1d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 02:56:42 WARN DAGScheduler: Broadcasting large task binary with size 1500.1 KiB\n",
      "25/11/24 02:56:51 WARN DAGScheduler: Broadcasting large task binary with size 1498.6 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: /opt/spark/work-dir/data/mlmodels/als/als_books\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo\n",
    "model_path = \"/opt/spark/work-dir/data/mlmodels/als/als_books\"\n",
    "model.write().overwrite().save(model_path)\n",
    "print(f\"Modelo guardado en: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb176860",
   "metadata": {},
   "source": [
    "# 4. ML Evaluation (20 points)\n",
    "\n",
    "Métrica utilizada: Elegí RMSE (Root Mean Square Error).\n",
    "\n",
    "¿Por qué? Porque estoy prediciendo un número exacto (estrellas del 1 al 10). El RMSE me dice, en promedio, por cuántos puntos se equivocó mi predicción respecto a la realidad.\n",
    "\n",
    "Resultado: Obtuve un error de 1.88.\n",
    "\n",
    "Interpretación: Significa que el modelo suele desviarse menos de 2 estrellas de la calificación real, lo cual es un resultado decente considerando lo subjetivos que son los gustos en libros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "388d0fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo desde: /opt/spark/work-dir/data/mlmodels/als/als_books...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 02:57:13 WARN DAGScheduler: Broadcasting large task binary with size 1228.0 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Error promedio en estrellas): 1.88\n",
      "Predicción vs Realidad:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 02:57:25 WARN DAGScheduler: Broadcasting large task binary with size 1220.8 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----------+\n",
      "|user_id|  isbn_str|rating|prediction|\n",
      "+-------+----------+------+----------+\n",
      "|   8576|0553264990|     5| 3.3146055|\n",
      "|  16447|0676973655|     3|  4.252397|\n",
      "|  13305|8445071408|     7| 7.5595984|\n",
      "|   7978|0316748641|     7|  5.307867|\n",
      "|   5607|0451208080|     8|  8.249564|\n",
      "|  10887|0061099325|     4| 5.9868307|\n",
      "|   5255|3257233051|     9|  7.727029|\n",
      "|   2151|0060977493|     7| 7.0600786|\n",
      "|   2151|0446606383|     6| 6.6108456|\n",
      "|   2151|0449006522|     6| 7.9352884|\n",
      "|   2151|0553580388|     8| 7.3770123|\n",
      "|   2151|155874262X|     5| 7.9744673|\n",
      "|   4569|0060987103|     8| 7.5712585|\n",
      "|   4569|0804111359|     8|  7.497422|\n",
      "|    740|0142001740|     9| 7.6105204|\n",
      "|    740|0380789035|    10|  7.520733|\n",
      "|    740|0439064872|     9|  7.929495|\n",
      "|   9490|0380815923|    10|  5.783345|\n",
      "|   4116|1573225126|     5|  6.094401|\n",
      "|   9525|0425156842|     7|  5.624893|\n",
      "|   9525|0452277337|     7|  5.215217|\n",
      "|   9525|0671021001|     6|  6.048205|\n",
      "|   6346|039914739X|     3| 5.0458856|\n",
      "|   6346|081296666X|     5|  6.797931|\n",
      "|   5422|006017143X|     9|  8.289034|\n",
      "|   1341|0060558865|     8|  7.762801|\n",
      "|   1341|0345369068|     8|  8.560911|\n",
      "|   1341|0553575538|     7| 7.1986203|\n",
      "|   1341|0553583441|     7|  7.497919|\n",
      "|  12821|0399144463|     2|   5.34614|\n",
      "+-------+----------+------+----------+\n",
      "only showing top 30 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "\n",
    "\n",
    "# Cargar el modelo desde el disco\n",
    "print(f\"Cargando modelo desde: {model_path}...\")\n",
    "loaded_model = ALSModel.load(model_path)\n",
    "\n",
    "\n",
    "predictions = loaded_model.transform(test)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"rating\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"RMSE (Error promedio en estrellas): {rmse:.2f}\")\n",
    "\n",
    "# Muestra visual\n",
    "print(\"Predicción vs Realidad:\")\n",
    "predictions.select(\"user_id\", \"isbn_str\", \"rating\", \"prediction\").show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b97b6bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando recomendaciones para el Usuario ID: 276747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "TOP 5 libros recomendados para: 276747\n",
      "------------------------------------------------------------\n",
      "ISBN: 0440471478 | Predicción: 10.00 / 10\n",
      "ISBN: 0312099045 | Predicción: 10.00 / 10\n",
      "ISBN: 0836213319 | Predicción: 10.00 / 10\n",
      "ISBN: 0452261368 | Predicción: 10.00 / 10\n",
      "ISBN: 0743467558 | Predicción: 10.00 / 10\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "target_user = 276747 \n",
    "\n",
    "print(f\"Generando recomendaciones para el Usuario ID: {target_user}\")\n",
    "\n",
    "# Crear DataFrame solo con el usuario\n",
    "request_df = spark.createDataFrame([(target_user,)], [\"user_idf\"])\n",
    "\n",
    "try:\n",
    "    # Extraemos el transformador de usuarios (Stage 0) para convertir el ID.\n",
    "    user_indexer_model = model_pipeline.stages[0]\n",
    "    request_indexed = user_indexer_model.transform(request_df)\n",
    "    \n",
    "    if request_indexed.count() == 0:\n",
    "        print(\"Usuario desconocido para el modelo (No existe en los datos de entrenamiento).\")\n",
    "    else:\n",
    "        # Generar 5 recomendaciones usando el indice interno\n",
    "        recommendations = loaded_model.recommendForUserSubset(request_indexed, 5)\n",
    "        \n",
    "        # Para decodificar los libros necesitamos el Stage 1\n",
    "        book_indexer_model = model_pipeline.stages[1] \n",
    "        book_labels = book_indexer_model.labels\n",
    "        \n",
    "        if recommendations.count() > 0:\n",
    "            recs_row = recommendations.collect()[0]\n",
    "            book_list = recs_row['recommendations'] \n",
    "            \n",
    "            print(\"-\" * 60)\n",
    "            print(f\"TOP 5 libros recomendados para: {target_user}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            for item in book_list:\n",
    "                book_idx = int(item['book_id'])\n",
    "                rating = item['rating']\n",
    "                \n",
    "                final_rating = min(max(rating, 1.0), 10.0)  # Para que no se pase de 10 porque a ALS le vale pasarse\n",
    "                \n",
    "                # Recuperar ISBN real usando los labels del stage de libros\n",
    "                real_isbn = book_labels[book_idx]\n",
    "                \n",
    "                print(f\"ISBN: {real_isbn} | Predicción: {final_rating:.2f} / 10\")\n",
    "        else:\n",
    "            print(\"El modelo no pudo generar recomendaciones para este usuario.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error en demo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc91b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
