{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ab648c-f591-4b23-8df8-05e671f1fda2",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 07**: Machine learning final project\n",
    "\n",
    "**Date**: November 23rd 2025\n",
    "\n",
    "**Student Name**: Jaime Antonio Contreras Barragan\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604e1dd-6dbb-4090-909d-6346a748fdbd",
   "metadata": {},
   "source": [
    "# Create SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02dc7210-9c3f-44b9-83c9-7107bc3544e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/24 04:10:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Final Project ML\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"INFO\")\n",
    "# Optimization (reduce the number of shuffle partitions)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57afc74-e115-4b04-9a8f-40bd61ddcd5d",
   "metadata": {},
   "source": [
    "# ML algorimo a usar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eeab1b-6c34-4c39-aa21-855bd431d7e1",
   "metadata": {},
   "source": [
    "Primero que nada quiero poder adivinar si una reseña va a ser positiva, negativa o neutral, sin tener que leer la reseña del celular como tal. Para empezar tenemos 3 clasificaciones en el propio dataset, por lo tanto ya sabemos que tipo de algoritmo tenemos que usar, en este caso el de clasificacion.\n",
    "### SVM\n",
    "Ahora, porque SVM? Para empezar ya contamos como tal con las clases, y son 3, ademas que como tal quiero que clasifique, no que me de una probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0a9163-b362-479b-9a2a-a6681ca48cf6",
   "metadata": {},
   "source": [
    "# Descripcion de dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43774aae-768f-4e1f-8047-afd4031bced8",
   "metadata": {},
   "source": [
    "Kaggle link: https://www.kaggle.com/datasets/mohankrishnathalla/mobile-reviews-sentiment-and-specification\n",
    "\n",
    "Es el mismo dataset de las practicas finales anteriores.\n",
    "Este es un dataset de reviews de celulares 2024-2025. \n",
    "En este se tiene en cuenta la review como tal, calificacion general, y de caracteristicas del telefono, datos de reseñador, (y lo que nos importa para esta practica) datos relacionados con la reseña, longitud, cantidad de palabras, votos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9261ef46-1f8b-46ce-8468-b3527a9cbb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9824\n",
      "-rwxrwxrwx 1 root root 10056684 Oct 23 03:20 \u001b[0m\u001b[01;32mMobile_Reviews_Sentiment.csv\u001b[0m*\n",
      "drwxr-xr-x 1 root root     4096 Nov 16 23:30 \u001b[01;34m_spark_metadata\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls -l /opt/spark/work-dir/data/Mobile_Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d12e1cb-3003-4289-8963-c5e25bcd5f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "| Positive|27540|\n",
      "|  Neutral|12549|\n",
      "| Negative| 9911|\n",
      "+---------+-----+\n",
      "\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,desc,count, rand\n",
    "from jaimodule.spark_utils import SparkUtils\n",
    "\n",
    "schema = SparkUtils.generate_schema([\n",
    "    (\"review_id\",\"int\"),\n",
    "    (\"customer_name\",\"string\"),\n",
    "    (\"age\", \"int\"),\n",
    "    (\"brand\", \"string\"),\n",
    "    (\"model\", \"string\"),\n",
    "    (\"price_usd\", \"float\"),\n",
    "    (\"price_local\", \"string\"),\n",
    "    (\"currency\", \"string\"),\n",
    "    (\"exchange_rate_to_usd\", \"float\"),\n",
    "    (\"rating\", \"int\"),\n",
    "    (\"review_text\", \"string\"),\n",
    "    (\"sentiment\", \"string\"),\n",
    "    (\"country\", \"string\"),\n",
    "    (\"language\", \"string\"),\n",
    "    (\"review_date\", \"date\"),\n",
    "    (\"verified_purchase\", \"boolean\"),\n",
    "    (\"battery_life_rating\", \"int\"),\n",
    "    (\"camera_rating\", \"int\"),\n",
    "    (\"performance_rating\", \"int\"),\n",
    "    (\"design_rating\", \"int\"),\n",
    "    (\"display_rating\", \"int\"),\n",
    "    (\"review_length\", \"int\"),\n",
    "    (\"word_count\", \"int\"),\n",
    "    (\"helpful_votes\", \"int\"),\n",
    "    (\"source\", \"string\")\n",
    "])\n",
    "\n",
    "# Import your module\n",
    "#tuve que poner el path completo por el metadata spark\n",
    "base_path = \"/opt/spark/work-dir/data/Mobile_Reviews/Mobile_Reviews_Sentiment.csv\"\n",
    "mobile_reviews_df = spark.read \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .schema(schema) \\\n",
    "                .csv(base_path) \n",
    "\n",
    "data_df= mobile_reviews_df.select(\n",
    "    col(\"sentiment\"),\n",
    "    col(\"word_count\"),\n",
    "    col(\"review_length\"),\n",
    "    col(\"helpful_votes\")\n",
    "    #col(\"price_usd\")\n",
    ")\n",
    "\n",
    "data_df.groupBy(\"sentiment\").count().show()\n",
    "print(data_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1de1f-9a58-46cd-9d74-ced170172d22",
   "metadata": {},
   "source": [
    "Como vemos el dataset no esta balanceado, se podria decir que esta entre 1/2, 1/4 y 1/5 mas o menos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0135f368-8ad0-4b70-b3c2-36f2b2d14c35",
   "metadata": {},
   "source": [
    "# ML Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416392f-2d68-4602-861c-c4e134ceba14",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d4ae8-daaa-4c12-b9e9-183944ec4f16",
   "metadata": {},
   "source": [
    "## Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5393765-0e4e-4fd4-b209-f607af916844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------------+-------------+\n",
      "|sentiment|word_count|review_length|helpful_votes|\n",
      "+---------+----------+-------------+-------------+\n",
      "| Positive|        13|           69|            5|\n",
      "|  Neutral|        14|           71|            1|\n",
      "| Negative|         7|           45|            2|\n",
      "|  Neutral|         9|           60|            2|\n",
      "|  Neutral|        13|           82|            2|\n",
      "| Negative|        10|           46|            2|\n",
      "| Negative|         9|           56|            2|\n",
      "| Negative|         9|           57|            1|\n",
      "| Positive|        10|           55|            3|\n",
      "|  Neutral|        11|           62|            1|\n",
      "+---------+----------+-------------+-------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "positive_df = data_df.filter(col(\"sentiment\") == \"Positive\").limit(9911)\n",
    "neutral_df  = data_df.filter(col(\"sentiment\") == \"Neutral\").limit(9911)\n",
    "negative_df = data_df.filter(col(\"sentiment\") == \"Negative\").limit(9911)\n",
    "\n",
    "balanced_df = positive_df.union(negative_df).union(neutral_df)\n",
    "ordered_df = balanced_df.orderBy(rand())\n",
    "\n",
    "#Aqui solo balanceo el df, basandome en el grupo mas pequeño para que sean del mismo tamaño\n",
    "print(ordered_df.count())\n",
    "ordered_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a8deb-9392-4196-9c78-7e2fa895faf0",
   "metadata": {},
   "source": [
    "# Assemble the features into a single vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3d1a21-aff6-4021-9c14-7c3d84364a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|label|features       |\n",
      "+-----+---------------+\n",
      "|2.0  |[13.0,69.0,5.0]|\n",
      "|1.0  |[14.0,71.0,1.0]|\n",
      "|0.0  |[7.0,45.0,2.0] |\n",
      "|1.0  |[9.0,60.0,2.0] |\n",
      "|1.0  |[13.0,82.0,2.0]|\n",
      "+-----+---------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"label\")\n",
    "indexer_model = indexer.fit(ordered_df)\n",
    "indexed_df = indexer_model.transform(ordered_df)\n",
    "\n",
    "#assembler = VectorAssembler(inputCols = [\"word_count\",\"review_length\",\"helpful_votes\",\"price_usd\"],outputCol = \"features\")\n",
    "#Se elegieron las siguierntes columnas por lo siguiente:\n",
    "#-Descartamos ratings, ya que en la relacion entre buen rating y mal rating es obvio, para que no sea el unico dato importante\n",
    "#-utilizamos todos los datos relacionados al review, sin tocar el review como tal, ya que tendriamos que tokenizarlo\n",
    "#-Word count: Cantidad de palabras\n",
    "#-Review length: Longitud de la review\n",
    "#-helpful_votes: Si a sido relevante para otros usuarios\n",
    "#Utilizamos estos parametros relacionados al review para sin necesitar el review como tal poder saber en que categoria caera.\n",
    "assembler = VectorAssembler(inputCols = [\"word_count\",\"review_length\",\"helpful_votes\"],outputCol = \"features\")\n",
    "\n",
    "data_final = assembler.transform(indexed_df).select(\"label\", \"features\")\n",
    "\n",
    "data_final.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52829029-6d32-4d4e-b9e4-854eaed264e8",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d6a200d-7a98-4dc2-be03-f18738c12407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 7886|\n",
      "|  1.0| 7901|\n",
      "|  2.0| 7879|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#PARA TEST Y PARA PRUEBA\n",
    "train_df, test_df = data_final.randomSplit([0.8,0.2], seed = 57)\n",
    "train_df.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f613d-a10b-41cf-b465-8633faffe04b",
   "metadata": {},
   "source": [
    "## Create ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843d66e3-e05b-43a1-be66-f38a75f38635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import OneVsRest, LinearSVC\n",
    "\n",
    "lsvc = LinearSVC(maxIter=50, regParam = 0.07) #0.73\n",
    "#lsvc = LinearSVC(maxIter=25, regParam = 0.1) #0.724\n",
    "#lsvc = LinearSVC(maxIter=50, regParam = 0.1) #0.728\n",
    "#lsvc = LinearSVC(maxIter=50, regParam = 0.05) 0.727\n",
    "#lsvc = LinearSVC(maxIter=50, regParam = 0.01) 0.724\n",
    "#lsvc = LinearSVC(maxIter=25, regParam = 0.05) \n",
    "#lsvc = LinearSVC(maxIter=100, regParam = 0.01) 0.75\n",
    "#lsvc = LinearSVC(maxIter=10, regParam = 0.01) 0.723\n",
    "ovr = OneVsRest(classifier=lsvc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a93903-7e77-4613-855d-2c9a741c4011",
   "metadata": {},
   "source": [
    "## Train ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8dc826-860d-463f-b9d2-c3fad7051c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 04:10:39 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    }
   ],
   "source": [
    "ovr_model = ovr.fit(train_df)\n",
    "\n",
    "predictions = ovr_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f01a62-08a0-4420-81ff-af58d2473617",
   "metadata": {},
   "source": [
    "## Persist the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083edbaa-45ce-48da-a143-ba56e41304d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "ova_model_path = \"/opt/spark/work-dir/data/mlmodels/svm/svm_ova_fp\"\n",
    "ovr_model.write().overwrite().save(ova_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea584122-01ad-427d-b1b0-8ea1391004e4",
   "metadata": {},
   "source": [
    "# ML EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f3deaa-168e-43d6-ae43-f758339a9a52",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cfc247a-9902-481d-9b7b-d5654800b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7285313993736607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7280765961149458\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions,\n",
    "                             {evaluator.metricName: \"accuracy\"})\n",
    "#Como esta balanceado usamos este\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#no balanceados\n",
    "f1 = evaluator.evaluate(predictions,\n",
    "                       {evaluator.metricName: \"f1\"})\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "477a7d78-c0e2-41f6-b59f-0456e4d987a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SparkContext.stop of <SparkContext master=spark://spark-master:7077 appName=Final Project ML>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ec9a4-f082-4ec8-bf4e-e8f4e64e0930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
