{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc05522d",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Streaming_Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "\n",
    "#### <center> **Final project: Machine Learning** </center>\n",
    "<div style=\"text-align: center;\">\n",
    "    <br>\n",
    "    <strong>Estudiante:</strong> Juan Pablo Quintero <br>\n",
    "    <strong>Fecha:</strong> 23 de Noviembre de 2025 <br>\n",
    "    <strong>Profesor:</strong> Pablo Camarrilo Ramirez "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c952a-cd72-4ae0-928e-cf4ff8aed102",
   "metadata": {},
   "source": [
    "# Iniciamos Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dbe5853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/25 02:29:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ML:Proyecto Final_Random Forest\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"INFO\")\n",
    "\n",
    "# Optimization (reduce the number of shuffle partitions)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32af42-1739-408e-909a-3ac62914d50b",
   "metadata": {},
   "source": [
    "# ML Algoritmo a Usar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf503dbd-0560-43b4-8cba-381de8ccc804",
   "metadata": {},
   "source": [
    "Voy usar el Ml de clasificacion, debido a que quiero ver el nivel de trafico que enfrenta un repartidor de comida rapida.\n",
    "Este problema me parece interesnate por que quien no a pedido por una aplicacion de comida rapida o a pedido un servicio de comida rapida yo creo que todos, entonces para resolver la poblematica de que la comida te llegue fria , es crucial saber si el trafico va a estar **Alto**, **Medio**, o **Bajo** esto con la unnica finalidad de la satisfaccion del cliente y que este al tanto de que tanto podria tardar su pedido por el trafico. <br>\n",
    "El algoritmo seleccionado : **Random Forest**, elegi random forest por que es bueno tanto manejando variables numericas como la distancia y categoricas como el clima, y la zona."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e026d87-406a-4145-94a1-dcf9ce816054",
   "metadata": {},
   "source": [
    "# Descripcion del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe39db3-5929-4992-a5b7-5d62975e4f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- distance_km: float (nullable = true)\n",
      " |-- delivery_time_min: float (nullable = true)\n",
      " |-- traffic_level: string (nullable = true)\n",
      " |-- route_length_km: float (nullable = true)\n",
      " |-- delivery_mode: string (nullable = true)\n",
      " |-- weather: string (nullable = true)\n",
      " |-- order_time: timestamp (nullable = true)\n",
      " |-- restaurant_zone: string (nullable = true)\n",
      " |-- customer_zone: string (nullable = true)\n",
      "\n",
      "+--------+-----------+-----------------+-------------+---------------+-------------+-------+-------------------+---------------+-------------+\n",
      "|order_id|distance_km|delivery_time_min|traffic_level|route_length_km|delivery_mode|weather|         order_time|restaurant_zone|customer_zone|\n",
      "+--------+-----------+-----------------+-------------+---------------+-------------+-------+-------------------+---------------+-------------+\n",
      "|       1|       7.97|             63.8|         High|           9.75|      Bicycle|  Clear|2025-01-01 15:29:00|          South|        North|\n",
      "|       2|        0.9|              7.6|         High|           1.28|          Car| Cloudy|2025-01-03 00:47:00|           West|        North|\n",
      "|       3|      11.12|             78.0|       Medium|          16.65|         Bike|  Rainy|2025-01-04 17:32:00|          South|      Central|\n",
      "|       4|        4.9|             24.8|          Low|           5.25|      Scooter|  Rainy|2025-01-01 14:12:00|        Central|      Central|\n",
      "|       5|      10.04|             56.0|         High|          11.34|          Car|  Rainy|2025-01-02 16:50:00|           West|        North|\n",
      "|       6|      10.96|             76.8|         High|          13.62|          Car|  Windy|2025-01-02 09:56:00|           West|        North|\n",
      "|       7|        9.6|             54.4|          Low|          13.32|         Bike|  Windy|2025-01-03 00:29:00|        Central|        North|\n",
      "|       8|       6.24|             52.9|          Low|           8.41|         Bike| Cloudy|2025-01-02 21:36:00|          South|      Central|\n",
      "|       9|       9.98|             81.4|       Medium|          14.87|      Bicycle|  Rainy|2025-01-01 08:19:00|        Central|         West|\n",
      "|      10|       2.48|             17.1|         High|           3.38|          Car|  Windy|2025-01-01 09:28:00|          South|        North|\n",
      "|      11|       7.23|             47.7|       Medium|           7.63|         Bike|  Rainy|2025-01-03 15:24:00|           West|      Central|\n",
      "|      12|       6.65|             27.8|         High|           6.69|         Bike|  Rainy|2025-01-03 06:47:00|        Central|         West|\n",
      "|      13|      11.42|             83.4|       Medium|          13.97|          Car|  Rainy|2025-01-03 05:24:00|        Central|        South|\n",
      "|      14|       1.26|              9.9|          Low|           1.55|      Bicycle|  Windy|2025-01-03 18:37:00|          South|        North|\n",
      "|      15|       9.88|             56.6|       Medium|          12.45|         Bike| Cloudy|2025-01-03 04:12:00|          North|      Central|\n",
      "|      16|       4.69|             23.2|          Low|           4.86|      Scooter|  Clear|2025-01-04 04:16:00|          North|        North|\n",
      "|      17|       7.27|             34.9|         High|           8.66|      Scooter| Cloudy|2025-01-03 14:38:00|        Central|         West|\n",
      "|      18|      10.19|             60.2|         High|          10.24|          Car|  Windy|2025-01-03 02:11:00|          North|        South|\n",
      "|      19|       2.11|              9.2|       Medium|           2.23|      Scooter|  Rainy|2025-01-02 17:10:00|        Central|        North|\n",
      "|      20|       3.12|             18.0|         High|           3.41|      Bicycle|  Windy|2025-01-04 08:23:00|          South|      Central|\n",
      "+--------+-----------+-----------------+-------------+---------------+-------------+-------+-------------------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "Total de registros: 200\n",
      "Columnas: 10\n",
      "+-------------+-----+\n",
      "|traffic_level|count|\n",
      "+-------------+-----+\n",
      "|          Low|   65|\n",
      "|         High|   68|\n",
      "|       Medium|   67|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PabloQuintero.spark_utils import SparkUtils\n",
    "#Definimos el Dataset\n",
    "Repartidor_schema = SparkUtils.generate_schema([\n",
    "    (\"order_id\", \"IntegerType\"),\n",
    "    (\"distance_km\", \"FloatType\"),\n",
    "    (\"delivery_time_min\", \"FloatType\"),\n",
    "    (\"traffic_level\", \"StringType\"),\n",
    "    (\"route_length_km\", \"FloatType\"),\n",
    "    (\"delivery_mode\", \"StringType\"),\n",
    "    (\"weather\", \"StringType\"),\n",
    "    (\"order_time\", \"TimestampType\"),\n",
    "    (\"restaurant_zone\", \"StringType\"),\n",
    "    (\"customer_zone\", \"StringType\")\n",
    "])\n",
    "Repartidor_df = spark.read \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .schema(Repartidor_schema) \\\n",
    "                    .csv(\"/opt/spark/work-dir/data/ml/Random_Forest/\")\n",
    "Repartidor_df.printSchema()\n",
    "Repartidor_df.show()\n",
    "#Tamaño del dataset\n",
    "print(f\"Total de registros: {Repartidor_df.count()}\")\n",
    "print(f\"Columnas: {len(Repartidor_df.columns)}\")\n",
    "#Esta balanceado ? Usando el nivel del trafico\n",
    "Repartidor_df.groupBy(\"traffic_level\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de358d2-96d9-4ad8-a2f6-0d7caa198874",
   "metadata": {},
   "source": [
    "# ML Proceso de entrenamineto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6878df7-2111-469e-93ff-76c4e1e14393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/25 03:17:35 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#Preparando los datos \n",
    "ind_weather = StringIndexer(inputCol=\"weather\", outputCol=\"weather_idx\")\n",
    "ind_mode = StringIndexer(inputCol=\"delivery_mode\", outputCol=\"delivery_mode_idx\")\n",
    "ind_Rzone = StringIndexer(inputCol=\"restaurant_zone\", outputCol=\"restaurant_zone_idx\")\n",
    "\n",
    "indexer_label = StringIndexer(inputCol=\"traffic_level\", outputCol=\"label\")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"distance_km\", \"weather_idx\", \"delivery_mode_idx\", \"restaurant_zone_idx\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=20, maxDepth=5)\n",
    "pipeline = Pipeline(stages=[ind_weather, ind_mode, ind_Rzone, indexer_label, assembler, rf])\n",
    "train_data, test_data = Repartidor_df.randomSplit([0.7, 0.3], seed=42)\n",
    "model = pipeline.fit(train_data)\n",
    "#Guardar el Modelo\n",
    "model.write().overwrite().save(\"food_delivery_rf_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131ae2c-8172-44c7-868e-608bd44ffd0b",
   "metadata": {},
   "source": [
    "# ML Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71a4be66-8b9e-499f-bb03-c9a995e5d781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+----------+--------------------+\n",
      "|traffic_level|label|prediction|         probability|\n",
      "+-------------+-----+----------+--------------------+\n",
      "|       Medium|  2.0|       1.0|[0.34844322344322...|\n",
      "|          Low|  0.0|       0.0|[0.79827393971223...|\n",
      "|       Medium|  2.0|       1.0|[0.35700874615580...|\n",
      "|         High|  1.0|       2.0|[0.17083516483516...|\n",
      "|          Low|  0.0|       2.0|[0.20793452380952...|\n",
      "+-------------+-----+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "Accuracy del modelo: 0.29\n",
      "F1-Score del modelo: 0.29\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "#Predicciones\n",
    "predictions = model.transform(test_data)\n",
    "predictions.select(\"traffic_level\", \"label\", \"prediction\", \"probability\").show(5)\n",
    "#Evaluar modelo\n",
    "evaluator_acc = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_acc.evaluate(predictions)\n",
    "print(f\"Accuracy del modelo: {accuracy:.2f}\")\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "print(f\"F1-Score del modelo: {f1_score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
