{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "\n",
    "#### <center> **Final Project: Machine Learning** </center>\n",
    "---\n",
    "\n",
    "**Date**: October, 2025\n",
    "\n",
    "**Student Name**: Axel Gallardo\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d79f275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/22 19:24:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, round as spark_round\n",
    "\n",
    "# Crear sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ML project\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"5\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c5da61",
   "metadata": {},
   "source": [
    "# Machine Learning algorithm to use\n",
    "\n",
    "En este proyecto el objetivo será predecir el nivel de desempeño académico de un estudiante a partir de sus características personales y hábitos de estudio usando un modelo de clasificación con Random Forest debido a que maneja muy bien relaciones no lineales y variables numéricas codificadas como enteros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200790a",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "Para este proyecto utilizo el conjunto de datos “Students Performance Dataset” disponible públicamente en Kaggle aquí https://www.kaggle.com/datasets/rabieelkharoua/students-performance-dataset\n",
    "\n",
    "El dataset contiene información de 2,392 estudiantes en un CSV de aproximadamente 167 KB organizados en 15 columnas:\n",
    "\n",
    "StudentID\n",
    "\n",
    "Age\n",
    "\n",
    "Gender\n",
    "\n",
    "Ethnicity\n",
    "\n",
    "ParentalEducation\n",
    "\n",
    "ParentalSupport\n",
    "\n",
    "StudyTimeWeekly\n",
    "\n",
    "Absences\n",
    "\n",
    "Tutoring\n",
    "\n",
    "Extracurricular\n",
    "\n",
    "Sports\n",
    "\n",
    "Music\n",
    "\n",
    "Volunteering\n",
    "\n",
    "GPA\n",
    "\n",
    "GradeClass\n",
    "\n",
    "A continuación se demuestra que el dataset no está balanceado basado en la variable objetivo (GradeClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301564d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros: 2392\n",
      "Distribución de la variable objetivo (GradeClass):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n",
      "|GradeClass|count|percentage|\n",
      "+----------+-----+----------+\n",
      "|0.0       |107  |4.47      |\n",
      "|1.0       |269  |11.25     |\n",
      "|2.0       |391  |16.35     |\n",
      "|3.0       |414  |17.31     |\n",
      "|4.0       |1211 |50.63     |\n",
      "+----------+-----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pcamarillor.spark_utils import SparkUtils\n",
    "\n",
    "# Definir el esquema del dataset\n",
    "student_schema = SparkUtils.generate_schema([\n",
    "    (\"StudentID\",         \"int\"),\n",
    "    (\"Age\",               \"int\"),\n",
    "    (\"Gender\",            \"int\"),\n",
    "    (\"Ethnicity\",         \"int\"),\n",
    "    (\"ParentalEducation\", \"int\"),\n",
    "    (\"StudyTimeWeekly\",   \"float\"),\n",
    "    (\"Absences\",          \"int\"),\n",
    "    (\"Tutoring\",          \"int\"),\n",
    "    (\"ParentalSupport\",   \"int\"),\n",
    "    (\"Extracurricular\",   \"int\"),\n",
    "    (\"Sports\",            \"int\"),\n",
    "    (\"Music\",             \"int\"),\n",
    "    (\"Volunteering\",      \"int\"),\n",
    "    (\"GPA\",               \"float\"),\n",
    "    (\"GradeClass\",        \"float\")\n",
    "])\n",
    "\n",
    "student_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(student_schema) \\\n",
    "    .csv(\"/opt/spark/work-dir/data/ProyectoML/\")\n",
    "\n",
    "total_rows = student_df.count()\n",
    "print(f\"Total de registros: {total_rows}\")\n",
    "\n",
    "balance_df = (\n",
    "    student_df\n",
    "      .groupBy(\"GradeClass\")\n",
    "      .agg(count(\"*\").alias(\"count\"))\n",
    "      .withColumn(\n",
    "          \"percentage\",\n",
    "          spark_round(col(\"count\") / total_rows * 100, 2)\n",
    "      )\n",
    "      .orderBy(\"GradeClass\")\n",
    ")\n",
    "\n",
    "print(\"Distribución de la variable objetivo (GradeClass):\")\n",
    "balance_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1940562e",
   "metadata": {},
   "source": [
    "# ML Training process\n",
    "\n",
    "Para entrenar el modelo se reutilizó el flujo de el notebook \"Lecture 19 decision trees random forest\", ajustando los features para ser todas las columnas menos el id y las 2 columnas que serían las objetivo: GPA y GradeClass.\n",
    "\n",
    "La división de entrenamiento sigue siendo 80-20 y la semilla usada para mantener los resultados constantes a cada ejecución fue la 10, inicialmente el numero de arboles y la profundidad eran 3 y 5, pero al necesitar de resultados más precisos se aumentó a 50 y 10, y finalmente se redujo a 25 y 8 por alertas de tareas con un tamaño excesivo\n",
    "\n",
    "Finalmente se guardó el modelo en la ruta \"/opt/spark/work-dir/data/mlmodels/student_performance/rf_gradeclass_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e39b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_cols = [\n",
    "    \"Age\",\n",
    "    \"Gender\",\n",
    "    \"Ethnicity\",\n",
    "    \"ParentalEducation\",\n",
    "    \"StudyTimeWeekly\",\n",
    "    \"Absences\",\n",
    "    \"Tutoring\",\n",
    "    \"ParentalSupport\",\n",
    "    \"Extracurricular\",\n",
    "    \"Sports\",\n",
    "    \"Music\",\n",
    "    \"Volunteering\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "data_with_features = assembler.transform(student_df) \\\n",
    "                               .select(\"GradeClass\", \"features\") \\\n",
    "                               .withColumnRenamed(\"GradeClass\", \"label\")\n",
    "\n",
    "train_df, test_df = data_with_features.randomSplit([0.8, 0.2], seed=10)\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features\",\n",
    "    numTrees=25,\n",
    "    maxDepth=8,\n",
    "    seed=10\n",
    ")\n",
    "\n",
    "rf_model = rf.fit(train_df)\n",
    "\n",
    "model_path = \"/opt/spark/work-dir/data/mlmodels/student_performance/rf_gradeclass_model\"\n",
    "\n",
    "rf_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef739e",
   "metadata": {},
   "source": [
    "# ML Evaluation\n",
    "Para la evaluación se usó el conjunto de prueba previamente generado, y como resultado se obtuvo una precisión y un puntaje F1 de cerca del 70%, resultado similar al obtenido con 50 arboles de 10 de profundidad, por lo que su reducción se vió adecuada.\n",
    "\n",
    "Se debe tener más en cuenta el puntaje de F1 pues al estar desbalanceado el modelo este representa mejor el puntaje de precisión obtenido.\n",
    "\n",
    "Todo esto aplicado al modelo guardado para comprobar que fue correctamente almacenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fe88731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest: 0.6942148760330579\n",
      "F1 Score of Random Forest: 0.6809299888442133\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "rf_model_saved = rf_model.load(model_path)\n",
    "\n",
    "predictions = rf_model_saved.transform(test_df)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, \n",
    "                  {evaluator.metricName: \"accuracy\"})\n",
    "print(f\"Accuracy of Random Forest: {accuracy}\")\n",
    "\n",
    "f1 = evaluator.evaluate(predictions,\n",
    "                {evaluator.metricName: \"f1\"})\n",
    "print(f\"F1 Score of Random Forest: {f1}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0ac99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
