{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Big Data** </center>\n",
    "---\n",
    "### <center> **Autumn 2025** </center>\n",
    "---\n",
    "### <center> **Final Project: Machine Learning** </center>\n",
    "### <center> **Alternating Least Squares (ALS)** </center>\n",
    "---\n",
    "**Profesor**: Pablo Camarillo Ramirez\n",
    "\n",
    "\n",
    "**Estudiante**: Ana Carolina Arellano Valdez "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning algorithm to use: **Alternating Least Squares (ALS)**\n",
    "I would like to solve the problem of books recommendation using the Alternating Least Squares (ALS) algorithm. I am selecting this problem because I used to be a disciplined reader, but the book recommendations that I received from my family or friends were not always aligned with my interests. I found this page called \"goodreads\" and it is to upload your book preferences and reviews. Based on that, the page recommends books that you might like. However, I think that the recommendations could be improved using a more sophisticated algorithm like ALS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "- Source: Kaggle -> https://www.kaggle.com/datasets/tranhungnghiep/goodbooks6m/data?select=ratings.csv\n",
    "- Size of the dataset: Sample of 99 out of 6 million ratings\n",
    "- How many unique users/items are there? \n",
    "  - Unique users: 5\n",
    "  - Unique books: 96\n",
    "\n",
    "The ratings.csv file looks like this:\n",
    "    \n",
    "    |user_id|book_id|rating|\n",
    "    |-------|-------|------|\n",
    "    |1      |258    |5     |\n",
    "    |2      |4081   |4     |\n",
    "    |2      |260    |5     |\n",
    "    |2      |9296   |5     |\n",
    "    |2      |2318   |3     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Training Process\n",
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/06 18:50:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ML: ALS\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"INFO\")\n",
    "\n",
    "# Optimization (reduce the number of shuffle partitions)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|    258|     5|\n",
      "|      2|   4081|     4|\n",
      "|      2|    260|     5|\n",
      "+-------+-------+------+\n",
      "only showing top 3 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from carolinarellano.spark_utils import SparkUtils\n",
    "\n",
    "books_ratings_path = \"/opt/spark/work-dir/data/ml/als\"\n",
    "books_ratings_schema = SparkUtils.generate_schema([(\"user_id\", \"int\"), (\"book_id\", \"int\"), (\"rating\", \"int\")])\n",
    "\n",
    "# Source https://www.kaggle.com/datasets/tranhungnghiep/goodbooks6m/data?select=ratings.csv\n",
    "books_ratings_df = spark.read \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .option(\"delimiter\", \",\") \\\n",
    "                    .schema(books_ratings_schema) \\\n",
    "                    .csv(books_ratings_path)\n",
    "\n",
    "books_ratings_df.printSchema()\n",
    "books_ratings_df.show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items o books (n): 96\n",
      "Number of users (m): 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of items o books (n): {books_ratings_df.groupBy('book_id').count().count()}\")\n",
    "print(f\"Number of users (m): {books_ratings_df.groupBy('user_id').count().count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create & Train the ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model choice:** Alternating Least Squares (ALS)\n",
    "I used Alternating Least Squares (ALS) because the task is classic user–item rating prediction and top-N recommendations. Since the data contains explicit 1–5 ratings, I trained ALS in explicit-feedback mode.\n",
    "\n",
    "**Feaure mapping:**\n",
    "- userCol = \"user_id\"\n",
    "- itemCol = \"book_id\"\n",
    "- ratingCol = \"rating\"\n",
    "\n",
    "**Hyperparameters:**\n",
    "- rank = 3 -> The number of latent factors in the model. I chose 3 because it is a small dataset and I wanted to avoid overfitting.\n",
    "- regParam = 0.1 -> The regularization parameter. I chose 0.1 to prevent overfitting while still allowing the model to learn from the data.\n",
    "- maxIter = 5 -> The number of iterations to run. I chose 5 to balance between training time and model performance.\n",
    "- coldStartStrategy = \"drop\" -> This parameter is set to \"drop\" to ensure that any rows in the validation or test set that contain NaN predictions are dropped. Fortunately, in this small dataset, there are no such rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Recommendation system generated successfully\n",
      "Recommendation system generated successfully\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"user_id\", \n",
    "    itemCol=\"book_id\",\n",
    "    ratingCol=\"rating\", \n",
    "    maxIter=5,  \n",
    "    regParam=0.1,  \n",
    "    rank=3,  \n",
    "    coldStartStrategy=\"drop\",  # Avoids NaN predictions\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting model training...\")\n",
    "model = als.fit(books_ratings_df)\n",
    "print(\"Recommendation system generated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "als_model_path = \"/opt/spark/work-dir/data/mlmodels/als/als_books\"\n",
    "model.write().overwrite().save(als_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 345:================================================>     (89 + 1) / 100]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 345:================================================>     (89 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------------------------------------------------+\n",
      "|user_id|recommendations                                                                                       |\n",
      "+-------+------------------------------------------------------------------------------------------------------+\n",
      "|1      |[{1796, 4.927858}, {258, 4.927858}, {9296, 3.699322}, {8519, 3.699322}, {3753, 3.699322}]             |\n",
      "|2      |[{9296, 4.950305}, {8519, 4.950305}, {3753, 4.950305}, {2686, 4.950305}, {301, 4.950305}]             |\n",
      "|4      |[{1237, 4.9404473}, {693, 4.9404473}, {325, 4.9404473}, {103, 4.9404473}, {102, 4.9404473}]           |\n",
      "|6      |[{6351, 3.9524057}, {5556, -0.12159826}, {3638, -0.12159826}, {2738, -0.12159826}, {867, -0.12159826}]|\n",
      "|8      |[{9114, 4.9561243}, {5425, 4.9561243}, {4622, 4.9561243}, {3020, 4.9561243}, {2732, 4.9561243}]       |\n",
      "+-------+------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "# Load saved model\n",
    "#als_model = ALSModel.load(als_model_path)\n",
    "\n",
    "# Generate the  top 5 recommendations for each user\n",
    "user_recommendations = model.recommendForAllUsers(numItems=5)\n",
    "# Show recommendations\n",
    "user_recommendations.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Evaluation\n",
    "**Evaluator choice:** RegressionEvaluator\n",
    "I used RegressionEvaluator because the task is to predict continuous ratings (1-5) for user-item pairs. RegressionEvaluator is useful for evaluating the performance of regression models by calculating metrics such as RMSE (Root Mean Square Error), which measures the average magnitude of the prediction errors.\n",
    "\n",
    "\n",
    "**Metric used:** RMSE (Root Mean Square Error)\n",
    "I chose RMSE as the evaluation metric because it provides a clear measure of how well the model's predicted ratings match the actual ratings. RMSE penalizes larger errors more than smaller ones, making it a useful metric for the recommendation task where accurate predictions are crucial for user satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error (RMSE) = 0.0476170399192705\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Generate predictions for all users\n",
    "predictions = model.transform(books_ratings_df)\n",
    "\n",
    "\n",
    "# Set up evaluator to compute RMSE\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"rating\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error (RMSE) = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
