{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 07**: Structured Streaming with Files \n",
    "\n",
    "**Date**: October 10th 2025\n",
    "\n",
    "**Student Name**: José Alfredo Calvillo Gómez\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "import os\n",
    "\n",
    "# Inicializar SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StructuredStreamingLab\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Directorio donde se guardan los logs\n",
    "log_dir = \"/ruta/a/tu/directorio/logs\"  \n",
    "\n",
    "# Definir el esquema para los datos de los logs (timestamp, nivel de log, y mensaje)\n",
    "schema = \"timestamp STRING, level STRING, message STRING\"\n",
    "\n",
    "# Leer datos del directorio de logs utilizando Structured Streaming\n",
    "logs_df = spark.readStream \\\n",
    "    .schema(schema) \\\n",
    "    .csv(log_dir)\n",
    "\n",
    "# Filtrar logs con errores críticos (por ejemplo, errores repetidos 500)\n",
    "critical_errors_df = logs_df.filter(col(\"level\") == \"ERROR\") \\\n",
    "    .filter(col(\"message\").contains(\"500\"))\n",
    "\n",
    "# Contar los errores críticos por cada micro-lote\n",
    "error_counts_df = critical_errors_df.groupBy(\"message\").count()\n",
    "\n",
    "# Sink: Mostrar el resultado en la consola\n",
    "query = error_counts_df.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "# Esperar a que el proceso de streaming termine (al menos 3 micro-lotes)\n",
    "query.awaitTermination(30)  # Espera 30 segundos para que se procesen al menos 3 micro-lotes\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
