{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 05**: Data pipeline with Neo4j\n",
    "\n",
    "**Date**: October 2nd 2025\n",
    "\n",
    "**Student Name**: Antonia Horburger\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893c817",
   "metadata": {},
   "source": [
    "# Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953daf1-68eb-4897-93d9-367d75fb3649",
   "metadata": {},
   "source": [
    "Breaking Bad: https://www.kaggle.com/datasets/jishnukoliyadan/breaking-bad-network-analysis\n",
    "\n",
    "Este conjunto de datos fue recolectado para realizar un análisis de redes de la serie de televisión Breaking Bad.\n",
    "\n",
    "Los datos fueron obtenidos mediante web scraping de la página de fandom de Breaking Bad. El objetivo principal es construir un grafo en el que:\n",
    "\n",
    "Nodos representan a los personajes de la serie. La lista de personajes se encuentra en el archivo character_df.csv (y su versión limpia character_df_cleaned.csv).\n",
    "\n",
    "Aristas representan relaciones de co-ocurrencia entre personajes, es decir, si aparecen mencionados en el mismo párrafo de los resúmenes de episodios (Season_1.txt hasta Season_5B.txt). Estas relaciones incluyen un peso, que indica cuántas veces dos personajes co-aparecen en la narrativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e84c3",
   "metadata": {},
   "source": [
    "# Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed17a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /root/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /root/.ivy2.5.2/jars\n",
      "org.neo4j#neo4j-connector-apache-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-edd67821-b92c-485d-942e-c85306ddf416;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.13;5.3.10_for_spark_3 in central\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.13_common;5.3.10_for_spark_3 in central\n",
      "\tfound org.neo4j#caniuse-core;1.3.0 in central\n",
      "\tfound org.neo4j#caniuse-api;1.3.0 in central\n",
      "\tfound org.jetbrains.kotlin#kotlin-stdlib;2.1.20 in central\n",
      "\tfound org.jetbrains#annotations;13.0 in central\n",
      "\tfound org.neo4j#caniuse-neo4j-detection;1.3.0 in central\n",
      "\tfound org.neo4j.driver#neo4j-java-driver-slim;4.4.21 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.4 in central\n",
      "\tfound io.netty#netty-handler;4.1.127.Final in central\n",
      "\tfound io.netty#netty-common;4.1.127.Final in central\n",
      "\tfound io.netty#netty-resolver;4.1.127.Final in central\n",
      "\tfound io.netty#netty-buffer;4.1.127.Final in central\n",
      "\tfound io.netty#netty-transport;4.1.127.Final in central\n",
      "\tfound io.netty#netty-transport-native-unix-common;4.1.127.Final in central\n",
      "\tfound io.netty#netty-codec;4.1.127.Final in central\n",
      "\tfound io.netty#netty-tcnative-classes;2.0.73.Final in central\n",
      "\tfound io.projectreactor#reactor-core;3.6.11 in central\n",
      "\tfound org.neo4j#neo4j-cypher-dsl;2022.11.0 in central\n",
      "\tfound org.apiguardian#apiguardian-api;1.1.2 in central\n",
      "\tfound org.neo4j.connectors#commons-authn-spi;1.0.0-rc2 in central\n",
      "\tfound org.neo4j.connectors#commons-reauth-driver;1.0.0-rc2 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.17 in central\n",
      "\tfound org.neo4j.connectors#commons-authn-provided;1.0.0-rc2 in central\n",
      ":: resolution report :: resolve 613ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tio.netty#netty-buffer;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-codec;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-common;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-handler;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-resolver;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-tcnative-classes;2.0.73.Final from central in [default]\n",
      "\tio.netty#netty-transport;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-unix-common;4.1.127.Final from central in [default]\n",
      "\tio.projectreactor#reactor-core;3.6.11 from central in [default]\n",
      "\torg.apiguardian#apiguardian-api;1.1.2 from central in [default]\n",
      "\torg.jetbrains#annotations;13.0 from central in [default]\n",
      "\torg.jetbrains.kotlin#kotlin-stdlib;2.1.20 from central in [default]\n",
      "\torg.neo4j#caniuse-api;1.3.0 from central in [default]\n",
      "\torg.neo4j#caniuse-core;1.3.0 from central in [default]\n",
      "\torg.neo4j#caniuse-neo4j-detection;1.3.0 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.13;5.3.10_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.13_common;5.3.10_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-cypher-dsl;2022.11.0 from central in [default]\n",
      "\torg.neo4j.connectors#commons-authn-provided;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.connectors#commons-authn-spi;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.connectors#commons-reauth-driver;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.driver#neo4j-java-driver-slim;4.4.21 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.4 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.17 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   24  |   0   |   0   |   0   ||   24  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-edd67821-b92c-485d-942e-c85306ddf416\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 24 already retrieved (0kB/12ms)\n",
      "25/10/03 15:50:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Examples on SparkSQL\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.neo4j:neo4j-connector-apache-spark_2.13:5.3.10_for_spark_3\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93cd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from antoniahorburger.spark_utils import SparkUtils\n",
    "\n",
    "characters_schema = SparkUtils.generate_schema([\n",
    "    (\"Season\", \"string\"),\n",
    "    (\"Characters\", \"string\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66184dbc-2b01-40b5-924e-1eb0f4c637a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+\n",
      "|Season  |Characters      |\n",
      "+--------+----------------+\n",
      "|Season_1|Walter White    |\n",
      "|Season_1|Skyler White    |\n",
      "|Season_1|Jesse Pinkman   |\n",
      "|Season_1|Hank Schrader   |\n",
      "|Season_1|Marie Schrader  |\n",
      "|Season_1|Walter White Jr.|\n",
      "|Season_1|Krazy-8         |\n",
      "|Season_1|Emilio          |\n",
      "|Season_1|Gomez           |\n",
      "|Season_1|Bogdan          |\n",
      "+--------+----------------+\n",
      "only showing top 10 rows\n",
      "root\n",
      " |-- Season: string (nullable = true)\n",
      " |-- Characters: string (nullable = true)\n",
      "\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|line                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|The episode opens on black and white shots of a backyard. The camera pans over to reveal what appears to be a plastic eyeball in a pool of water. The eyeball is then sucked into the drain of the pool while a pink teddy bear, missing its left eye, floats underwater.                                                                                                                                                                                                                                                                                                                                                            |\n",
      "|After buying meth from Walt and Jesse at the junkyard, Tuco violently attacks his henchman, No-Doze, for presuming to speak for him. Afterwards, he drives away, leaving Walt and Jesse to ponder the danger of their situation. In Jesse's car, Walt calculates that he needs $737,000 to provide for his family’s future, factoring in medical bills, his children's tuition, mortgage, and other variables—in other words, eleven more meth deals—before he can leave the drug business.                                                                                                                                          |\n",
      "|Moments later, Tuco roars back to the junkyard in his SUV, ordering Walt to resuscitate an unconscious No-Doze. Walt is unable to help No-Doze as he dies as a result of the brutal attack. Tuco's other henchman, Gonzo, says they should give his buddy a proper burial, but Tuco orders him to stash the body underneath a stack of old cars. Walt and Jesse begin to leave, but Tuco questions them, to which Walt says they thought they were done. Tuco tells them coldly they are done. The two begin to leave, but Jesse is grabbed by the neck and shoved to the ground. Tuco stares intently at the two as they depart.    |\n",
      "|Walt returns home, where Skyler is applying an avocado mask. She discovers him aimlessly clicking through television channels, and asks him what he’s doing. He sobs briefly before standing behind her and forcing himself on her, even after she asks him to slow down. Only when she screams \"Stop it!\" does he let up. Walt rests in the backyard, overlooking the pool. Skyler follows and says that while she understands his situation, he cannot take his anger out on her. As the two talk, Junior returns home and sees the avocado imprint of Skyler's face on the refrigerator.                                          |\n",
      "|Jesse purchases a gun at a local fast food joint, the Dog House, telling Walt that he thinks Tuco wants to kill both of them for witnessing No-Doze's murder. Jesse argues for pre-emptively killing Tuco before he kills them. Walt makes Jesse walk through how he would shoot Tuco and his crew, pointing out many problems with his ill-conceived plan. Walt also questions whether Jesse will have it in him. Jesse points out that Walt did, to which he grimly replies, \"Yeah.\"                                                                                                                                               |\n",
      "|Marie invites Skyler to dinner, but Skyler doesn't answer the phone. Hank reminds Marie that she has a therapy appointment at the same time she was planning to eat out. Defensive, Marie tells him he’s mistaken and speeds away in her car, intentionally running over an RC toy belonging to a neighbor kid. Hank approaches the distraught kid and apologizes while taking out a money clip of cash from his pocket.                                                                                                                                                                                                             |\n",
      "|Gomez shows Hank grainy surveillance footage of a recent break-in at a chemical warehouse. Hank, unaware that he's watching Walt and Jesse, laughingly gives them low marks as burglars but concedes that they know their chemistry, correctly deducing that they are using methylamine as part of their cooking process. They note the large amount of meth they will be able to cook and predict they're going to step on some toes. After Walt pulls into his driveway that evening, a suspicious SUV parked down the street eases away.                                                                                          |\n",
      "|Skyler notices that Walt has spent the night watching the street outside; he bolts upright when the phone rings. The call is from Marie, but Skyler picks up the receiver and immediately hangs up. Later, Walt confronts Jesse about the other night, and questions him on whether he had given information to Tuco about him. Jesse denies doing so and warns Walt that Tuco is about to make a move. Jesse wants Walt to get his own gun to double their chances of survival, but Walt has another idea: use castor beans to create ricin, a poison they can slip to Tuco.                                                        |\n",
      "|When Hank visits Skyler, she questions if Marie sent him. He denies it, informing her that Marie is barely talking to him. When he asks Skyler to return Marie's phone calls, she tells him about Marie's shoplifting problem; he is aware of it and claims that Marie is getting help. This angers Skyler, who cites her pregnancy; her absent, cancer-stricken husband; a moody son; an overdrawn checking account and a defective water heater as problems more pressing than those of her \"spoiled, kleptomaniac, bitch sister.\" When she breaks down sobbing, Hank sheepishly hugs her and offers to check out the water heater.|\n",
      "|Over at Jesse's house, he and Walt cook up the ricin. Their plan is to offer the ricin to Tuco in a sample of their latest meth formula. Jesse wonders whether Tuco will question their latest meth formula, but Walt says that Tuco will snort anything he gets his hands on. Hank calls Walt from a crime scene to apologize for attempting to reconcile Skyler and Marie. Laughing, he sends Walt a cell-phone picture of both No-Doze and Gonzo, whose bodies have been found at the junkyard. Walt and Jesse stare at the photo in horror.                                                                                      |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "root\n",
      " |-- line: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ingesta de datos\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "ruta_characters = \"/opt/spark/work-dir/data/breakingbad/character_df_cleaned.csv\"\n",
    "ruta_summaries = \"/opt/spark/work-dir/data/breakingbad/summaries/*.txt\"\n",
    "\n",
    "# Leer CSV de personajes con esquema\n",
    "characters_df = (\n",
    "    spark.read\n",
    "         .option(\"header\", True)\n",
    "         .schema(characters_schema)\n",
    "         .csv(ruta_characters)\n",
    ")\n",
    "\n",
    "characters_df.show(10, truncate=False)\n",
    "characters_df.printSchema()\n",
    "\n",
    "# Leer resúmenes como texto\n",
    "summaries_df = (\n",
    "    spark.read\n",
    "         .text(ruta_summaries)\n",
    "         .withColumnRenamed(\"value\", \"line\")\n",
    ")\n",
    "\n",
    "summaries_df.show(10, truncate=False)\n",
    "summaries_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e82d5",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6355aff9-7a33-462b-b934-a21abe507a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+---------+\n",
      "|id                       |Season   |\n",
      "+-------------------------+---------+\n",
      "|ABQ Detective            |Season_3 |\n",
      "|APD Detective Tim Roberts|Season_2 |\n",
      "|APD Officer              |Season_3 |\n",
      "|ASAC George Merkert      |Season_2 |\n",
      "|ASAC George Merket       |Season_5A|\n",
      "|ASAC Ramey               |Season_5B|\n",
      "|Addict                   |Season_2 |\n",
      "|Agent Buddy              |Season_2 |\n",
      "|Agent Van Oster          |Season_5B|\n",
      "|Airport Traveler         |Season_5A|\n",
      "+-------------------------+---------+\n",
      "only showing top 10 rows\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- Season: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------+\n",
      "|src          |dst        |weight|\n",
      "+-------------+-----------+------+\n",
      "|Ed           |Gonzo      |4     |\n",
      "|Himself      |No-Doze    |1     |\n",
      "|Doctor       |ER Doctor  |1     |\n",
      "|Ed           |Gomez      |51    |\n",
      "|Clovis       |Father     |1     |\n",
      "|Father       |Gomez      |1     |\n",
      "|DEA          |Father     |5     |\n",
      "|Ed           |Skinny Pete|22    |\n",
      "|Badger       |Combo      |6     |\n",
      "|Carmen Molina|Student    |1     |\n",
      "+-------------+-----------+------+\n",
      "only showing top 10 rows\n",
      "root\n",
      " |-- src: string (nullable = true)\n",
      " |-- dst: string (nullable = true)\n",
      " |-- weight: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split, trim, when, size, element_at, lower, instr\n",
    "\n",
    "#nodes de characters\n",
    "\n",
    "names_col = split(col(\"Characters\"), r\"(?i)\\s+as\\s+\")\n",
    "characters_clean = (\n",
    "    characters_df\n",
    "      .withColumn(\n",
    "          \"CharacterName\",\n",
    "          when(size(names_col) >= 2, element_at(names_col, 2)) #necesario por el \"as\"\n",
    "          .otherwise(element_at(names_col, 1))\n",
    "      )\n",
    "      .withColumn(\"CharacterName\", trim(col(\"CharacterName\")))\n",
    "      .dropna(subset=[\"CharacterName\"])\n",
    "      .dropDuplicates([\"CharacterName\"])\n",
    ")\n",
    "\n",
    "character_nodes = characters_clean.select(\n",
    "    col(\"CharacterName\").alias(\"id\"),\n",
    "    col(\"Season\")\n",
    ").dropDuplicates([\"id\"])\n",
    "\n",
    "character_nodes.show(10, truncate=False)\n",
    "character_nodes.printSchema()\n",
    "\n",
    "#edges\n",
    "\n",
    "mentions = (\n",
    "    summaries_df.alias(\"s\")\n",
    "      .join(\n",
    "          characters_clean.alias(\"c\"),\n",
    "          instr(lower(col(\"s.line\")), lower(col(\"c.CharacterName\"))) > 0,\n",
    "          \"inner\"\n",
    "      )\n",
    "      .select(col(\"s.line\").alias(\"line\"), col(\"c.CharacterName\").alias(\"name\"))\n",
    ")\n",
    "\n",
    "pairs = (\n",
    "    mentions.alias(\"a\")\n",
    "      .join(\n",
    "          mentions.alias(\"b\"),\n",
    "          (col(\"a.line\") == col(\"b.line\")) & (col(\"a.name\") < col(\"b.name\")),\n",
    "          \"inner\"\n",
    "      )\n",
    "      .select(col(\"a.name\").alias(\"src\"), col(\"b.name\").alias(\"dst\"))\n",
    ")\n",
    "\n",
    "edges_df = pairs.groupBy(\"src\", \"dst\").count().withColumnRenamed(\"count\", \"weight\")\n",
    "\n",
    "edges_df.show(10, truncate=False)\n",
    "edges_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a68775",
   "metadata": {},
   "source": [
    "# Writing Data in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01d7a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385 character nodes wrote in Neo4j\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977 co-occurrence edges wrote in Neo4j\n"
     ]
    }
   ],
   "source": [
    "neo4j_url = \"bolt://neo4j-iteso:7687\"\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_passwd = \"neo4j@1234\"\n",
    "\n",
    "#nodes de characters\n",
    "character_nodes.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"labels\", \":Character\") \\\n",
    "  .option(\"node.keys\", \"id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{character_nodes.count()} character nodes wrote in Neo4j\")\n",
    "\n",
    "#edges\n",
    "edges_df.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"relationship\", \"CO_OCCURS_WITH\") \\\n",
    "  .option(\"relationship.save.strategy\", \"keys\") \\\n",
    "  .option(\"relationship.source.labels\", \":Character\") \\\n",
    "  .option(\"relationship.source.save.mode\", \"match\") \\\n",
    "  .option(\"relationship.source.node.keys\", \"src:id\") \\\n",
    "  .option(\"relationship.target.labels\", \":Character\") \\\n",
    "  .option(\"relationship.target.save.mode\", \"match\") \\\n",
    "  .option(\"relationship.target.node.keys\", \"dst:id\") \\\n",
    "  .option(\"relationship.properties\", \"weight\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{edges_df.count()} co-occurrence edges wrote in Neo4j\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc6ad5-787c-4cf2-a0ae-0ac2273b3fb1",
   "metadata": {},
   "source": [
    "# Read and Query Graphs with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0c2f9f-280a-4abd-bb54-717d635d1bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+---------+\n",
      "|id                       |Season   |\n",
      "+-------------------------+---------+\n",
      "|ABQ Detective            |Season_3 |\n",
      "|APD Detective Tim Roberts|Season_2 |\n",
      "|APD Officer              |Season_3 |\n",
      "|ASAC George Merkert      |Season_2 |\n",
      "|ASAC George Merket       |Season_5A|\n",
      "|ASAC Ramey               |Season_5B|\n",
      "|Addict                   |Season_2 |\n",
      "|Agent Buddy              |Season_2 |\n",
      "|Agent Van Oster          |Season_5B|\n",
      "|Airport Traveler         |Season_5A|\n",
      "+-------------------------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Leer nodos\n",
    "characters_from_neo4j = spark.read \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"labels\", \":Character\") \\\n",
    "  .load()\n",
    "\n",
    "characters_from_neo4j.select(\"id\", \"Season\").show(10, truncate=False)\n",
    "\n",
    "# Leer relaciones especificando labels de origen/destino\n",
    "edges_from_neo4j = spark.read \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"relationship\", \"CO_OCCURS_WITH\") \\\n",
    "  .option(\"relationship.source.labels\", \":Character\") \\\n",
    "  .option(\"relationship.target.labels\", \":Character\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9078a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
