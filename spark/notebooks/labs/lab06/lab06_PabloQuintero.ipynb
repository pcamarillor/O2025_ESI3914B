{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 05**: Data pipeline with Neo4j\n",
    "\n",
    "**Date**: October 2nd 2025\n",
    "\n",
    "**Student Name**: Pablo Quintero\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893c817",
   "metadata": {},
   "source": [
    "# Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e84c3",
   "metadata": {},
   "source": [
    "# Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed17a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Lab06\") \\\n",
    "    .master(\"spark://f5f576f1e425:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.neo4j:neo4j-connector-apache-spark_2.13:5.3.10_for_spark_3\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "# Optimization (reduce the number of shuffle partitions)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a93cd621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------+\n",
      "|Season  |Characters                          |\n",
      "+--------+------------------------------------+\n",
      "|Season_1|Bryan Cranston as Walter White      |\n",
      "|Season_1|Anna Gunn as Skyler White           |\n",
      "|Season_1|Aaron Paul as Jesse Pinkman         |\n",
      "|Season_1|Dean Norris as Hank Schrader        |\n",
      "|Season_1|Betsy Brandt as Marie Schrader      |\n",
      "|Season_1|RJ Mitte as Walter White Jr.        |\n",
      "|Season_1|Max Arciniega as Krazy-8            |\n",
      "|Season_1|John Koyama as Emilio               |\n",
      "|Season_1|Steven Michael Quezada as Gomez     |\n",
      "|Season_1|Marius Stan as Bogdan               |\n",
      "|Season_1|Aaron Hill as Jock                  |\n",
      "|Season_1|Greg Chase as Dr. Belknap           |\n",
      "|Season_1|Carmen Serano as Carmen             |\n",
      "|Season_1|Evan Bobrick as Chad                |\n",
      "|Season_1|Roberta Marquez as Chad's Girlfriend|\n",
      "|Season_1|Christopher Dempsey as E.M.T.       |\n",
      "|Season_1|Allan Pacheco as Irving             |\n",
      "|Season_1|Jason Byrd as Chemistry Student     |\n",
      "|Season_1|Linda Speciale as Sexy Neighbor     |\n",
      "|Season_1|Jesus Ramirez as Jock's Friend #1   |\n",
      "+--------+------------------------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from PabloQuintero.spark_utils import SparkUtils\n",
    "# Build schema\n",
    "schema_breakingbad= SparkUtils.generate_schema([(\"Season\", \"string\"), (\"Characters\", \"string\")])\n",
    "\n",
    "# Import your module\n",
    "df_Bad = spark.read.schema(schema_breakingbad).option(\"header\", True).csv(\"/opt/spark/work-dir/data/BreakingBad\")\n",
    "df_Bad.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e82d5",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "000b6d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame Final de Nodos ---\n",
      "+----------------------+-----+\n",
      "|id                    |label|\n",
      "+----------------------+-----+\n",
      "|Bryan Cranston        |Actor|\n",
      "|John Koyama           |Actor|\n",
      "|Steven Michael Quezada|Actor|\n",
      "|Evan Bobrick          |Actor|\n",
      "|Jon Kristian Moore    |Actor|\n",
      "|Robert Anthony Brass  |Actor|\n",
      "|Adam Godley           |Actor|\n",
      "|Marc Mouchet          |Actor|\n",
      "|Frederic Doss         |Actor|\n",
      "|Dennis Keiffer        |Actor|\n",
      "|Kristen Loree         |Actor|\n",
      "|Vic Browder           |Actor|\n",
      "|Matthew Lee Jones     |Actor|\n",
      "|Tom Kiesche           |Actor|\n",
      "|Drew Waters           |Actor|\n",
      "|Liam Ruggles          |Actor|\n",
      "|Caleb Jones           |Actor|\n",
      "|John Christopher Hicks|Actor|\n",
      "|Tina Parker           |Actor|\n",
      "|Jimmy Daniels         |Actor|\n",
      "+----------------------+-----+\n",
      "only showing top 20 rows\n",
      "--- DataFrame Final de Relaciones ---\n",
      "+----------------------+--------------------+------------+\n",
      "|src                   |dst                 |relationship|\n",
      "+----------------------+--------------------+------------+\n",
      "|Bryan Cranston        |Walter White        |PLAYS       |\n",
      "|Aaron Paul            |Jesse Pinkman       |PLAYS       |\n",
      "|Dean Norris           |Hank Schrader       |PLAYS       |\n",
      "|Andrea Good           |Laundry Worker      |PLAYS       |\n",
      "|Peggy Ann O'Neal      |Pedestrian          |PLAYS       |\n",
      "|Jessica Hecht         |Gretchen Schwartz   |PLAYS       |\n",
      "|Steven Michael Quezada|Steven Gomez        |PLAYS       |\n",
      "|Robert Anthony Brass  |Bank Customer       |PLAYS       |\n",
      "|Marc Mouchet          |Farley              |PLAYS       |\n",
      "|Robert Arrington      |Soren               |PLAYS       |\n",
      "|Juanita Trad          |Medical Technician  |PLAYS       |\n",
      "|Beth Bailey           |Jodi Nichols        |PLAYS       |\n",
      "|Matthew Page          |Chemical Plant Guard|PLAYS       |\n",
      "|Charles Dowdy         |Mr. Wilson          |PLAYS       |\n",
      "|Clark Sanchez         |Biker               |PLAYS       |\n",
      "|Dana Cortez           |TV Reporter         |PLAYS       |\n",
      "|Julia Minesci         |Wendy               |PLAYS       |\n",
      "|Argos MacCallum       |Wino                |PLAYS       |\n",
      "|David Ury             |Spooge              |PLAYS       |\n",
      "|Rio Alexander         |Federale            |PLAYS       |\n",
      "+----------------------+--------------------+------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split, trim, lit, when\n",
    "# Add the code for your transformations to create nodes and edges\n",
    "processed_df = df_Bad \\\n",
    "    .where(col(\"Characters\").contains(\" as \")) \\\n",
    "    .withColumn(\"split_char\", split(col(\"Characters\"), \" as \")) \\\n",
    "    .withColumn(\"ActorName\", trim(col(\"split_char\").getItem(0))) \\\n",
    "    .withColumn(\"CharacterName\", trim(col(\"split_char\").getItem(1))) \\\n",
    "    .select(\"Season\", \"ActorName\", \"CharacterName\") \\\n",
    "    .na.drop()\n",
    "# Nodos de tipo 'Actor'\n",
    "actor_nodes = processed_df.select(\n",
    "    col(\"ActorName\").alias(\"id\")\n",
    ").distinct().withColumn(\"label\", lit(\"Actor\"))\n",
    "# Nodos de tipo 'Personaje'\n",
    "character_nodes = processed_df.withColumn(\n",
    "    \"id\",\n",
    "    when(col(\"CharacterName\") == \"Himself\", col(\"ActorName\"))\n",
    "    .otherwise(col(\"CharacterName\"))\n",
    ").select(\"id\").distinct().withColumn(\"label\", lit(\"Personaje\"))\n",
    "# Nodos de tipo 'Temporada'\n",
    "season_nodes = processed_df.select(\n",
    "    col(\"Season\").alias(\"id\")\n",
    ").distinct().withColumn(\"label\", lit(\"Temporada\"))\n",
    "nodes = actor_nodes.unionByName(character_nodes).unionByName(season_nodes)\n",
    "# Relaciones: (Actor) (Personaje)\n",
    "plays_edges = processed_df.select(\n",
    "    col(\"ActorName\").alias(\"src\"),\n",
    "    when(col(\"CharacterName\") == \"Himself\", col(\"ActorName\"))\n",
    "    .otherwise(col(\"CharacterName\")).alias(\"dst\")\n",
    ").distinct().withColumn(\"relationship\", lit(\"PLAYS\"))\n",
    "# Relaciones: (Personaje) (Temporada)\n",
    "appears_in_edges = processed_df.select(\n",
    "    when(col(\"CharacterName\") == \"Himself\", col(\"ActorName\"))\n",
    "    .otherwise(col(\"CharacterName\")).alias(\"src\"),\n",
    "    col(\"Season\").alias(\"dst\")\n",
    ").distinct().withColumn(\"relationship\", lit(\"APPEARS_IN\"))\n",
    "edges = plays_edges.unionByName(appears_in_edges)\n",
    "# DOS DataFrames finales\n",
    "print(\"--- DataFrame Final de Nodos ---\")\n",
    "nodes.show(20, truncate=False)\n",
    "\n",
    "print(\"--- DataFrame Final de Relaciones ---\")\n",
    "edges.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a68775",
   "metadata": {},
   "source": [
    "# Writing Data in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d7a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> 417 nodos :Actor escritos en Neo4j\n",
      "-> 436 nodos :Personaje escritos en Neo4j\n",
      "-> 6 nodos :Temporada escritos en Neo4j\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> 482 relaciones :PLAYS escritas en Neo4j\n",
      "-> 602 relaciones :APPEARS_IN escritas en Neo4j\n"
     ]
    }
   ],
   "source": [
    "# Add the code to write a graph from PySpark's DataFrames to Neo4j\n",
    "\n",
    "neo4j_url = \"bolt://neo4j-iteso:7687\"\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_passwd = \"neo4j@1234\"\n",
    "\n",
    "actor_nodes_to_write = nodes.where(col(\"label\") == \"Actor\").select(\"id\")\n",
    "actor_nodes_to_write.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"labels\", \":Actor\") \\\n",
    "  .option(\"node.keys\", \"id\") \\\n",
    "  .save()\n",
    "print(f\"-> {actor_nodes_to_write.count()} nodos :Actor escritos en Neo4j\")\n",
    "\n",
    "character_nodes_to_write = nodes.where(col(\"label\") == \"Personaje\").select(\"id\")\n",
    "character_nodes_to_write.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"labels\", \":Personaje\") \\\n",
    "  .option(\"node.keys\", \"id\") \\\n",
    "  .save()\n",
    "print(f\"-> {character_nodes_to_write.count()} nodos :Personaje escritos en Neo4j\")\n",
    "\n",
    "\n",
    "season_nodes_to_write = nodes.where(col(\"label\") == \"Temporada\").select(\"id\")\n",
    "season_nodes_to_write.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"labels\", \":Temporada\") \\\n",
    "  .option(\"node.keys\", \"id\") \\\n",
    "  .save()\n",
    "print(f\"-> {season_nodes_to_write.count()} nodos :Temporada escritos en Neo4j\")\n",
    "\n",
    "\n",
    "plays_edges_to_write = edges.where(col(\"relationship\") == \"PLAYS\")\n",
    "plays_edges_to_write.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"relationship\", \"PLAYS\") \\\n",
    "  .option(\"relationship.save.strategy\", \"keys\") \\\n",
    "  .option(\"relationship.source.labels\", \":Actor\") \\\n",
    "  .option(\"relationship.source.node.keys\", \"src:id\") \\\n",
    "  .option(\"relationship.target.labels\", \":Personaje\") \\\n",
    "  .option(\"relationship.target.node.keys\", \"dst:id\") \\\n",
    "  .save()\n",
    "print(f\"-> {plays_edges_to_write.count()} relaciones :PLAYS escritas en Neo4j\")\n",
    "\n",
    "appears_in_edges_to_write = edges.where(col(\"relationship\") == \"APPEARS_IN\")\n",
    "appears_in_edges_to_write.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"relationship\", \"APPEARS_IN\") \\\n",
    "  .option(\"relationship.save.strategy\", \"keys\") \\\n",
    "  .option(\"relationship.source.labels\", \":Personaje\") \\\n",
    "  .option(\"relationship.source.node.keys\", \"src:id\") \\\n",
    "  .option(\"relationship.target.labels\", \":Temporada\") \\\n",
    "  .option(\"relationship.target.node.keys\", \"dst:id\") \\\n",
    "  .save()\n",
    "print(f\"-> {appears_in_edges_to_write.count()} relaciones :APPEARS_IN escritas en Neo4j\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30287ea",
   "metadata": {},
   "source": [
    "# Read and Query Graphs with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03ca7b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Amigos de reparto de Bryan Cranston\n",
      "+--------------------+----------------+\n",
      "|     ColegaDeReparto|TemporadaEnComun|\n",
      "+--------------------+----------------+\n",
      "|          \"Anna Gunn|        Season_3|\n",
      "|\"Michael \"\"Yak\"\" ...|        Season_4|\n",
      "|          Aaron Hill|        Season_1|\n",
      "|          Aaron Paul|        Season_1|\n",
      "|          Aaron Paul|        Season_2|\n",
      "|          Aaron Paul|        Season_3|\n",
      "|          Aaron Paul|        Season_4|\n",
      "|          Aaron Paul|       Season_5A|\n",
      "|          Aaron Paul|       Season_5B|\n",
      "|        Aaron Wright|       Season_5B|\n",
      "|         Adam Godley|        Season_1|\n",
      "|         Adam Godley|       Season_5B|\n",
      "|    Alex Gianopoulos|        Season_4|\n",
      "|    Alex Gianopoulos|       Season_5B|\n",
      "|         Alex Knight|       Season_5A|\n",
      "|       Allan Pacheco|        Season_1|\n",
      "|     Amanda Fresquez|        Season_4|\n",
      "|    Amanda Schofield|        Season_3|\n",
      "|    Amanda Schofield|        Season_4|\n",
      "|    Amanda Schofield|       Season_5A|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Add the code to read a data frame from Neo4J and run a simple query to verify \n",
    "print(\"\\n Amigos de reparto de Bryan Cranston\")\n",
    "\n",
    "co_actors_df = spark.read \\\n",
    "    .format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .option(\"url\", neo4j_url) \\\n",
    "    .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "    .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "    .option(\"query\",\n",
    "            \"\"\"\n",
    "            MATCH (aaron:Actor {id: 'Bryan Cranston'})-[:PLAYS]->(:Personaje)-[:APPEARS_IN]->(s:Temporada)\n",
    "            MATCH (coactor:Actor)-[:PLAYS]->(:Personaje)-[:APPEARS_IN]->(s)\n",
    "            WHERE aaron <> coactor\n",
    "            RETURN coactor.id AS ColegaDeReparto, s.id AS TemporadaEnComun\n",
    "            ORDER BY ColegaDeReparto, TemporadaEnComun\n",
    "            \"\"\") \\\n",
    "    .load()\n",
    "co_actors_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
