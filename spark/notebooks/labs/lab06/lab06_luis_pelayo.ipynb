{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 05**: Data pipeline with Neo4j\n",
    "\n",
    "**Date**: October 2nd 2025\n",
    "\n",
    "**Student Name**: Luis Antonio Pelayo Sierra\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893c817",
   "metadata": {},
   "source": [
    "# Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7318da",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/alenreuel/airport-network\n",
    "\n",
    "Origen: Source Airport\n",
    "\n",
    "Destino: Destination Airport\n",
    "\n",
    "Aristas: Airlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e84c3",
   "metadata": {},
   "source": [
    "# Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed17a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Examples on SparkSQL\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.neo4j:neo4j-connector-apache-spark_2.13:5.3.10_for_spark_3\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a93cd621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------+-----------------+-------------------+----------------------+---------+-----+---------+\n",
      "|Airline|Airline ID|Source airport|Source airport ID|Destination airport|Destination airport ID|Codeshare|Stops|Equipment|\n",
      "+-------+----------+--------------+-----------------+-------------------+----------------------+---------+-----+---------+\n",
      "|     7H|     16726|           SCM|             7209|                BET|                  3599|        Y|    0|      CNA|\n",
      "|     9W|      3000|           GAU|             6173|                AJL|                  3039|        Y|    0|      AT7|\n",
      "|     A3|        96|           CPH|              609|                SKG|                  1486|        Y|    0|      320|\n",
      "|     AA|        24|           BOS|             3448|                PIT|                  3570|        Y|    0|  E70 CRJ|\n",
      "|     AA|        24|           OAK|             3453|                KOA|                  3514|        Y|    0|      737|\n",
      "|     AA|        24|           PHL|             3752|                SDF|                  4014|        Y|    0|  CRJ CR9|\n",
      "|     AA|        24|           PHX|             3462|                TUS|                  3636|        Y|    0|  CR9 CRJ|\n",
      "|     AC|       330|           YUL|              146|                YUY|                   149|        Y|    0|      DH1|\n",
      "|     AC|       330|           YVR|              156|                MUC|                   346|        Y|    0|      333|\n",
      "|     AC|       330|           YXE|              166|                YVR|                   156|        Y|    0|      CRJ|\n",
      "|     AC|       330|           YYZ|              193|                ATL|                  3682|        Y|    0|  CRA CRJ|\n",
      "|     AF|       137|           ATL|             3682|                DAL|                  3502|        Y|    0|      CRJ|\n",
      "|     AF|       137|           DTW|             3645|                MSY|                  3861|        Y|    0|      319|\n",
      "|     AF|       137|           ORY|             1386|                MAD|                  1229|        Y|    0|  E90 738|\n",
      "|     AM|       321|           ATL|             3682|                ABY|                  5715|        Y|    0|      CRJ|\n",
      "|     AS|       439|           DTW|             3645|                PDX|                  3720|        Y|    0|      739|\n",
      "|     AS|       439|           YYJ|              184|                SEA|                  3577|        Y|    0|      DH4|\n",
      "|     AY|      2350|           HEL|              421|                TMP|                   458|        Y|    0|  AT7 ATR|\n",
      "|     AZ|       596|           AMS|              580|                PTY|                  1871|        Y|    0|  777 77W|\n",
      "|     CA|       751|           MIG|             6400|                CGO|                  3375|        Y|    0|      CR2|\n",
      "+-------+----------+--------------+-----------------+-------------------+----------------------+---------+-----+---------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Build schema\n",
    "# Import your module\n",
    "from luis_pelayo.spark_utils import SparkUtils\n",
    "schema = SparkUtils.generate_schema([(\"Airline\", \"string\"), \n",
    "                                     (\"Airline ID\",\"int\"), \n",
    "                                     (\"Source airport\",\"string\"), \n",
    "                                     (\"Source airport ID\",\"int\"), \n",
    "                                     (\"Destination airport\",\"string\"), \n",
    "                                     (\"Destination airport ID\",\"int\"), \n",
    "                                     (\"Codeshare\",\"string\"), \n",
    "                                     (\"Stops\",\"int\"), \n",
    "                                     (\"Equipment\",\"string\")])\n",
    "\n",
    "path = \"/opt/spark/work-dir/data/airline/\"\n",
    "\n",
    "df_airlines = spark.read \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .schema(schema) \\\n",
    "                .csv(path + \"airline_network.csv\")\n",
    "\n",
    "\n",
    "df_airlines = df_airlines.dropna(how='any')\n",
    "df_airlines = df_airlines.dropDuplicates()\n",
    "\n",
    "df_airlines.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e82d5",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "000b6d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|name|\n",
      "+---+----+\n",
      "|  5| POM|\n",
      "| 16| KEF|\n",
      "| 21| YAM|\n",
      "| 27| YBC|\n",
      "| 28| YBG|\n",
      "| 29| YBK|\n",
      "| 30| YBL|\n",
      "| 33| YCD|\n",
      "| 34| YCG|\n",
      "| 41| YZS|\n",
      "| 45| YDF|\n",
      "| 49| YEG|\n",
      "| 50| YEK|\n",
      "| 55| YFB|\n",
      "| 56| YFC|\n",
      "| 61| YGK|\n",
      "| 63| YGP|\n",
      "| 65| YGR|\n",
      "| 73| YHZ|\n",
      "| 78| YKA|\n",
      "+---+----+\n",
      "only showing top 20 rows\n",
      "+----+----+-------+\n",
      "| src| dst|airline|\n",
      "+----+----+-------+\n",
      "| 132| 147|     5T|\n",
      "|6173|3057|     9W|\n",
      "|4037|3670|     AA|\n",
      "|3644|3577|     AA|\n",
      "|3670|3488|     AA|\n",
      "|3697|3645|     AA|\n",
      "| 507| 687|     AA|\n",
      "|3576|3488|     AA|\n",
      "|3731| 507|     AA|\n",
      "|3577| 156|     AA|\n",
      "| 507|1613|     AB|\n",
      "| 346|2179|     AB|\n",
      "| 146| 149|     AC|\n",
      "| 182| 146|     AC|\n",
      "|3682|3875|     AF|\n",
      "|3875|3682|     AF|\n",
      "|4041|3682|     AF|\n",
      "| 495|1265|     AF|\n",
      "|3448|3682|     AM|\n",
      "|3576|1819|     AM|\n",
      "+----+----+-------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Add the code for your transformations to create nodes and edges DataFrames HERE\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "airports = df_airlines.select(col(\"Source airport ID\").alias(\"id\"), col(\"Source airport\").alias(\"name\")).dropDuplicates([\"id\"])\n",
    "airports.show()\n",
    "\n",
    "connections = df_airlines.select(col(\"Source airport ID\").alias(\"src\"), col(\"Destination airport ID\").alias(\"dst\"), col(\"Airline\").alias(\"airline\")).dropDuplicates()\n",
    "connections.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a68775",
   "metadata": {},
   "source": [
    "# Writing Data in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01d7a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Add the code to write a graph from PySpark's DataFrames to Neo4j\n",
    "neo4j_url = \"bolt://neo4j-iteso:7687\"\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_passwd = \"neo4j@1234\"\n",
    "\n",
    "airports.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"labels\", \":Airports\") \\\n",
    "  .option(\"node.keys\", \"id\") \\\n",
    "  .save()\n",
    "\n",
    "connections.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"relationship\", \"AIRLINE\") \\\n",
    "  .option(\"relationship.save.strategy\", \"keys\") \\\n",
    "  .option(\"relationship.source.labels\", \":Airports\") \\\n",
    "  .option(\"relationship.source.save.mode\", \"match\") \\\n",
    "  .option(\"relationship.source.node.keys\", \"src:id\") \\\n",
    "  .option(\"relationship.target.labels\", \":Airports\") \\\n",
    "  .option(\"relationship.target.save.mode\", \"match\") \\\n",
    "  .option(\"relationship.target.node.keys\", \"dst:id\") \\\n",
    "  .save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30287ea",
   "metadata": {},
   "source": [
    "# Read and Query Graphs with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03ca7b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+\n",
      "|Source|Airline|Destination|\n",
      "+------+-------+-----------+\n",
      "|   POM|     QF|        CNS|\n",
      "|   POM|     QF|        SYD|\n",
      "|   POM|     VA|        BNE|\n",
      "|   KEF|     W2|        CPH|\n",
      "|   KEF|     W2|        SXF|\n",
      "|   KEF|     W2|        LGW|\n",
      "|   KEF|     W2|        ALC|\n",
      "|   KEF|     W2|        CDG|\n",
      "|   KEF|     AY|        HEL|\n",
      "|   YAM|     AC|        YYZ|\n",
      "|   YBC|     AC|        YYY|\n",
      "|   YBC|     AC|        YUL|\n",
      "|   YBG|     AC|        YUL|\n",
      "|   YBK|     5T|        YCS|\n",
      "|   YBK|     5T|        YXN|\n",
      "|   YBL|     AC|        YQQ|\n",
      "|   YCD|     AC|        YVR|\n",
      "|   YCG|     AC|        YVR|\n",
      "|   YCG|     AC|        YYC|\n",
      "|   YZS|     5T|        YRT|\n",
      "+------+-------+-----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Add the code to read a data frame from Neo4J and run a simple query to verify \n",
    "table = spark.read \\\n",
    "    .format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .option(\"url\", neo4j_url) \\\n",
    "    .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "    .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "    .option(\"query\",\"MATCH (S:Airports)-[A:AIRLINE]->(D:Airports) RETURN S.name AS Source, A.airline AS Airline, D.name AS Destination\")\\\n",
    "    .load()\n",
    "\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9078a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
