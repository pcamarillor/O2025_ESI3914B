{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 03**: Data Cleaning and Transformation Pipeline\n",
    "\n",
    "**Date**: September 18th 2025\n",
    "\n",
    "**Student Name**:\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7c59472-1379-4610-94ea-b3e176e50798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6143fd59-2a55-4fe6-9902-5dce157791e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/21 17:38:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Examples on data sources (Files)\") \\\n",
    "    .master(\"spark://38f00c0193b4:7077\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4c0e3f-add0-4268-9db9-01ae291ce0ca",
   "metadata": {},
   "source": [
    "# Define airlines schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b2ae18c-9cbd-4977-87b5-321fa69db2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('index', IntegerType(), True), StructField('airline', StringType(), True), StructField('flight', StringType(), True), StructField('source_city', StringType(), True), StructField('departure_time', StringType(), True), StructField('stops', StringType(), True), StructField('arrival_time', StringType(), True), StructField('destination_city', StringType(), True), StructField('class', StringType(), True), StructField('duration', FloatType(), True), StructField('days_left', IntegerType(), True), StructField('price', IntegerType(), True)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from axel2293.spark_utils import SparkUtils\n",
    "\n",
    "airline_schema_cols = [\n",
    "    (\"index\", \"int\"),\n",
    "    (\"airline\", \"string\"),\n",
    "    (\"flight\", \"string\"),\n",
    "    (\"source_city\", \"string\"),\n",
    "    (\"departure_time\", \"string\"),\n",
    "    (\"stops\", \"string\"),\n",
    "    (\"arrival_time\", \"string\"),\n",
    "    (\"destination_city\", \"string\"),\n",
    "    (\"class\", \"string\"),\n",
    "    (\"duration\", \"float\"),\n",
    "    (\"days_left\", \"int\"),\n",
    "    (\"price\", \"int\"),\n",
    "]\n",
    "\n",
    "airline_schema = SparkUtils.generate_schema(airline_schema_cols)\n",
    "airline_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a09dee-61ec-4b23-8a92-74a865e6be33",
   "metadata": {},
   "source": [
    "# Load Dataset CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf19cdb-dbb1-44dd-83eb-49d798c6bcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|index| airline| flight|source_city|departure_time|stops| arrival_time|destination_city|  class|duration|days_left|price|\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|    0|SpiceJet|SG-8709|      Delhi|       Evening| zero|        Night|          Mumbai|Economy|    2.17|        1| 5953|\n",
      "|    1|SpiceJet|SG-8157|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5953|\n",
      "|    2| AirAsia| I5-764|      Delhi| Early_Morning| zero|Early_Morning|          Mumbai|Economy|    2.17|        1| 5956|\n",
      "|    3| Vistara| UK-995|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.25|        1| 5955|\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "only showing top 4 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_airline = spark.read \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .schema(airline_schema) \\\n",
    "                .csv(\"/opt/spark/work-dir/data/airline/\")\n",
    "\n",
    "df_airline.show(n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd6336-9def-477d-ac44-c39962214668",
   "metadata": {},
   "source": [
    "## 1\n",
    "Drop unnecessary columns. Count how many null values the dataset has before/after the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d7bd379-116e-413a-b97d-36e5d8d6760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=============================>                             (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+-----------+--------------+-----+------------+----------------+-----+--------+---------+-----+\n",
      "|index|airline|flight|source_city|departure_time|stops|arrival_time|destination_city|class|duration|days_left|price|\n",
      "+-----+-------+------+-----------+--------------+-----+------------+----------------+-----+--------+---------+-----+\n",
      "|    0|      0|     0|          0|             0|    0|           0|               0|    0|       0|        0|    0|\n",
      "+-----+-------+------+-----------+--------------+-----+------------+----------------+-----+--------+---------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import trim, col, count, isnull, when\n",
    "\n",
    "# Show null values in each column\n",
    "df_airline.select([count(when(col(c).isNull(), c)).alias(c) for c in df_airline.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c2abaa-d5be-402d-882e-49bf08107437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records before cleaning: 300153\n"
     ]
    }
   ],
   "source": [
    "print(f\"Records before cleaning: {df_airline.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88a65f08-2be4-4e4c-a887-96fde7a62870",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_clean = df_airline \\\n",
    "                .dropDuplicates([\"index\"]) \\\n",
    "                .withColumn(\"airline\", trim(\"airline\")) \\\n",
    "                .withColumn(\"source_city\", trim(\"source_city\")) \\\n",
    "                .withColumn(\"destination_city\", trim(\"destination_city\")) \\\n",
    "                .filter(col(\"price\").isNotNull())\n",
    "airline_clean = df_airline.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c305a569-4380-421f-b4f8-d6adc7d282e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records after cleaning: 300153\n"
     ]
    }
   ],
   "source": [
    "print(f\"Records after cleaning: {df_airline.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5408d25a-2f95-4b66-bb51-c4c60ff59c8a",
   "metadata": {},
   "source": [
    "## 2\n",
    "Normalize categorical values: map “zero” → 0, “one” → 1, etc. in stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b8997c9-6c43-40a1-8547-1b4cb8f07377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+---------+\n",
      "|index| airline| flight|source_city|departure_time|stops| arrival_time|destination_city|  class|duration|days_left|price|stops_num|\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+---------+\n",
      "|    0|SpiceJet|SG-8709|      Delhi|       Evening| zero|        Night|          Mumbai|Economy|    2.17|        1| 5953|        0|\n",
      "|    1|SpiceJet|SG-8157|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5953|        0|\n",
      "|    2| AirAsia| I5-764|      Delhi| Early_Morning| zero|Early_Morning|          Mumbai|Economy|    2.17|        1| 5956|        0|\n",
      "|    3| Vistara| UK-995|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.25|        1| 5955|        0|\n",
      "|    4| Vistara| UK-963|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|        0|\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, lit\n",
    "\n",
    "airline_t2 = airline_clean.withColumn(\"stops_num\",\n",
    "                                            when(airline_clean.stops == \"zero\", lit(0))\n",
    "                                            .when(airline_clean.stops == \"one\", lit(1))\n",
    "                                           )\n",
    "airline_t2.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c724c77-6cc1-4a96-8284-46f0cd62d7a0",
   "metadata": {},
   "source": [
    "## 3\n",
    "Create a new column called route: “Delhi → Mumbai” from source_city and destination_city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa3616b2-464c-45ab-9c72-e62fe7c79f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-------------------+\n",
      "|source_city|destination_city|              route|\n",
      "+-----------+----------------+-------------------+\n",
      "|     Mumbai|         Chennai|  Mumbai -> Chennai|\n",
      "|    Kolkata|          Mumbai|  Kolkata -> Mumbai|\n",
      "|  Bangalore|           Delhi| Bangalore -> Delhi|\n",
      "|     Mumbai|         Kolkata|  Mumbai -> Kolkata|\n",
      "|     Mumbai|       Bangalore|Mumbai -> Bangalore|\n",
      "+-----------+----------------+-------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat, col\n",
    "\n",
    "airline_t3 = airline_clean.withColumn(\"route\",\n",
    "                                            concat(col(\"source_city\"), lit(\" -> \"), col(\"destination_city\"))\n",
    "                                           )\n",
    "airline_t3.select(\"source_city\", \"destination_city\", \"route\").distinct().show(n=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341816b5-ba0c-41c4-a3ff-944b78baa522",
   "metadata": {},
   "source": [
    "## 4\n",
    "Transform departure_time and arrival_time to numerical categories (Morning, Afternoon, etc.), then encode as numbers (0=Early_Morning, 1=Morning, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20b1ee56-d2ba-49b0-bdcb-0c5e11be372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|departure_time|\n",
      "+--------------+\n",
      "|       Evening|\n",
      "|       Morning|\n",
      "|    Late_Night|\n",
      "|     Afternoon|\n",
      "| Early_Morning|\n",
      "|         Night|\n",
      "+--------------+\n",
      "\n",
      "+-------------+\n",
      "| arrival_time|\n",
      "+-------------+\n",
      "|      Evening|\n",
      "|      Morning|\n",
      "|   Late_Night|\n",
      "|    Afternoon|\n",
      "|Early_Morning|\n",
      "|        Night|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "airline_clean.select(\"departure_time\").distinct().show()\n",
    "airline_clean.select(\"arrival_time\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82c5667c-f736-44b7-a26c-97436fff47f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight: string (nullable = true)\n",
      " |-- source_city: string (nullable = true)\n",
      " |-- departure_time: string (nullable = true)\n",
      " |-- stops: string (nullable = true)\n",
      " |-- arrival_time: string (nullable = true)\n",
      " |-- destination_city: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- duration: float (nullable = true)\n",
      " |-- days_left: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, lit\n",
    "\n",
    "airline_clean.printSchema()\n",
    "\n",
    "def encode_time(column):\n",
    "    return when(col(column) == \"Early_Morning\", lit(0)) \\\n",
    "            .when(col(column) == \"Morning\", lit(1)) \\\n",
    "            .when(col(column) == \"Afternoon\", lit(2)) \\\n",
    "            .when(col(column) == \"Evening\", lit(3)) \\\n",
    "            .when(col(column) == \"Night\", lit(4)) \\\n",
    "            .when(col(column) == \"Late_Night\", lit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f748597-5257-4d92-8be2-3855d7104dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------------+\n",
      "|departure_time_encoded|arrival_time_encoded|\n",
      "+----------------------+--------------------+\n",
      "|                     3|                   4|\n",
      "|                     0|                   1|\n",
      "|                     0|                   0|\n",
      "|                     1|                   2|\n",
      "|                     1|                   1|\n",
      "|                     1|                   2|\n",
      "|                     1|                   1|\n",
      "|                     2|                   3|\n",
      "|                     0|                   1|\n",
      "|                     2|                   3|\n",
      "|                     2|                   3|\n",
      "|                     1|                   2|\n",
      "|                     0|                   1|\n",
      "|                     1|                   2|\n",
      "|                     2|                   3|\n",
      "|                     1|                   1|\n",
      "|                     0|                   1|\n",
      "|                     0|                   1|\n",
      "|                     3|                   0|\n",
      "|                     3|                   1|\n",
      "+----------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "airline_t4 = airline_clean \\\n",
    "    .withColumn(\"departure_time_encoded\", encode_time(\"departure_time\")) \\\n",
    "    .withColumn(\"arrival_time_encoded\", encode_time(\"arrival_time\"))\n",
    "airline_t4.select(\"departure_time_encoded\", \"arrival_time_encoded\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a6c662-401a-42df-af4e-ffd4040cde87",
   "metadata": {},
   "source": [
    "## 5\n",
    "Add a new column is_expensive: when(price > 6000, True).otherwise(False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82dba3b0-4cff-408c-b954-a52d2716ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------+\n",
      "|index|price|is_expensive|\n",
      "+-----+-----+------------+\n",
      "|    0| 5953|       false|\n",
      "|    1| 5953|       false|\n",
      "|    2| 5956|       false|\n",
      "|    3| 5955|       false|\n",
      "|    4| 5955|       false|\n",
      "|    5| 5955|       false|\n",
      "|    6| 6060|        true|\n",
      "|    7| 6060|        true|\n",
      "|    8| 5954|       false|\n",
      "|    9| 5954|       false|\n",
      "+-----+-----+------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "airline_t5 = airline_clean.withColumn(\n",
    "    \"is_expensive\",\n",
    "    when(col(\"price\") > 6000, True).otherwise(False)\n",
    ")\n",
    "airline_t5.select(\"index\", \"price\", \"is_expensive\").show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69fe30-0d18-4182-8135-37740810ba6d",
   "metadata": {},
   "source": [
    "# Agregations\n",
    "Get the average price per airline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "896e935a-3573-433c-98d8-e3a79378c97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|  airline|        avg(price)|\n",
      "+---------+------------------+\n",
      "|   Indigo| 5324.216303339517|\n",
      "| SpiceJet| 6179.278881367218|\n",
      "|Air_India| 23507.01911190229|\n",
      "|  AirAsia|4091.0727419555224|\n",
      "| GO_FIRST| 5652.007595045959|\n",
      "|  Vistara| 30396.53630170735|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "airline_avg_price = airline_clean.groupBy(col(\"airline\")) \\\n",
    "    .agg(avg(col(\"price\")))\n",
    "\n",
    "airline_avg_price.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d441a0-9f57-476f-ac54-84c5401a8cc2",
   "metadata": {},
   "source": [
    "Average duration per route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14c8ac6e-b9e9-4f60-b58a-f4f2689e05b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|               route|      avg_duration|\n",
      "+--------------------+------------------+\n",
      "|  Bangalore -> Delhi|  9.77995566082195|\n",
      "|     Mumbai -> Delhi|  9.81805726844943|\n",
      "|  Delhi -> Bangalore| 10.35412503844018|\n",
      "|     Delhi -> Mumbai|10.367774213738123|\n",
      "|  Hyderabad -> Delhi|10.829816602522587|\n",
      "| Bangalore -> Mumbai| 10.90507225639642|\n",
      "|    Chennai -> Delhi|  11.1493744312541|\n",
      "|    Kolkata -> Delhi| 11.60498857561711|\n",
      "| Mumbai -> Bangalore|11.612022516178817|\n",
      "| Hyderabad -> Mumbai|11.962923295795918|\n",
      "|Hyderabad -> Bang...| 12.09331678643705|\n",
      "|   Chennai -> Mumbai|12.374656244132625|\n",
      "|    Delhi -> Chennai|12.433964745763944|\n",
      "|  Delhi -> Hyderabad|12.518350118710492|\n",
      "|   Mumbai -> Chennai|12.665900287564627|\n",
      "|    Delhi -> Kolkata| 12.73596614766045|\n",
      "|   Mumbai -> Kolkata|12.836848115489666|\n",
      "|   Kolkata -> Mumbai|12.991932481150478|\n",
      "|Bangalore -> Kolkata|13.099143404859825|\n",
      "|Chennai -> Hyderabad|13.153984931732971|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "airline_avg_route = airline_t3.groupBy(col(\"route\"))\\\n",
    "    .agg(avg(col(\"duration\")).alias(\"avg_duration\")) \\\n",
    "    .orderBy(col(\"avg_duration\").asc())\n",
    "\n",
    "airline_avg_route.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cdec2f-a43d-4998-a70e-1f8a771560e5",
   "metadata": {},
   "source": [
    "Minimum and maximum price per airline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dc28104-f9a1-4068-ae43-163170da4dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+\n",
      "|  airline|min_price|max_price|\n",
      "+---------+---------+---------+\n",
      "|   Indigo|     1105|    31952|\n",
      "| SpiceJet|     1106|    34158|\n",
      "|Air_India|     1526|    90970|\n",
      "|  AirAsia|     1105|    31917|\n",
      "| GO_FIRST|     1105|    32803|\n",
      "|  Vistara|     1714|   123071|\n",
      "+---------+---------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "\n",
    "airline_max_min_price = airline_clean.groupby(col(\"airline\")) \\\n",
    "                        .agg(\n",
    "                            min(col(\"price\")).alias(\"min_price\"),\n",
    "                            max(col(\"price\")).alias(\"max_price\")\n",
    "                        )\n",
    "airline_max_min_price.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0303db89-0e5a-436d-a133-543faef9ddf5",
   "metadata": {},
   "source": [
    "Count flights by departure_time category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14b71a15-e8e3-417e-aa6f-574a85f16fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "|departure_time|count_departure|\n",
      "+--------------+---------------+\n",
      "|       Evening|          65102|\n",
      "|       Morning|          71146|\n",
      "|    Late_Night|           1306|\n",
      "|     Afternoon|          47794|\n",
      "| Early_Morning|          66790|\n",
      "|         Night|          48015|\n",
      "+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airline_count_departure = airline_clean.groupby(col(\"departure_time\")) \\\n",
    "                            .agg(\n",
    "                                count(col(\"departure_time\")).alias(\"count_departure\")\n",
    "                            )\n",
    "airline_count_departure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea9d909d-852a-4f06-884c-3541e2704e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2779a78c-4fb1-4187-a963-b44ec8c081cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
