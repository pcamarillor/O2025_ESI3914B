{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 04**: Data Unions & Joins Pipeline\n",
    "\n",
    "**Date**: September 23rd 2025\n",
    "\n",
    "**Student Name**: Ana Carolina Arellano Valdez\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a801e65",
   "metadata": {},
   "source": [
    "# Initializing Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed17a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/26 02:46:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Examples on SparkSQL\") \\\n",
    "    .master(\"spark://9e979d8772f7:7077\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7643e95",
   "metadata": {},
   "source": [
    "# Build schema for each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93cd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build schema\n",
    "# Import your module\n",
    "from carolinarellano.spark_utils import SparkUtils\n",
    "\n",
    "schema_agencies = SparkUtils.generate_schema([(\"agency_id\", \"int\"), (\"agency_info\", \"string\")])\n",
    "schema_brands = SparkUtils.generate_schema([(\"brand_id\", \"int\"), (\"brand_info\", \"string\")])\n",
    "schema_cars = SparkUtils.generate_schema([(\"car_id\", \"int\"), (\"car_info\", \"string\")])\n",
    "schema_customers = SparkUtils.generate_schema([(\"customer_id\", \"int\"), (\"customer_info\", \"string\")])\n",
    "schema_rentals = SparkUtils.generate_schema([(\"rental_id\", \"int\"), (\"rental_info\", \"string\")])\n",
    "\n",
    "df_agencies = spark.read.schema(schema_agencies).option(\"header\", True).csv(\"/opt/spark/work-dir/data/car_service/agencies\")\n",
    "df_brands = spark.read.schema(schema_brands).option(\"header\", True).csv(\"/opt/spark/work-dir/data/car_service/brands\")\n",
    "df_cars = spark.read.schema(schema_cars).option(\"header\", True).csv(\"/opt/spark/work-dir/data/car_service/cars\")\n",
    "df_customers = spark.read.schema(schema_customers).option(\"header\", True).csv(\"/opt/spark/work-dir/data/car_service/customers\")\n",
    "df_rentals = spark.read.schema(schema_rentals).option(\"header\", True).csv(\"/opt/spark/work-dir/data/car_service/rentals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a98d90",
   "metadata": {},
   "source": [
    "# Union of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a4fd6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import get_json_object, col\n",
    "\n",
    "big_df = df_rentals \\\n",
    "    .withColumn(\"car_id\", get_json_object(col(\"rental_info\"), \"$.car_id\").cast(\"int\")) \\\n",
    "    .withColumn(\"customer_id\", get_json_object(col(\"rental_info\"), \"$.customer_id\").cast(\"int\")) \\\n",
    "    .withColumn(\"agency_id\", get_json_object(col(\"rental_info\"), \"$.agency_id\").cast(\"int\")) \\\n",
    "    .join(df_cars.withColumn(\"car_name\", get_json_object(col(\"car_info\"), \"$.car_name\")), \"car_id\", \"inner\") \\\n",
    "    .join(df_customers.withColumn(\"customer_name\", get_json_object(col(\"customer_info\"), \"$.customer_name\")), \"customer_id\", \"inner\") \\\n",
    "    .join(df_agencies.withColumn(\"agency_name\", get_json_object(col(\"agency_info\"), \"$.agency_name\")), \"agency_id\", \"inner\") \\\n",
    "    .select(\"rental_id\", \"car_name\", \"customer_name\", \"agency_name\") \\\n",
    "    .orderBy(\"rental_id\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59920de3",
   "metadata": {},
   "source": [
    "# Show the result of the union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58eef254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------------------+-------------+-------------+\n",
      "|rental_id|car_name                            |customer_name|agency_name  |\n",
      "+---------+------------------------------------+-------------+-------------+\n",
      "|17833    |Grimes-Green Model 8                |Jill Sherman |LA Car Rental|\n",
      "|17832    |Walker, Pratt and Thomas Model 9    |Troy Bell    |Zapopan Auto |\n",
      "|17831    |Levy Group Model 9                  |Lisa Baldwin |Zapopan Auto |\n",
      "|17830    |Alvarez-Davis Model 3               |David Walker |LA Car Rental|\n",
      "|17829    |Patrick, Barrera and Collins Model 6|Blake Jones  |LA Car Rental|\n",
      "+---------+------------------------------------+-------------+-------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "big_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
